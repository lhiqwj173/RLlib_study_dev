{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 测试\n",
    "1. 正常训练结果\n",
    "2. 产生梯度后发送给单独的learner(之后可以放在参数服务器上),学习之后放回参数并应用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray.rllib.algorithms.ppo import PPOConfig\n",
    "import sys\n",
    "sys.path.append(r\"..\")\n",
    "from easy_helper import simplify_rllib_metrics\n",
    "from ray.rllib.algorithms.ppo.torch.ppo_torch_learner import PPOTorchLearner\n",
    "from ray.rllib.core import COMPONENT_RL_MODULE\n",
    "import copy\n",
    "import gymnasium as gym\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 正常训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-18 18:58:40,657\tWARNING ppo.py:295 -- You are running PPO on the new API stack! This is the new default behavior for this algorithm. If you don't want to use the new API stack, set `config.api_stack(enable_rl_module_and_learner=False,enable_env_runner_and_connector_v2=False)`. For a detailed migration guide, see here: https://docs.ray.io/en/master/rllib/new-api-stack-migration-guide.html\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\programs\\miniconda3\\Lib\\site-packages\\ray\\rllib\\algorithms\\algorithm.py:569: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "`UnifiedLogger` will be removed in Ray 2.7.\n",
      "  return UnifiedLogger(config, logdir, loggers=None)\n",
      "d:\\programs\\miniconda3\\Lib\\site-packages\\ray\\tune\\logger\\unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "The `JsonLogger interface is deprecated in favor of the `ray.tune.json.JsonLoggerCallback` interface and will be removed in Ray 2.7.\n",
      "  self._loggers.append(cls(self.config, self.logdir, self.trial))\n",
      "d:\\programs\\miniconda3\\Lib\\site-packages\\ray\\tune\\logger\\unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "The `CSVLogger interface is deprecated in favor of the `ray.tune.csv.CSVLoggerCallback` interface and will be removed in Ray 2.7.\n",
      "  self._loggers.append(cls(self.config, self.logdir, self.trial))\n",
      "d:\\programs\\miniconda3\\Lib\\site-packages\\ray\\tune\\logger\\unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "The `TBXLogger interface is deprecated in favor of the `ray.tune.tensorboardx.TBXLoggerCallback` interface and will be removed in Ray 2.7.\n",
      "  self._loggers.append(cls(self.config, self.logdir, self.trial))\n",
      "2025-01-18 18:58:41,139\tWARNING deprecation.py:50 -- DeprecationWarning: `RLModule(config=[RLModuleConfig object])` has been deprecated. Use `RLModule(observation_space=.., action_space=.., inference_only=.., model_config=.., catalog_class=..)` instead. This will raise an error in the future!\n",
      "2025-01-18 18:58:41,188\tWARNING ppo.py:295 -- You are running PPO on the new API stack! This is the new default behavior for this algorithm. If you don't want to use the new API stack, set `config.api_stack(enable_rl_module_and_learner=False,enable_env_runner_and_connector_v2=False)`. For a detailed migration guide, see here: https://docs.ray.io/en/master/rllib/new-api-stack-migration-guide.html\n",
      "2025-01-18 18:58:41,307\tWARNING rl_module.py:427 -- Could not create a Catalog object for your RLModule! If you are not using the new API stack yet, make sure to switch it off in your config: `config.api_stack(enable_rl_module_and_learner=False, enable_env_runner_and_connector_v2=False)`. Some algos already use the new stack by default. Ignore this message, if your RLModule does not use a Catalog to build its sub-components.\n",
      "2025-01-18 18:58:42,504\tWARNING util.py:61 -- Install gputil for GPU system monitoring.\n",
      "2025-01-18 18:59:07,078\tINFO worker.py:1821 -- Started a local Ray instance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------- 训练迭代: 1 ---------\n",
      "环境运行器:\n",
      "  episode平均回报: 22.1500\n",
      "  episode最大回报: 64.0000\n",
      "  episode平均步数: 22.1500\n",
      "  episode最大步数: 64.0000\n",
      "  采样环境总步数: 4000.0000\n",
      "  episodes计数: 185.0000\n",
      "\n",
      "评估:\n",
      "  无评估数据\n",
      "\n",
      "学习者(默认策略):\n",
      "  熵: 0.6645\n",
      "  策略损失: -0.1389\n",
      "  值函数损失: 6.5063\n",
      "  总损失: 6.3725\n",
      "\n",
      "本轮时间: 27.6693\n",
      "每轮训练步数: 1\n",
      "------------------------------\n",
      "--------- 训练迭代: 2 ---------\n",
      "环境运行器:\n",
      "  episode平均回报: 39.0600\n",
      "  episode最大回报: 117.0000\n",
      "  episode平均步数: 39.0600\n",
      "  episode最大步数: 117.0000\n",
      "  采样环境总步数: 4000.0000\n",
      "  episodes计数: 102.0000\n",
      "\n",
      "评估:\n",
      "  无评估数据\n",
      "\n",
      "学习者(默认策略):\n",
      "  熵: 0.6339\n",
      "  策略损失: -0.0614\n",
      "  值函数损失: 8.0985\n",
      "  总损失: 8.0409\n",
      "\n",
      "本轮时间: 19.2447\n",
      "每轮训练步数: 1\n",
      "------------------------------\n",
      "--------- 训练迭代: 3 ---------\n",
      "环境运行器:\n",
      "  episode平均回报: 53.8800\n",
      "  episode最大回报: 147.0000\n",
      "  episode平均步数: 53.8900\n",
      "  episode最大步数: 147.0000\n",
      "  采样环境总步数: 4000.0000\n",
      "  episodes计数: 65.0000\n",
      "\n",
      "评估:\n",
      "  无评估数据\n",
      "\n",
      "学习者(默认策略):\n",
      "  熵: 0.6064\n",
      "  策略损失: 0.0233\n",
      "  值函数损失: 8.8780\n",
      "  总损失: 8.9050\n",
      "\n",
      "本轮时间: 19.1785\n",
      "每轮训练步数: 1\n",
      "------------------------------\n",
      "--------- 训练迭代: 4 ---------\n",
      "环境运行器:\n",
      "  episode平均回报: 81.3900\n",
      "  episode最大回报: 355.0000\n",
      "  episode平均步数: 81.4100\n",
      "  episode最大步数: 355.0000\n",
      "  采样环境总步数: 4000.0000\n",
      "  episodes计数: 29.0000\n",
      "\n",
      "评估:\n",
      "  无评估数据\n",
      "\n",
      "学习者(默认策略):\n",
      "  熵: 0.5953\n",
      "  策略损失: -0.0085\n",
      "  值函数损失: 9.3512\n",
      "  总损失: 9.3452\n",
      "\n",
      "本轮时间: 20.2873\n",
      "每轮训练步数: 1\n",
      "------------------------------\n",
      "--------- 训练迭代: 5 ---------\n",
      "环境运行器:\n",
      "  episode平均回报: 112.5900\n",
      "  episode最大回报: 416.0000\n",
      "  episode平均步数: 112.6100\n",
      "  episode最大步数: 416.0000\n",
      "  采样环境总步数: 4000.0000\n",
      "  episodes计数: 20.0000\n",
      "\n",
      "评估:\n",
      "  无评估数据\n",
      "\n",
      "学习者(默认策略):\n",
      "  熵: 0.5917\n",
      "  策略损失: -0.0937\n",
      "  值函数损失: 9.5625\n",
      "  总损失: 9.4705\n",
      "\n",
      "本轮时间: 21.8925\n",
      "每轮训练步数: 1\n",
      "------------------------------\n",
      "--------- 训练迭代: 6 ---------\n",
      "环境运行器:\n",
      "  episode平均回报: 141.1300\n",
      "  episode最大回报: 500.0000\n",
      "  episode平均步数: 141.1600\n",
      "  episode最大步数: 500.0000\n",
      "  采样环境总步数: 4000.0000\n",
      "  episodes计数: 14.0000\n",
      "\n",
      "评估:\n",
      "  无评估数据\n",
      "\n",
      "学习者(默认策略):\n",
      "  熵: 0.5828\n",
      "  策略损失: -0.0069\n",
      "  值函数损失: 9.8644\n",
      "  总损失: 9.8592\n",
      "\n",
      "本轮时间: 21.8807\n",
      "每轮训练步数: 1\n",
      "------------------------------\n",
      "--------- 训练迭代: 7 ---------\n",
      "环境运行器:\n",
      "  episode平均回报: 174.9600\n",
      "  episode最大回报: 500.0000\n",
      "  episode平均步数: 175.0000\n",
      "  episode最大步数: 501.0000\n",
      "  采样环境总步数: 4000.0000\n",
      "  episodes计数: 12.0000\n",
      "\n",
      "评估:\n",
      "  无评估数据\n",
      "\n",
      "学习者(默认策略):\n",
      "  熵: 0.5865\n",
      "  策略损失: -0.0489\n",
      "  值函数损失: 9.9214\n",
      "  总损失: 9.8737\n",
      "\n",
      "本轮时间: 21.1252\n",
      "每轮训练步数: 1\n",
      "------------------------------\n",
      "--------- 训练迭代: 8 ---------\n",
      "环境运行器:\n",
      "  episode平均回报: 206.7000\n",
      "  episode最大回报: 500.0000\n",
      "  episode平均步数: 206.7500\n",
      "  episode最大步数: 501.0000\n",
      "  采样环境总步数: 4000.0000\n",
      "  episodes计数: 10.0000\n",
      "\n",
      "评估:\n",
      "  无评估数据\n",
      "\n",
      "学习者(默认策略):\n",
      "  熵: 0.5540\n",
      "  策略损失: 0.0700\n",
      "  值函数损失: 9.8446\n",
      "  总损失: 9.9155\n",
      "\n",
      "本轮时间: 20.3040\n",
      "每轮训练步数: 1\n",
      "------------------------------\n",
      "--------- 训练迭代: 9 ---------\n",
      "环境运行器:\n",
      "  episode平均回报: 239.7900\n",
      "  episode最大回报: 500.0000\n",
      "  episode平均步数: 239.8500\n",
      "  episode最大步数: 501.0000\n",
      "  采样环境总步数: 4000.0000\n",
      "  episodes计数: 8.0000\n",
      "\n",
      "评估:\n",
      "  无评估数据\n",
      "\n",
      "学习者(默认策略):\n",
      "  熵: 0.5729\n",
      "  策略损失: -0.1390\n",
      "  值函数损失: 9.8177\n",
      "  总损失: 9.6797\n",
      "\n",
      "本轮时间: 19.5130\n",
      "每轮训练步数: 1\n",
      "------------------------------\n",
      "--------- 训练迭代: 10 ---------\n",
      "环境运行器:\n",
      "  episode平均回报: 274.4700\n",
      "  episode最大回报: 500.0000\n",
      "  episode平均步数: 274.5300\n",
      "  episode最大步数: 501.0000\n",
      "  采样环境总步数: 4000.0000\n",
      "  episodes计数: 8.0000\n",
      "\n",
      "评估:\n",
      "  无评估数据\n",
      "\n",
      "学习者(默认策略):\n",
      "  熵: 0.5512\n",
      "  策略损失: -0.0436\n",
      "  值函数损失: 10.0000\n",
      "  总损失: 9.9572\n",
      "\n",
      "本轮时间: 19.3446\n",
      "每轮训练步数: 1\n",
      "------------------------------\n",
      "--------- 训练迭代: 11 ---------\n",
      "环境运行器:\n",
      "  episode平均回报: 301.1800\n",
      "  episode最大回报: 500.0000\n",
      "  episode平均步数: 301.2500\n",
      "  episode最大步数: 501.0000\n",
      "  采样环境总步数: 4000.0000\n",
      "  episodes计数: 9.0000\n",
      "\n",
      "评估:\n",
      "  无评估数据\n",
      "\n",
      "学习者(默认策略):\n",
      "  熵: 0.5741\n",
      "  策略损失: 0.0259\n",
      "  值函数损失: 9.8286\n",
      "  总损失: 9.8550\n",
      "\n",
      "本轮时间: 19.3385\n",
      "每轮训练步数: 1\n",
      "------------------------------\n",
      "--------- 训练迭代: 12 ---------\n",
      "环境运行器:\n",
      "  episode平均回报: 328.9800\n",
      "  episode最大回报: 500.0000\n",
      "  episode平均步数: 329.0600\n",
      "  episode最大步数: 501.0000\n",
      "  采样环境总步数: 4000.0000\n",
      "  episodes计数: 8.0000\n",
      "\n",
      "评估:\n",
      "  无评估数据\n",
      "\n",
      "学习者(默认策略):\n",
      "  熵: 0.5870\n",
      "  策略损失: 0.0099\n",
      "  值函数损失: 9.7242\n",
      "  总损失: 9.7343\n",
      "\n",
      "本轮时间: 19.5224\n",
      "每轮训练步数: 1\n",
      "------------------------------\n",
      "--------- 训练迭代: 13 ---------\n",
      "环境运行器:\n",
      "  episode平均回报: 361.0000\n",
      "  episode最大回报: 500.0000\n",
      "  episode平均步数: 361.0900\n",
      "  episode最大步数: 501.0000\n",
      "  采样环境总步数: 4000.0000\n",
      "  episodes计数: 11.0000\n",
      "\n",
      "评估:\n",
      "  无评估数据\n",
      "\n",
      "学习者(默认策略):\n",
      "  熵: 0.5315\n",
      "  策略损失: 0.0158\n",
      "  值函数损失: 9.8708\n",
      "  总损失: 9.8870\n",
      "\n",
      "本轮时间: 19.6195\n",
      "每轮训练步数: 1\n",
      "------------------------------\n",
      "--------- 训练迭代: 14 ---------\n",
      "环境运行器:\n",
      "  episode平均回报: 381.3900\n",
      "  episode最大回报: 500.0000\n",
      "  episode平均步数: 381.4800\n",
      "  episode最大步数: 501.0000\n",
      "  采样环境总步数: 4000.0000\n",
      "  episodes计数: 8.0000\n",
      "\n",
      "评估:\n",
      "  无评估数据\n",
      "\n",
      "学习者(默认策略):\n",
      "  熵: 0.5526\n",
      "  策略损失: -0.0416\n",
      "  值函数损失: 10.0000\n",
      "  总损失: 9.9587\n",
      "\n",
      "本轮时间: 19.2368\n",
      "每轮训练步数: 1\n",
      "------------------------------\n",
      "--------- 训练迭代: 15 ---------\n",
      "环境运行器:\n",
      "  episode平均回报: 405.7100\n",
      "  episode最大回报: 500.0000\n",
      "  episode平均步数: 405.8100\n",
      "  episode最大步数: 501.0000\n",
      "  采样环境总步数: 4000.0000\n",
      "  episodes计数: 8.0000\n",
      "\n",
      "评估:\n",
      "  无评估数据\n",
      "\n",
      "学习者(默认策略):\n",
      "  熵: 0.5308\n",
      "  策略损失: -0.1505\n",
      "  值函数损失: 9.9284\n",
      "  总损失: 9.7781\n",
      "\n",
      "本轮时间: 19.4787\n",
      "每轮训练步数: 1\n",
      "------------------------------\n",
      "--------- 训练迭代: 16 ---------\n",
      "环境运行器:\n",
      "  episode平均回报: 429.3200\n",
      "  episode最大回报: 500.0000\n",
      "  episode平均步数: 429.4200\n",
      "  episode最大步数: 501.0000\n",
      "  采样环境总步数: 4000.0000\n",
      "  episodes计数: 8.0000\n",
      "\n",
      "评估:\n",
      "  无评估数据\n",
      "\n",
      "学习者(默认策略):\n",
      "  熵: 0.5462\n",
      "  策略损失: -0.0579\n",
      "  值函数损失: 9.9309\n",
      "  总损失: 9.8732\n",
      "\n",
      "本轮时间: 19.3600\n",
      "每轮训练步数: 1\n",
      "------------------------------\n",
      "--------- 训练迭代: 17 ---------\n",
      "环境运行器:\n",
      "  episode平均回报: 442.7300\n",
      "  episode最大回报: 500.0000\n",
      "  episode平均步数: 442.8400\n",
      "  episode最大步数: 501.0000\n",
      "  采样环境总步数: 4000.0000\n",
      "  episodes计数: 10.0000\n",
      "\n",
      "评估:\n",
      "  无评估数据\n",
      "\n",
      "学习者(默认策略):\n",
      "  熵: 0.5689\n",
      "  策略损失: 0.0307\n",
      "  值函数损失: 9.8323\n",
      "  总损失: 9.8631\n",
      "\n",
      "本轮时间: 19.4289\n",
      "每轮训练步数: 1\n",
      "------------------------------\n",
      "--------- 训练迭代: 18 ---------\n",
      "环境运行器:\n",
      "  episode平均回报: 452.9200\n",
      "  episode最大回报: 500.0000\n",
      "  episode平均步数: 453.0300\n",
      "  episode最大步数: 501.0000\n",
      "  采样环境总步数: 4000.0000\n",
      "  episodes计数: 8.0000\n",
      "\n",
      "评估:\n",
      "  无评估数据\n",
      "\n",
      "学习者(默认策略):\n",
      "  熵: 0.5610\n",
      "  策略损失: -0.0755\n",
      "  值函数损失: 9.8495\n",
      "  总损失: 9.7741\n",
      "\n",
      "本轮时间: 19.4148\n",
      "每轮训练步数: 1\n",
      "------------------------------\n",
      "--------- 训练迭代: 19 ---------\n",
      "环境运行器:\n",
      "  episode平均回报: 432.5100\n",
      "  episode最大回报: 500.0000\n",
      "  episode平均步数: 432.6100\n",
      "  episode最大步数: 501.0000\n",
      "  采样环境总步数: 4000.0000\n",
      "  episodes计数: 16.0000\n",
      "\n",
      "评估:\n",
      "  无评估数据\n",
      "\n",
      "学习者(默认策略):\n",
      "  熵: 0.5597\n",
      "  策略损失: -0.0153\n",
      "  值函数损失: 9.7160\n",
      "  总损失: 9.7010\n",
      "\n",
      "本轮时间: 19.4680\n",
      "每轮训练步数: 1\n",
      "------------------------------\n",
      "--------- 训练迭代: 20 ---------\n",
      "环境运行器:\n",
      "  episode平均回报: 413.0700\n",
      "  episode最大回报: 500.0000\n",
      "  episode平均步数: 413.1700\n",
      "  episode最大步数: 501.0000\n",
      "  采样环境总步数: 4000.0000\n",
      "  episodes计数: 12.0000\n",
      "\n",
      "评估:\n",
      "  无评估数据\n",
      "\n",
      "学习者(默认策略):\n",
      "  熵: 0.5339\n",
      "  策略损失: -0.0553\n",
      "  值函数损失: 9.6684\n",
      "  总损失: 9.6132\n",
      "\n",
      "本轮时间: 19.5822\n",
      "每轮训练步数: 1\n",
      "------------------------------\n",
      "--------- 训练迭代: 21 ---------\n",
      "环境运行器:\n",
      "  episode平均回报: 414.0200\n",
      "  episode最大回报: 500.0000\n",
      "  episode平均步数: 414.1200\n",
      "  episode最大步数: 501.0000\n",
      "  采样环境总步数: 4000.0000\n",
      "  episodes计数: 8.0000\n",
      "\n",
      "评估:\n",
      "  无评估数据\n",
      "\n",
      "学习者(默认策略):\n",
      "  熵: 0.5698\n",
      "  策略损失: -0.0503\n",
      "  值函数损失: 9.7590\n",
      "  总损失: 9.7088\n",
      "\n",
      "本轮时间: 19.3055\n",
      "每轮训练步数: 1\n",
      "------------------------------\n",
      "--------- 训练迭代: 22 ---------\n",
      "环境运行器:\n",
      "  episode平均回报: 409.9600\n",
      "  episode最大回报: 500.0000\n",
      "  episode平均步数: 410.0600\n",
      "  episode最大步数: 501.0000\n",
      "  采样环境总步数: 4000.0000\n",
      "  episodes计数: 9.0000\n",
      "\n",
      "评估:\n",
      "  无评估数据\n",
      "\n",
      "学习者(默认策略):\n",
      "  熵: 0.5478\n",
      "  策略损失: 0.0288\n",
      "  值函数损失: 9.8640\n",
      "  总损失: 9.8929\n",
      "\n",
      "本轮时间: 19.4645\n",
      "每轮训练步数: 1\n",
      "------------------------------\n",
      "--------- 训练迭代: 23 ---------\n",
      "环境运行器:\n",
      "  episode平均回报: 413.1400\n",
      "  episode最大回报: 500.0000\n",
      "  episode平均步数: 413.2400\n",
      "  episode最大步数: 501.0000\n",
      "  采样环境总步数: 4000.0000\n",
      "  episodes计数: 9.0000\n",
      "\n",
      "评估:\n",
      "  无评估数据\n",
      "\n",
      "学习者(默认策略):\n",
      "  熵: 0.5668\n",
      "  策略损失: 0.1352\n",
      "  值函数损失: 9.6836\n",
      "  总损失: 9.8189\n",
      "\n",
      "本轮时间: 19.3117\n",
      "每轮训练步数: 1\n",
      "------------------------------\n",
      "--------- 训练迭代: 24 ---------\n",
      "环境运行器:\n",
      "  episode平均回报: 413.4800\n",
      "  episode最大回报: 500.0000\n",
      "  episode平均步数: 413.5800\n",
      "  episode最大步数: 501.0000\n",
      "  采样环境总步数: 4000.0000\n",
      "  episodes计数: 9.0000\n",
      "\n",
      "评估:\n",
      "  无评估数据\n",
      "\n",
      "学习者(默认策略):\n",
      "  熵: 0.4977\n",
      "  策略损失: 0.1521\n",
      "  值函数损失: 9.5443\n",
      "  总损失: 9.6966\n",
      "\n",
      "本轮时间: 19.4641\n",
      "每轮训练步数: 1\n",
      "------------------------------\n",
      "--------- 训练迭代: 25 ---------\n",
      "环境运行器:\n",
      "  episode平均回报: 409.6900\n",
      "  episode最大回报: 500.0000\n",
      "  episode平均步数: 409.7900\n",
      "  episode最大步数: 501.0000\n",
      "  采样环境总步数: 4000.0000\n",
      "  episodes计数: 9.0000\n",
      "\n",
      "评估:\n",
      "  无评估数据\n",
      "\n",
      "学习者(默认策略):\n",
      "  熵: 0.4838\n",
      "  策略损失: -0.0089\n",
      "  值函数损失: 9.9998\n",
      "  总损失: 9.9910\n",
      "\n",
      "本轮时间: 19.3669\n",
      "每轮训练步数: 1\n",
      "------------------------------\n",
      "--------- 训练迭代: 26 ---------\n",
      "环境运行器:\n",
      "  episode平均回报: 403.9300\n",
      "  episode最大回报: 500.0000\n",
      "  episode平均步数: 404.0300\n",
      "  episode最大步数: 501.0000\n",
      "  采样环境总步数: 4000.0000\n",
      "  episodes计数: 10.0000\n",
      "\n",
      "评估:\n",
      "  无评估数据\n",
      "\n",
      "学习者(默认策略):\n",
      "  熵: 0.5251\n",
      "  策略损失: 0.0267\n",
      "  值函数损失: 9.8135\n",
      "  总损失: 9.8402\n",
      "\n",
      "本轮时间: 19.4910\n",
      "每轮训练步数: 1\n",
      "------------------------------\n",
      "--------- 训练迭代: 27 ---------\n",
      "环境运行器:\n",
      "  episode平均回报: 404.0200\n",
      "  episode最大回报: 500.0000\n",
      "  episode平均步数: 404.1200\n",
      "  episode最大步数: 501.0000\n",
      "  采样环境总步数: 4000.0000\n",
      "  episodes计数: 8.0000\n",
      "\n",
      "评估:\n",
      "  无评估数据\n",
      "\n",
      "学习者(默认策略):\n",
      "  熵: 0.5009\n",
      "  策略损失: 0.0338\n",
      "  值函数损失: 9.7964\n",
      "  总损失: 9.8304\n",
      "\n",
      "本轮时间: 19.2376\n",
      "每轮训练步数: 1\n",
      "------------------------------\n",
      "--------- 训练迭代: 28 ---------\n",
      "环境运行器:\n",
      "  episode平均回报: 407.2600\n",
      "  episode最大回报: 500.0000\n",
      "  episode平均步数: 407.3600\n",
      "  episode最大步数: 501.0000\n",
      "  采样环境总步数: 4000.0000\n",
      "  episodes计数: 8.0000\n",
      "\n",
      "评估:\n",
      "  无评估数据\n",
      "\n",
      "学习者(默认策略):\n",
      "  熵: 0.4971\n",
      "  策略损失: 0.1365\n",
      "  值函数损失: 9.7651\n",
      "  总损失: 9.9018\n",
      "\n",
      "本轮时间: 19.8831\n",
      "每轮训练步数: 1\n",
      "------------------------------\n",
      "--------- 训练迭代: 29 ---------\n",
      "环境运行器:\n",
      "  episode平均回报: 422.5200\n",
      "  episode最大回报: 500.0000\n",
      "  episode平均步数: 422.6200\n",
      "  episode最大步数: 501.0000\n",
      "  采样环境总步数: 4000.0000\n",
      "  episodes计数: 9.0000\n",
      "\n",
      "评估:\n",
      "  无评估数据\n",
      "\n",
      "学习者(默认策略):\n",
      "  熵: 0.4573\n",
      "  策略损失: 0.0433\n",
      "  值函数损失: 9.8242\n",
      "  总损失: 9.8676\n",
      "\n",
      "本轮时间: 19.4097\n",
      "每轮训练步数: 1\n",
      "------------------------------\n",
      "--------- 训练迭代: 30 ---------\n",
      "环境运行器:\n",
      "  episode平均回报: 442.5000\n",
      "  episode最大回报: 500.0000\n",
      "  episode平均步数: 442.6100\n",
      "  episode最大步数: 501.0000\n",
      "  采样环境总步数: 4000.0000\n",
      "  episodes计数: 8.0000\n",
      "\n",
      "评估:\n",
      "  无评估数据\n",
      "\n",
      "学习者(默认策略):\n",
      "  熵: 0.5227\n",
      "  策略损失: -0.1537\n",
      "  值函数损失: 9.9503\n",
      "  总损失: 9.7967\n",
      "\n",
      "本轮时间: 19.3535\n",
      "每轮训练步数: 1\n",
      "------------------------------\n",
      "--------- 训练迭代: 31 ---------\n",
      "环境运行器:\n",
      "  episode平均回报: 452.6700\n",
      "  episode最大回报: 500.0000\n",
      "  episode平均步数: 452.7800\n",
      "  episode最大步数: 501.0000\n",
      "  采样环境总步数: 4000.0000\n",
      "  episodes计数: 8.0000\n",
      "\n",
      "评估:\n",
      "  无评估数据\n",
      "\n",
      "学习者(默认策略):\n",
      "  熵: 0.4885\n",
      "  策略损失: 0.1437\n",
      "  值函数损失: 9.8441\n",
      "  总损失: 9.9880\n",
      "\n",
      "本轮时间: 19.5618\n",
      "每轮训练步数: 1\n",
      "------------------------------\n",
      "--------- 训练迭代: 32 ---------\n",
      "环境运行器:\n",
      "  episode平均回报: 464.6700\n",
      "  episode最大回报: 500.0000\n",
      "  episode平均步数: 464.7800\n",
      "  episode最大步数: 501.0000\n",
      "  采样环境总步数: 4000.0000\n",
      "  episodes计数: 8.0000\n",
      "\n",
      "评估:\n",
      "  无评估数据\n",
      "\n",
      "学习者(默认策略):\n",
      "  熵: 0.4606\n",
      "  策略损失: 0.0922\n",
      "  值函数损失: 9.7316\n",
      "  总损失: 9.8239\n",
      "\n",
      "本轮时间: 19.4842\n",
      "每轮训练步数: 1\n",
      "------------------------------\n",
      "--------- 训练迭代: 33 ---------\n",
      "环境运行器:\n",
      "  episode平均回报: 466.2700\n",
      "  episode最大回报: 500.0000\n",
      "  episode平均步数: 466.3800\n",
      "  episode最大步数: 501.0000\n",
      "  采样环境总步数: 4000.0000\n",
      "  episodes计数: 8.0000\n",
      "\n",
      "评估:\n",
      "  无评估数据\n",
      "\n",
      "学习者(默认策略):\n",
      "  熵: 0.4895\n",
      "  策略损失: 0.0512\n",
      "  值函数损失: 9.7363\n",
      "  总损失: 9.7875\n",
      "\n",
      "本轮时间: 19.2741\n",
      "每轮训练步数: 1\n",
      "------------------------------\n",
      "--------- 训练迭代: 34 ---------\n",
      "环境运行器:\n",
      "  episode平均回报: 465.4300\n",
      "  episode最大回报: 500.0000\n",
      "  episode平均步数: 465.5400\n",
      "  episode最大步数: 501.0000\n",
      "  采样环境总步数: 4000.0000\n",
      "  episodes计数: 10.0000\n",
      "\n",
      "评估:\n",
      "  无评估数据\n",
      "\n",
      "学习者(默认策略):\n",
      "  熵: 0.4531\n",
      "  策略损失: -0.0999\n",
      "  值函数损失: 9.7855\n",
      "  总损失: 9.6856\n",
      "\n",
      "本轮时间: 21.1264\n",
      "每轮训练步数: 1\n",
      "------------------------------\n",
      "--------- 训练迭代: 35 ---------\n",
      "环境运行器:\n",
      "  episode平均回报: 468.5000\n",
      "  episode最大回报: 500.0000\n",
      "  episode平均步数: 468.6100\n",
      "  episode最大步数: 501.0000\n",
      "  采样环境总步数: 4000.0000\n",
      "  episodes计数: 8.0000\n",
      "\n",
      "评估:\n",
      "  无评估数据\n",
      "\n",
      "学习者(默认策略):\n",
      "  熵: 0.4284\n",
      "  策略损失: -0.0841\n",
      "  值函数损失: 9.8683\n",
      "  总损失: 9.7843\n",
      "\n",
      "本轮时间: 19.4699\n",
      "每轮训练步数: 1\n",
      "------------------------------\n",
      "--------- 训练迭代: 36 ---------\n",
      "环境运行器:\n",
      "  episode平均回报: 473.2700\n",
      "  episode最大回报: 500.0000\n",
      "  episode平均步数: 473.3800\n",
      "  episode最大步数: 501.0000\n",
      "  采样环境总步数: 4000.0000\n",
      "  episodes计数: 8.0000\n",
      "\n",
      "评估:\n",
      "  无评估数据\n",
      "\n",
      "学习者(默认策略):\n",
      "  熵: 0.4194\n",
      "  策略损失: -0.1338\n",
      "  值函数损失: 10.0000\n",
      "  总损失: 9.8663\n",
      "\n",
      "本轮时间: 19.4335\n",
      "每轮训练步数: 1\n",
      "------------------------------\n",
      "--------- 训练迭代: 37 ---------\n",
      "环境运行器:\n",
      "  episode平均回报: 478.5900\n",
      "  episode最大回报: 500.0000\n",
      "  episode平均步数: 478.7000\n",
      "  episode最大步数: 501.0000\n",
      "  采样环境总步数: 4000.0000\n",
      "  episodes计数: 8.0000\n",
      "\n",
      "评估:\n",
      "  无评估数据\n",
      "\n",
      "学习者(默认策略):\n",
      "  熵: 0.4080\n",
      "  策略损失: 0.1602\n",
      "  值函数损失: 9.9017\n",
      "  总损失: 10.0619\n",
      "\n",
      "本轮时间: 19.2411\n",
      "每轮训练步数: 1\n",
      "------------------------------\n",
      "--------- 训练迭代: 38 ---------\n",
      "环境运行器:\n",
      "  episode平均回报: 483.5300\n",
      "  episode最大回报: 500.0000\n",
      "  episode平均步数: 483.6500\n",
      "  episode最大步数: 501.0000\n",
      "  采样环境总步数: 4000.0000\n",
      "  episodes计数: 8.0000\n",
      "\n",
      "评估:\n",
      "  无评估数据\n",
      "\n",
      "学习者(默认策略):\n",
      "  熵: 0.3911\n",
      "  策略损失: -0.0762\n",
      "  值函数损失: 9.9634\n",
      "  总损失: 9.8872\n",
      "\n",
      "本轮时间: 19.5271\n",
      "每轮训练步数: 1\n",
      "------------------------------\n",
      "--------- 训练迭代: 39 ---------\n",
      "环境运行器:\n",
      "  episode平均回报: 484.1500\n",
      "  episode最大回报: 500.0000\n",
      "  episode平均步数: 484.2700\n",
      "  episode最大步数: 501.0000\n",
      "  采样环境总步数: 4000.0000\n",
      "  episodes计数: 8.0000\n",
      "\n",
      "评估:\n",
      "  无评估数据\n",
      "\n",
      "学习者(默认策略):\n",
      "  熵: 0.3798\n",
      "  策略损失: -0.0512\n",
      "  值函数损失: 9.9720\n",
      "  总损失: 9.9208\n",
      "\n",
      "本轮时间: 19.4106\n",
      "每轮训练步数: 1\n",
      "------------------------------\n",
      "--------- 训练迭代: 40 ---------\n",
      "环境运行器:\n",
      "  episode平均回报: 485.8600\n",
      "  episode最大回报: 500.0000\n",
      "  episode平均步数: 485.9800\n",
      "  episode最大步数: 501.0000\n",
      "  采样环境总步数: 4000.0000\n",
      "  episodes计数: 8.0000\n",
      "\n",
      "评估:\n",
      "  无评估数据\n",
      "\n",
      "学习者(默认策略):\n",
      "  熵: 0.4305\n",
      "  策略损失: 0.0218\n",
      "  值函数损失: 9.9256\n",
      "  总损失: 9.9474\n",
      "\n",
      "本轮时间: 19.4893\n",
      "每轮训练步数: 1\n",
      "------------------------------\n",
      "--------- 训练迭代: 41 ---------\n",
      "环境运行器:\n",
      "  episode平均回报: 488.5100\n",
      "  episode最大回报: 500.0000\n",
      "  episode平均步数: 488.6300\n",
      "  episode最大步数: 501.0000\n",
      "  采样环境总步数: 4000.0000\n",
      "  episodes计数: 8.0000\n",
      "\n",
      "评估:\n",
      "  无评估数据\n",
      "\n",
      "学习者(默认策略):\n",
      "  熵: 0.3656\n",
      "  策略损失: -0.0516\n",
      "  值函数损失: 9.8738\n",
      "  总损失: 9.8223\n",
      "\n",
      "本轮时间: 19.2975\n",
      "每轮训练步数: 1\n",
      "------------------------------\n",
      "--------- 训练迭代: 42 ---------\n",
      "环境运行器:\n",
      "  episode平均回报: 473.4100\n",
      "  episode最大回报: 500.0000\n",
      "  episode平均步数: 473.5200\n",
      "  episode最大步数: 501.0000\n",
      "  采样环境总步数: 4000.0000\n",
      "  episodes计数: 11.0000\n",
      "\n",
      "评估:\n",
      "  无评估数据\n",
      "\n",
      "学习者(默认策略):\n",
      "  熵: 0.4187\n",
      "  策略损失: 0.0781\n",
      "  值函数损失: 9.7915\n",
      "  总损失: 9.8696\n",
      "\n",
      "本轮时间: 20.7671\n",
      "每轮训练步数: 1\n",
      "------------------------------\n",
      "--------- 训练迭代: 43 ---------\n",
      "环境运行器:\n",
      "  episode平均回报: 470.7400\n",
      "  episode最大回报: 500.0000\n",
      "  episode平均步数: 470.8500\n",
      "  episode最大步数: 501.0000\n",
      "  采样环境总步数: 4000.0000\n",
      "  episodes计数: 9.0000\n",
      "\n",
      "评估:\n",
      "  无评估数据\n",
      "\n",
      "学习者(默认策略):\n",
      "  熵: 0.3748\n",
      "  策略损失: 0.0229\n",
      "  值函数损失: 9.9403\n",
      "  总损失: 9.9633\n",
      "\n",
      "本轮时间: 19.2257\n",
      "每轮训练步数: 1\n",
      "------------------------------\n",
      "--------- 训练迭代: 44 ---------\n",
      "环境运行器:\n",
      "  episode平均回报: 465.4600\n",
      "  episode最大回报: 500.0000\n",
      "  episode平均步数: 465.5700\n",
      "  episode最大步数: 501.0000\n",
      "  采样环境总步数: 4000.0000\n",
      "  episodes计数: 9.0000\n",
      "\n",
      "评估:\n",
      "  无评估数据\n",
      "\n",
      "学习者(默认策略):\n",
      "  熵: 0.4133\n",
      "  策略损失: -0.0637\n",
      "  值函数损失: 9.7654\n",
      "  总损失: 9.7017\n",
      "\n",
      "本轮时间: 19.2200\n",
      "每轮训练步数: 1\n",
      "------------------------------\n",
      "--------- 训练迭代: 45 ---------\n",
      "环境运行器:\n",
      "  episode平均回报: 457.8500\n",
      "  episode最大回报: 500.0000\n",
      "  episode平均步数: 457.9600\n",
      "  episode最大步数: 501.0000\n",
      "  采样环境总步数: 4000.0000\n",
      "  episodes计数: 10.0000\n",
      "\n",
      "评估:\n",
      "  无评估数据\n",
      "\n",
      "学习者(默认策略):\n",
      "  熵: 0.4263\n",
      "  策略损失: -0.1028\n",
      "  值函数损失: 9.8026\n",
      "  总损失: 9.6998\n",
      "\n",
      "本轮时间: 19.2801\n",
      "每轮训练步数: 1\n",
      "------------------------------\n",
      "--------- 训练迭代: 46 ---------\n",
      "环境运行器:\n",
      "  episode平均回报: 457.3300\n",
      "  episode最大回报: 500.0000\n",
      "  episode平均步数: 457.4400\n",
      "  episode最大步数: 501.0000\n",
      "  采样环境总步数: 4000.0000\n",
      "  episodes计数: 9.0000\n",
      "\n",
      "评估:\n",
      "  无评估数据\n",
      "\n",
      "学习者(默认策略):\n",
      "  熵: 0.3820\n",
      "  策略损失: 0.0382\n",
      "  值函数损失: 9.7070\n",
      "  总损失: 9.7452\n",
      "\n",
      "本轮时间: 19.5268\n",
      "每轮训练步数: 1\n",
      "------------------------------\n",
      "--------- 训练迭代: 47 ---------\n",
      "环境运行器:\n",
      "  episode平均回报: 457.3300\n",
      "  episode最大回报: 500.0000\n",
      "  episode平均步数: 457.4400\n",
      "  episode最大步数: 501.0000\n",
      "  采样环境总步数: 4000.0000\n",
      "  episodes计数: 8.0000\n",
      "\n",
      "评估:\n",
      "  无评估数据\n",
      "\n",
      "学习者(默认策略):\n",
      "  熵: 0.3382\n",
      "  策略损失: 0.0534\n",
      "  值函数损失: 9.7511\n",
      "  总损失: 9.8046\n",
      "\n",
      "本轮时间: 19.4760\n",
      "每轮训练步数: 1\n",
      "------------------------------\n",
      "--------- 训练迭代: 48 ---------\n",
      "环境运行器:\n",
      "  episode平均回报: 457.3300\n",
      "  episode最大回报: 500.0000\n",
      "  episode平均步数: 457.4400\n",
      "  episode最大步数: 501.0000\n",
      "  采样环境总步数: 4000.0000\n",
      "  episodes计数: 8.0000\n",
      "\n",
      "评估:\n",
      "  无评估数据\n",
      "\n",
      "学习者(默认策略):\n",
      "  熵: 0.3500\n",
      "  策略损失: 0.1571\n",
      "  值函数损失: 9.8968\n",
      "  总损失: 10.0539\n",
      "\n",
      "本轮时间: 19.2047\n",
      "每轮训练步数: 1\n",
      "------------------------------\n",
      "--------- 训练迭代: 49 ---------\n",
      "环境运行器:\n",
      "  episode平均回报: 457.3300\n",
      "  episode最大回报: 500.0000\n",
      "  episode平均步数: 457.4400\n",
      "  episode最大步数: 501.0000\n",
      "  采样环境总步数: 4000.0000\n",
      "  episodes计数: 8.0000\n",
      "\n",
      "评估:\n",
      "  无评估数据\n",
      "\n",
      "学习者(默认策略):\n",
      "  熵: 0.3559\n",
      "  策略损失: -0.0022\n",
      "  值函数损失: 9.8233\n",
      "  总损失: 9.8210\n",
      "\n",
      "本轮时间: 19.3050\n",
      "每轮训练步数: 1\n",
      "------------------------------\n",
      "--------- 训练迭代: 50 ---------\n",
      "环境运行器:\n",
      "  episode平均回报: 458.3600\n",
      "  episode最大回报: 500.0000\n",
      "  episode平均步数: 458.4700\n",
      "  episode最大步数: 501.0000\n",
      "  采样环境总步数: 4000.0000\n",
      "  episodes计数: 8.0000\n",
      "\n",
      "评估:\n",
      "  无评估数据\n",
      "\n",
      "学习者(默认策略):\n",
      "  熵: 0.4004\n",
      "  策略损失: 0.0520\n",
      "  值函数损失: 9.7088\n",
      "  总损失: 9.7607\n",
      "\n",
      "本轮时间: 19.4415\n",
      "每轮训练步数: 1\n",
      "------------------------------\n",
      "cost time: 16.52min\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAigAAAGdCAYAAAA44ojeAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAPppJREFUeJzt3Qd8leXd//FvdsgmIYORQJC99xA3FLRIQcCqpYoWa7XoX6W11qdWq4+P+NA+arUqtlVRK6JYwYp1ICAoe2+QaRLIYGWQkH3+r+sKSYmiknCS+5yTz/v1Ot73GUl+uYk531zTz+VyuQQAAOBB/J0uAAAA4OsIKAAAwOMQUAAAgMchoAAAAI9DQAEAAB6HgAIAADwOAQUAAHgcAgoAAPA4gfJClZWVOnz4sCIjI+Xn5+d0OQAA4ByYtWELCgrUqlUr+fv7+15AMeEkOTnZ6TIAAEA9pKenq02bNr4XUEzLSfU3GBUV5XQ5AADgHOTn59sGhur3cZ8LKNXdOiacEFAAAPAu5zI8g0GyAADA49QpoPzhD3+wqefMW5cuXWqeLy4u1tSpUxUXF6eIiAhNmDBB2dnZtT5HWlqaRo8erbCwMCUkJOi+++5TeXm5+74jAADg9ercxdO9e3d9+umn//kEgf/5FPfee68++OADzZ07V9HR0brzzjs1fvx4LV++3D5fUVFhw0lSUpJWrFihzMxM3XTTTQoKCtLjjz/uru8JAAA0tYBiAokJGF+Xl5enl156SbNnz9YVV1xhH3vllVfUtWtXrVq1SkOGDNEnn3yiHTt22ICTmJioPn366L//+791//3329aZ4OBg93xXAADAq9V5DMqePXvs/OX27dtr0qRJtsvGWL9+vcrKyjRixIia15run5SUFK1cudLeN8eePXvacFJt1KhRdlTv9u3bv/VrlpSU2NeceQMAAL6rTgFl8ODBmjVrlj766CO98MILOnDggC6++GK76EpWVpZtAYmJian1MSaMmOcMczwznFQ/X/3ct5k+fbrtMqq+sQYKAAC+rU5dPFdddVXNea9evWxgadu2rd5++201a9ZMDeWBBx7QtGnTvjGPGgAA+KbzmmZsWks6deqkvXv32nEppaWlys3NrfUaM4unesyKOX59Vk/1/bONa6kWEhJSs+YJa58AAOD7ziugnDx5Uvv27VPLli3Vv39/Oxtn0aJFNc/v3r3bjlEZOnSovW+OW7duVU5OTs1rFi5caANHt27dzqcUAADQVLt4fv3rX2vMmDG2W8fsh/Pwww8rICBAN9xwgx0bMmXKFNsVExsba0PHXXfdZUOJmcFjjBw50gaRG2+8UTNmzLDjTh588EG7doppJQEAAKhzQMnIyLBh5NixY4qPj9dFF11kpxCbc+Opp56yuxOaBdrMzBszQ+f555+v+XgTZhYsWKA77rjDBpfw8HBNnjxZjz76KP8aAACghp/L7H3sZcwgWdNiY9ZeYTwKAAC+9/7tlZsFAgBgmL+xM06c0uaMXO3OKtAVXRLUN6W502XBDQgoAACvcaSgRFsycrU5I88et2Tk6Xhhac3zryw/qH/ecaE6J0U6WifOHwEFAOBRyisqlZlXrLTjRTW3/UdOamtGng7nFX/j9UEBfuqSFKWS8gp9mX1SP5u1VvOnDlN8JJMvvBkBBQDQYCorXTpVVqHCknIVlp4+lpSryJyXVp2fKCpT+hlh5NCJUyqvPPvwSD8/qUN8hHq1iVHv5Gh77JIUqdCgAJ0oLNU1zy/XwWNFuu31dXrz50Ps4/BODJIFALhVblGp5m88pLnrM7QjM1/1eZcJDvRXcvNmSokNs7fk2DB1bxWtnm2iFRHy7X9b7ztyUtc8t1z5xeX6Ue9W+vP1feRnUg08AoNkAQCN3lKyfN9RvbU2XZ9sz1ZpRWWt501GiAgOVFhIgMKDAxUeEqiw4AAbNiJDA20AqQ4jKXFhSowMlb9/3YPFBfERmvnT/rrp5TX61+bDah8frntGdHLfN4pGQ0ABANTbodxTmrsuXXPXZdjzat1aRum6gcka2T1RMc2CFRrk32gtGRd2aKHHxvXQb9/dqqc/3aPUFuEa26d1o3xtuA8BBQBQJ2UVlVq4I1tvrknTF3uP1nThmJaQcX1a22DSo3W0ozVePyhF+48W6q/L9uu+d7aoTfMw9W/L9GNvQkABAJyT7PxizV6dZoNJTkFJzeND28fZUHJljySPGpR6/5VdtP9IoT7dma3bXltnZ/aYriR4BwbJAgC+lXmLWLX/uF5fdVAfb89WxenZNS0iQnTdwDb68YBktY0Ll6cys4SunbnSDtbtlBhh10iJDA1yuqwmK78O798EFADANxQUl2nexkN6feVX2pNzsubxge2a68ah7XRl9yQ708YbZOad0ti/LLetPpd2itdLkwcoMMA7avc1BBQAQJ2Zt4Nth/L19rp0vbshw65bYpjZNuP6ttaNQ9qqa0vv/J1rVp398YsrVVxWqeFdEjSqe5J6J8eoQ0KEAuoxWwj1Q0ABAJyznPxizd90SO+sz7ArsVa7ID7chpLx/dsoyge6RT7alqnb/7Gh1mMmfJkBvb3bRNvA0rtNjNo0b8baKQ2EgAIA+E7FZRV28Og/12do6ZdHVL1wa0igv21duH5gsoZeEOdzb9RrDx633/fm9Fy7dH51K9GZYsODbVeWmQl0acf4eq3HgrMjoAAAzrqY2qaMXBtK3t982K62Ws1MwZ3Yv41G92rpE60l58IM+DV7/GxKr9p00OyIvDMzX2UV/3lbTI5tpkmD29rBwCa44PwQUAAAdr2SbYfytObAcdtysPbgCeWdKqt5vmV0qCb0a6Px/VqrfXyEo7V6CrPh4I7D+Xp/c6bmrk9XwekQZwYEX92zpX46tK36Jsf4XMtSYyGgAICXt3QcPVmi9BOnlHGiSBknTqmotNy2bEQ3+88t6oxjZEigSsortTH9RE0g2fBVrt2o7+tjLkwXjgkmpguHAaLf7lRphW1pem3VQTt4uFr3VlH66ZC2GtunlcKCWU6sLggoAOAlTJAwgSLjdBgxO/lm5J5SaXntvWy+j8kZ5q/66nVKqsWEBWlgu1gNMrfUWHVrFaUgptjWiXmb3JyRZ6dcv7/lcM2/TVRooO4e0UmTh7Zl2vI5IqAAgBf467J9evzfu741cLSMbmZnlJhl2iNCAuyYEdNFk3+qzB6rb6blpFpSVKgNIgNTYzU4NVYd4iMY5OlGJwpLbdfPP1alKe14kX2sc2KkHhnbXUPaxzldnscjoACABzO/dv/vky/1lyV77f0RXRNty4YJI8nNw+wxKTr0nFs6zIyc/OIyVVZKiVEhjI9opG64t9ala8ZHu3SiqGpcz496t9LvRndVYlSo0+V5LAIKAHjwG9sj72/Xqyu/svd/c2Vn/fKyDk6XhXrKLSrVnz7ZrTdWp9lNE8ODA/T/hnfULcNSvWal3cZEQAEAD1ReUanf/HOL3t1wSKaR49GxPexCaPB+ZrbUQ+9t04a03JpF7h75UQ9d1LGF06V5FAIKAHjg9NW7Zm/UJzuy7cyZP13bS9f0beN0WXBz69i7Gw/piQ936ujJUvvYqO6JGpQaZ2dPNQsKsLs92/PT96uPgY04Tqi0olK5RWU6Vliq44UlOnayVCeKzHlpzbl5bmzv1rp7REfH3r+ZHwUADcxMEb7ttfX6Yu9R2+z/3E/66QfdEp0uC25mBiObxe7Mv+3Tn36p11Z+ZXeANjdvlHGiahCwUwgoANCA8orKdMusNbbp3/zl/LebBmhYB5r9fZlZm+bhMd113cBkzV6dZlsrikor7GBmsy5N9bkJrmatFfPY12aHN6gAPz81Dw9SbHiIYk8f48KD1TwsWLERwYo1x/Bgu4qukwgoANBAjhSU6KaX19jl082b1qxbBqpvSnOny0Ij6ZIUZccZoX4IKIBDjp0s0e/f26bCkgo9P6mfwkP439GXHDxaqJ/NWqv9RwvVIiJEr08ZpK4tGTMHnCt+IwIOjfj/xevrdSj3lL1v+qt/N7qb02XBTZbsztHdb260C6u1jmmmN24drHYtwp0uC/AqTNIGGtm7GzI04YUVNpwkRIbYx15ebvb6yHO6NJwnMynyL4v32JYTE076pcTo3V9eSDgB6oGAAjTizrJmga5pb2+2S5Nf3jleC6ddqtE9W9r9U/5r3tZv7KMC73GypFy3/2O9/vTJl3bBrp8MTtGbtw1hVVGgnujiARqB2Zl26hsbtPrAcXv//13RQfeM6GSnJT48ppuWfXlEW+xmZAd187BUp8tFHe07ctJ22e3NOangAH89Ora7rh+U4nRZgFejBQVoYFsycvWjZ7+w4cQsgz3zp/01bWTnmg3cEqJC9Zuruthz89d3Zl7VuBR4h093ZGvcX5bbcGI26nvrF0MIJ4AbEFCABvTO+gxNnLlSh/OK1b5FuN67c5iu7JH0jddNGpSiPskxtpvgkX/tcKRW1H3VUDO4+dbX1qmgpFyD2sXq/bsuYhox4CYEFKCB3rz+8K/t+vXczSotr9SIrgmaf+cwdUiIPOvrTWvK9PE97XLXH23P0sId3rnyZFNhguRtr6/T05/usfdvvrCd3vj5YMWfHvQM4PwRUIAGmMnxu/nbNGvFQXv/nhEd9dcbBygqNOg7P86skXHrxe3t+cN2fZTyRqkXdfdf727Vpztz7LL1f7q2t/7wo+4KCuDXKeBO/B8FuDmcPPbBTr25Jk1miMmfr+9TMxj2XNw9vKPaNG9mu4SeXPhlg9eLulu8K1v/2nzY/vua9U3M3isA3I+AArjRU5/u0UtfHLDnT0zopbF9Wtfp483Opv89rmpp7FeWH2BtFA/s2nlw3jZ7PuWiVA1sF+t0SYDPIqAAbjJz6T49s6hqTMIjP+quHw9Irtfnubxzgq7u1dJuHvbAu6yN4kn+9PFu27plNlG79wednC4H8GkEFMANzPolT3y4y57/5srOmnxhu/P6fA+N6abI0EBtPZSn11ZWjWWBszakndCrp/8tHr+mp8KCWUYKaEgEFMANU4l//952e37n5R30y8s6nPfnTIgM1W+r10b5eDdrozjMzMT67T+32BVix/drrYs7xjtdEuDzCCjAefhgS6Z+885me37LsHb61Uj3NfvfMDDF7uVSWFqhh08HIDjjxaX79GX2ScWFB+v3bOoINAoCCnAesznunrPRjhW5bkCyHrq6m/z8zm22zrmoWhull10b5ZMd2fpoW6bbPjfOnVkh9tnFe2u63pqHBztdEtAkEFCAelix96hu/8cGlVe6NKZ3Kz0+vqdbw0m1zkmR+sWlVWujPDh/u3KLSt3+NfDdC+6ZNU9KKyp1Wed4/ah3K6dLApoMAgpQR19mF9jlzatWiE3Ukz/urYBzXOekPu66oqM6JETYDQcfXcAy+I3pzbVpWnPwuMKCA/TYuB4NEkIBnB0BBaijx/+9U0WlFRraPk5/+UnfBl9BNDQoQDMm9pJ5b3x3wyEt2ZXToF8PVbLyivXEv6tmZt03qrPaNA9zuiSgSSGgAHWwYt9Rfbb7iB0XYvbOMeGhMfRLaa4pw1Lt+X/N26r84rJG+bpN2cP/2mY3ATSbON409PymjQOoOwIKUIdl7KvXOpk0OEXtWoQ36tf/1cjOahsXpsy8Yk3/985G/dpNjRmQ/PH2bBtEn5jQs0G78ACcHQEFOEcfbM3Ulow8hQcH6K7hHRv965tl8P93Qi97/uaadH2x52ij19AU5J0q00Onp3XfcdkF6pIU5XRJQJNEQAHOgRkQ+8ePd9vz2y65QC0iQhypY0j7ON04pK09/+27W9jxuAFayR7513blFJSofXy4pl5+/ovuAagfAgpwDuasTdNXx4psMLn14qqxIE65/6ouah3TTBknTtWEJrjH3z7fr3c3HrI7FT8xvlejjTEC8E0EFOAcdrD986dVmwDePaKjwkOc3YMlIiTQjoswZq04qDUHjjtaj6/4dEe2pp8eY2QW3RuUyk7FgJMIKMD3+Nuy/TpWWKrUFuG6fmD9dih2N7MXjFm91rj/n1t0qrTC6ZK82s7MfLsqsNlrxwyAPt/NHgGcPwIK8B1yCopts3/1WhgNveZJXfzX6K5KjArRgaOFeurTL50ux2sdKSjRra+us3seDesQpz/8qDsLsgEewHN+2wIe6NlFe+2ibL2TY3RVjyR5kuhmQXr8mqqunr9/vl8b0044XZLXKS6r0C9eX6dDuafUvkW4nv9Jf48KoUBT5mxnOuDBTMvEm2vS7PkDV3XxyL+qh3dN1Lg+rTR/02H95p0teuCHXXSisEwnikqVW1R1tLfTjxUUl6tryyiN6p5ol+mvz8Z3ZqaLuTbpJ07Z2U3mVlZRdSw5fay+hQT566IOLdS9VZTHXT/zffz2n1u0IS1XUaGB+vvkAYoOC3K6LACnEVCAb/Gnj3fbzQAv7xxvp/d6qofHdNcXe49qT85J/WzWuu99vWkt+HRntl18bHBqrEZ1T9LI7olqGd3sW9/I9x8t1Kr9x7Rq/3Gt3n/MTsOtC9MVdUWXBF3RJdF2o4QFO/+r5/nP9tlgZ67DCz/tr/bxEU6XBOAMfi7z28fL5OfnKzo6Wnl5eYqKYhEluN+m9FyNe2653f/mw7sv9vjFupZ+eUSPLdhhp8XGhAWpeViwmocFKeb00bSUmPPQQH+t3H/MrpJqBoaeyXRjmZYVE1jMb4WqQHJMqw8ct+M0zhQc6G+7RMzXCw7wt/ftLcBfQaeP5r75OLM9gOkmO/NjL7wgTsO7JOjyLgmO7HHz4dZM3fHGBnv+P9f00KTBVWvLAPCc928CCvA15n+J6/+6yr4xT+jXRv/3497yRWnHivTx9ix9tD1LG9JO2FDybUyo6JcSY1uSzM3sT3Oua4SUlFdo9f7jWrwrx7bcmPVbztQ5MVI3DErWtQOSG2UK97ZDeZo4c4WKyyp184Xt7KBYAI2DgAKcB7Nb8C2z1to35SW/vswuitYUZist3JGtj7ZlaeW+Y7bbw2xQWBVIYm3rijsWLTO/bvbmnNSiXTlavDNH6746rsrTv4HMOJCfDmlrQ0NCVKgaQnZ+scb+Zbmy8ot1Sad4vTx5gAIZFAs0GgIKUE8VlS6NfuZz7coq0G2XtNd//bCrmhqzpoq/vxQS2PCrqOYWler9LZl6+YsDduCtERTgp7F9WtsVe8+3a616QK/p1jLBa8W+YzpeWKoOCRF695cXKiqUQbFAYyKgAPX0z/UZ+tXczfav+WW/udyO20DDq6x02e4fs+bM2oP/mS59cccWNiiamUDnMgvI/DpLO15kw4gZP2OCSXZ+7fEzLaNDNee2IWob17i7UQNQnd6/z6vD94knntADDzygu+++W08//bR9rLi4WL/61a80Z84clZSUaNSoUXr++eeVmJhY83FpaWm64447tGTJEkVERGjy5MmaPn26AgOdH9mPpsuMlXhyYdWCZ3dc1oFw0oj8/f000s4mSrLrufz98wP6cFumPt9z1N66JEXa6dEmgJguoUqXy46ZOfNoWr/MwN/DecW1PrcZsNs3JUZDL6gaP2POG6N1CMD5qXciWLt2rV588UX16lW1/Xu1e++9Vx988IHmzp1rU9Kdd96p8ePHa/ny5fb5iooKjR49WklJSVqxYoUyMzN10003KSgoSI8//vh5fjtA/c1Zk26n4CZEhthxEHBG35Tmem5Sc6UfL9JLXxzQ2+vSbZebuZ2LQH8/O4jXBJKh7ePUr21zNv0DvFC9unhOnjypfv362ZaRxx57TH369LEtKKbJJj4+XrNnz9bEiRPta3ft2qWuXbtq5cqVGjJkiD788ENdffXVOnz4cE2rysyZM3X//ffryJEjCg7+/r9a6eKBuxWVluuSGZ/p6MkSPTauhx2sCc+QV1Smf2/L1Mnicjvt29/Pr+Zodh02XT/Vj5kBzQPaNfeIdVYAONDFM3XqVNsKMmLECBtQqq1fv15lZWX28WpdunRRSkpKTUAxx549e9bq8jHdQKbLZ/v27erbt+83vp7pKjK3M79BwJ1eWX7QhpOU2DD9+PQmfPAMZnXXGwalOF0GgEZW54BixpZs2LDBdvF8XVZWlm0BiYmJqfW4CSPmuerXnBlOqp+vfu5szPiURx55pK6lAuf8F/qLS/fZ82k/6GSnFwMAnFWn38Tp6el2QOwbb7yh0NCGWafgbMxAXNMcVH0zdQDu8uKyfcovLrcLho3p3crpcgAAdQ0opgsnJyfHjj8xM27MbenSpXrmmWfsuWkJKS0tVW5ubq2Py87OtoNiDXM097/+fPVzZxMSEmL7qs68Ae5aoMx07xi/HtXZLlAGAPCygDJ8+HBt3bpVmzZtqrkNGDBAkyZNqjk3s3EWLVpU8zG7d++204qHDh1q75uj+Rwm6FRbuHChDR3dunVz5/cGfK/nFu/VqbIKO+tjRNcEp8sBANRnDEpkZKR69OhR67Hw8HDFxcXVPD5lyhRNmzZNsbGxNnTcddddNpSYAbLGyJEjbRC58cYbNWPGDDvu5MEHH7QDb01LCdBYzDTW2WvS7PlvRnU+p4XAAACNw+1z8Z566in5+/trwoQJtRZqqxYQEKAFCxbYWTsmuJiAYxZqe/TRR91dCvCdnv50j8oqXHaV0gs7tHC6HADAGVjqHk3SnuwCjXp6mV2VdP7UYbaLBwDgOe/fzKdEk/R/n3xpw8mo7omEEwDwQAQUNDmb03P10fYsu/Lor0Z2drocAMBZEFDQ5Pzpk932eE3f1uqUGOl0OQCAsyCgoElZsa9qd9ygAD/dO6KT0+UAAL4FAQVNhhkP/sePq1pPzN4uybFhTpcEAPgWBBQ0GYt25mhjWq5Cg/x15+UdnC4HAPAdCChoEkrKKzT9w532/OYLU5UQ1Xh7SQEA6o6AgibhxaX7te9IoVpEhOiOSy9wuhwAwPcgoMDn7T9yUn9ZsteePzSmm6LDgpwuCQDwPQgo8PmBsb+bt02l5ZW6pFO8xvRq6XRJAIBzQECBT3t3wyGt3H/MDox9bGwPNgQEAC9BQIHPOl5Yqsc+2GHP7x7eSSlxTCsGAG9BQIHPevzfO3WiqEydEyN168WpTpcDAKgDAgp80sp9x/TO+gy7387j43sqKIAfdQDwJvzWhs8pLqvQ7+ZtteeTBqeof9vmTpcEAKgjAgp8zguf7dP+o4WKjwzRfaO6OF0OAKAeCCjwKXtzTtqAYjxs1jxpxponAOCNCCjwsTVPtqq0olKXd47X6J6seQIA3oqAAp8xd32GVh84btc8eZQ1TwDAqxFQ4BOOnSyx04qNe0d0UnIsa54AgDcjoMAn/M+/dyq3qExdW0bpZxex5gkAeDsCCrxe+vEizdt4yJ4/fk0P1jwBAB/Ab3J4vbfWpsvlki7q0EJ9U1jzBAB8AQEFXq2solJvr0u35zcMSnG6HACAmxBQ4NUW78pRTkGJ4sKD9YNuiU6XAwBwEwIKvNqba9LsceKANgoO5McZAHwFv9HhtTJOFGnpl0fs+Q0D6d4BAF9CQIHXevv04NhhHeLUrkW40+UAANyIgAKvVF5RqbcYHAsAPouAAq8dHJudXzU4dmS3JKfLAQC4GQEF3j04tj+DYwHAF/GbHV7nUO4pfXZ6cOx1A5OdLgcA0AAIKPDalWOHto9T+/gIp8sBADQAAgq8bnCsmb1j/GQwg2MBwFcRUOBVPtt9RFn5xYo1g2O7s3IsAPgqAgq8dnBsSGCA0+UAABoIAQVe43DuKS3ZnWPPr2dwLAD4NAIKvIbZtbjSJQ1pH8vgWADwcQQUeM/KsacHx7JyLAD4PgIKvILZFDAzr1jNw4J0ZQ9WjgUAX0dAgVdgcCwANC0EFHi8zLxTdu8d43q6dwCgSSCgwOO9vTbDDo4dnBqrCxgcCwBNAgEFHq2i0qW31lZ177ByLAA0HQQUeLSFO7J0OK9YMWFBGtWdwbEA0FQQUOCxXC6XZi7db89vHNJWoUEMjgWApoKAAo+19uAJbUrPVXCgv24a2s7pcgAAjYiAAo/14tJ9NVOL4yNDnC4HANCICCjwSHuyC7RoV478/KSfX9ze6XIAAI2MgAKP9NdlVWNPRnVLUmqLcKfLAQA0MgIKPE5WXrHmbzpkz39xKa0nANAUEVDgcV5ZcUBlFS4NahervinNnS4HAOAAAgo8Sn5xmWavqlqYjdYTAGi6CCjwKG+uTlNBSbk6JETo8s4JTpcDAHAIAQUeo7S8Ui8vP2DPb7ukvfz9/ZwuCQDgEAIKPMZ7mw4pO79EiVEhGtunldPlAAAcRECBR6isdNVMLb5lWKpCAlnWHgCaMgIKPMJnX+ZoT85JRYQEsmsxAICAAs9QvSmgCSdRoUFOlwMAcBgBBY7bmHZCaw4cV1CAn24ZxqaAAAACCjxA9diTH/VurZbRzZwuBwDgbQHlhRdeUK9evRQVFWVvQ4cO1YcffljzfHFxsaZOnaq4uDhFRERowoQJys7OrvU50tLSNHr0aIWFhSkhIUH33XefysvL3fcdwascOFqoj7Zn1UwtBgCgzgGlTZs2euKJJ7R+/XqtW7dOV1xxhcaOHavt27fb5++99169//77mjt3rpYuXarDhw9r/PjxNR9fUVFhw0lpaalWrFihV199VbNmzdJDDz3Ev0YT9ffP98vlkq7okqDOSZFOlwMA8BB+Lpd5e6i/2NhY/fGPf9TEiRMVHx+v2bNn23Nj165d6tq1q1auXKkhQ4bY1parr77aBpfExET7mpkzZ+r+++/XkSNHFBwcfE5fMz8/X9HR0crLy7MtOfBOR0+W6MInFtsF2ubcNkRD2sc5XRIAoAHV5f273mNQTGvInDlzVFhYaLt6TKtKWVmZRowYUfOaLl26KCUlxQYUwxx79uxZE06MUaNG2YKrW2HOpqSkxL7mzBu83yvLD9hw0rtNtAanxjpdDgDAg9Q5oGzdutWOLwkJCdHtt9+uefPmqVu3bsrKyrItIDExMbVeb8KIec4wxzPDSfXz1c99m+nTp9vEVX1LTk6ua9nwwE0BX1vxlT2/47IO8vNjWXsAwHkElM6dO2vTpk1avXq17rjjDk2ePFk7duyo66epkwceeMA2B1Xf0tPTG/TroeG9vvIruylgx4QIjexWO7QCABBY1w8wrSQdOnSw5/3799fatWv15z//Wdddd50d/Jqbm1urFcXM4klKSrLn5rhmzZpan696lk/1a87GtNaYG3zDqdIKvfRF1aaAv7z8AjYFBAC4fx2UyspKO0bEhJWgoCAtWrSo5rndu3fbacVmjIphjqaLKCcnp+Y1CxcutANlTDcRmoY316TpeGGpkmObaUwvNgUEAJxnC4rparnqqqvswNeCggI7Y+ezzz7Txx9/bMeGTJkyRdOmTbMze0zouOuuu2woMTN4jJEjR9ogcuONN2rGjBl23MmDDz5o106hhaRpMINiqxdmu/3SCxQYwFqBAIDzDCim5eOmm25SZmamDSRm0TYTTn7wgx/Y55966in5+/vbBdpMq4qZofP888/XfHxAQIAWLFhgx66Y4BIeHm7HsDz66KN1KQNebN7GDGXlFyshMkQT+7dxuhwAgK+ug+IE1kHxTuUVlRrx5FIdPFakB0d31a0Xs3IsADQl+Y2xDgpQV//elmXDSfOwIN0wKMXpcgAAHoyAgkZRWenS80v22vNbhqUqPKTOE8gAAE0IAQWNYvGuHO3KKlBESKAmD23ndDkAAA9HQEGDM8Oc/nK69eSnQ9oqOizI6ZIAAB6OgIIGt3LfMW1Kz1VIoL+mXJTqdDkAAC9AQEGDe+6zqtaT6wcmKz6S9W4AAN+PgIIGtTHthJbvPaZAfz/ddukFTpcDAPASBBQ0qOeW7LPHa/q2VuuYZk6XAwDwEgQUNJhdWfn6dGe2/Pyk2y+j9QQAcO4IKGgwz59uPflhz5a6ID7C6XIAAF6EgIIGcfBooRZsOWzPf0nrCQCgjggoaBAvLz+gSpd0RZcEdW8V7XQ5AAAvQ0CB25WUV+hfm6taT26+kFVjAQB1R0CB2y3ZdUS5RWVKjArRsA4tnC4HAOCFCChwu39uyLDHcX1bK8Dfz+lyAABeiIACtzpeWKolu3Ls+YR+bZwuBwDgpQgocKv3Nx9WeaVLPVtHq1NipNPlAAC8FAEFDdK9M75fa6dLAQB4MQIK3GZPdoG2ZOTZfXd+1LuV0+UAALwYAQVu8+7GQ/Z4WecExUWwazEAoP4IKHCLikqX5p8OKBPo3gEAnCcCCtxi5b5jyswrVlRooK7omuB0OQAAL0dAgVu8e3pw7JjerRQSGOB0OQAAL0dAwXkrLCnXh9uy7PmE/qx9AgA4fwQUnDcTTk6VVSi1Rbj6Jsc4XQ4AwAcQUOC27p3xfVvLz4+l7QEA54+AgvNyKPeUVu4/VrP3DgAA7kBAwXkxU4tdLmlI+1glx4Y5XQ4AwEcQUFBvLpfrjKXtGRwLAHAfAgrqbXNGnvYfKVRokL+u6pHkdDkAAB9CQMF5D469snuSIkODnC4HAOBDCCiol5LyCv1r82F7TvcOAMDdCCiolyW7jii3qEwJkSEa1qGF0+UAAHwMAQXn1b1zTd/WCvBn7RMAgHsRUFBnxwtLtWR3jj2newcA0BAIKKiz9zcfVlmFSz1aR6lzUqTT5QAAfBABBXVWs/ZJX1pPAAANg4CCOtmZma8tGXkKCvDT2D6tnC4HAOCjCCiok7fWptvjiK6JiosIcbocAICPIqCgTmufzN90yJ7/eGCy0+UAAHwYAQXnbOGObLv2ScvoUF3SMd7pcgAAPoyAgjp370zs34a1TwAADYqAgnOScaJIX+w9as+v7U/3DgCgYRFQcE7eWZ8hl0sa2j5OKXFhTpcDAPBxBBR8r8pKl+auq1r75DoGxwIAGgEBBd9rxb5jOpR7SpGhgbqyR5LT5QAAmgACCr7XW+uqBseO69NaoUEBTpcDAGgCCCj4TrlFpfp4e5Y9//EAuncAAI2DgILvNH/jIZWWV6pryyi7OSAAAI2BgILv9Hb14NgBbeTnx9onAIDGQUDBt9p2KE87MvMVHOivcX1bO10OAKAJIaDge1eOHdU9STFhwU6XAwBoQggoOKvisv9sDHgdg2MBAI2MgIKz+mhblgqKy9U6ppkuvCDO6XIAAE0MAQVn9fbptU+uHdBG/mwMCABoZAQUfEPasSK7eqyZtHMt3TsAAAcQUPANc9dXtZ5c1KGF7eIBAKCxEVBQS0Wly+5cbLAxIADAKQQU1LJszxFl5hUrJixIP+iW6HQ5AIAmioCCWuaesTFgSCAbAwIAnEFAQY2jJ0u0cEe2Pad7BwDgNQFl+vTpGjhwoCIjI5WQkKBx48Zp9+7dtV5TXFysqVOnKi4uThEREZowYYKys6ve9KqlpaVp9OjRCgsLs5/nvvvuU3l5uXu+I9Tb3HUZKqtwqXdyjN0cEAAArwgoS5cuteFj1apVWrhwocrKyjRy5EgVFhbWvObee+/V+++/r7lz59rXHz58WOPHj695vqKiwoaT0tJSrVixQq+++qpmzZqlhx56yL3fGeqkstKlN9ek2fNJg1KcLgcA0MT5uVwuV30/+MiRI7YFxASRSy65RHl5eYqPj9fs2bM1ceJE+5pdu3apa9euWrlypYYMGaIPP/xQV199tQ0uiYlVgzBnzpyp+++/336+4ODv3/MlPz9f0dHR9utFRfGXvjt8vueIbnxpjSJDArX6d8MVFhzodEkAAB9Tl/fv8xqDYr6AERsba4/r16+3rSojRoyoeU2XLl2UkpJiA4phjj179qwJJ8aoUaNs0du3bz/r1ykpKbHPn3mDe81eXdV6ck2/1oQTAIDj6h1QKisrdc8992jYsGHq0aOHfSwrK8u2gMTExNR6rQkj5rnq15wZTqqfr37u28a+mMRVfUtOZgCnO+UUFNcMjv3JYLp3AABeHFDMWJRt27Zpzpw5amgPPPCAba2pvqWnV02FhfsGx5ZXutQvJUZdkugyAwA4r15t+XfeeacWLFigZcuWqU2bNjWPJyUl2cGvubm5tVpRzCwe81z1a9asWVPr81XP8ql+zdeFhITYGxp2cOxPBrd1uhwAAOregmLG05pwMm/ePC1evFipqam1nu/fv7+CgoK0aNGimsfMNGQzrXjo0KH2vjlu3bpVOTk5Na8xM4LMYJlu3brVpRy4gVk5NuPEKUWFBurqXi2dLgcAgLq3oJhuHTND57333rNroVSPGTHjQpo1a2aPU6ZM0bRp0+zAWRM67rrrLhtKzAwew0xLNkHkxhtv1IwZM+znePDBB+3nppXEucGx4/u1UWgQK8cCALwwoLzwwgv2eNlll9V6/JVXXtHNN99sz5966in5+/vbBdrM7BszQ+f555+veW1AQIDtHrrjjjtscAkPD9fkyZP16KOPuuc7wjnLzi/Wol1VLVmTGBwLAPCVdVCcwjoo7vHMoj16cuGXGtiuuebefqHT5QAAfFx+Y62DAu9VUenSnJrBsbSeAAA8CwGliVr6ZY4O5xUrJixIV/VgcCwAwLMQUJr44NgJDI4FAHggAkoTdDj3lBafHhx7AxsDAgA8EAGlCXprbboqXdLg1Fh1SIhwuhwAAL6BgNLElFdU2oBiMDgWAOCpCChNzJLdR5SVX6zY8GBd2ePsWwsAAOA0AkoTM3v1V/Y4sX8bhQQyOBYA4JkIKE1IxokiffblEXvO4FgAgCcjoDQhZuyJWTf4wgvilNoi3OlyAAD4VgSUJqKMwbEAAC9CQGkiPtt9RDkFJYoLD9bIbgyOBQB4NgJKE/HO+qrWk/H9Wis4kH92AIBn452qCTh2skSLdlatHDuxf7LT5QAA8L0IKE3A/E2HVV7pUq820eqcFOl0OQAAfC8CShPwzvoMe7y2fxunSwEA4JwQUHzctkN52pmZr+AAf43p3crpcgAAOCcElCbSevKD7omKCQt2uhwAAM4JAcWHlZRXaP6mQ/ac7h0AgDchoPiwxTtzlFtUpsSoEF3cMd7pcgAAOGcEFB8293T3zvh+bRTg7+d0OQAAnDMCio/KyS/W0tMbA5qdiwEA8CYEFB81b+MhVVS61C8lRhfERzhdDgAAdUJA8UEul6ume+faAawcCwDwPgQUH7Q5I097c04qNMhfo3u1dLocAADqjIDig+auq9oY8MruSYoKDXK6HAAA6oyA4mOKyyr0r82H7TndOwAAb0VA8TGf7MhWQXG5Wsc009D2cU6XAwBAvRBQfLR7Z0K/1vJn7RMAgJcioPiQw7mn9MXeo/Z8Yn+6dwAA3ouA4mNrn7hc0uDUWKXEhTldDgAA9UZA8aW1T05377ByLADA2xFQfMT6r07o4LEihQUH6Ic9WfsEAODdCCg+Yu66qpVjR/dsqfCQQKfLAQDgvBBQfEBRabkWbKla+4TuHQCALyCg+IAFWzJVWFqhtnFhGpQa63Q5AACcNwKKDwyOffmLA/b8hkEp8vNj7RMAgPcjoHg5s+7JrqwCOzjWBBQAAHwBAcXL/e3zqtaTHw9IVnQzNgYEAPgGAooX251VoGVfHpFZ0f5nw1KdLgcAALchoHixl77Yb4+juiexciwAwKcQULxUTkGx5m+smlp868XtnS4HAAC3IqB4qX+s/EqlFZXqmxKj/m2bO10OAABuRUDxQqdKK/T6qq/s+c9pPQEA+CACihd6d2OGThSVKTm2mR1/AgCAryGgeJnKSpdeOj21+JYLUxVgpvAAAOBjCCheZvGuHO0/WqjI0ED9eGCy0+UAANAgCChe5u+npxb/ZFCKIti1GADgowgoXmTboTyt2n9cgf5+unlYO6fLAQCgwRBQvMjfPq9qPRndq6VaRjdzuhwAABoMAcVLHM49pQ+2ZNrzWy9iajEAwLcRULzEqysOqrzSpcGpserZJtrpcgAAaFAEFC9wsqRcs9ek2XMWZgMANAUEFC/w9tp0FRSXq32LcF3RJcHpcgAAaHAEFA9XXlGpl5dXLcz2s4tS5c/CbACAJoCA4uE+2ZGtjBOn1DwsSBP6tXG6HAAAGgUBxcPNWnHQHicNbqtmwQFOlwMAQKMgoHiwL7MLtObAcbvfzqQhKU6XAwBAoyGgeLA3Vn1lj8O7JLAwGwCgSSGgeKjCknK9u+GQPf/pkLZOlwMAQKMioHio9zcfVkFJudrGhemiDi2cLgcAAM8OKMuWLdOYMWPUqlUr+fn5af78+bWed7lceuihh9SyZUs1a9ZMI0aM0J49e2q95vjx45o0aZKioqIUExOjKVOm6OTJk+f/3fgIcw3/sfqrml2LmVoMAGhq6hxQCgsL1bt3bz333HNnfX7GjBl65plnNHPmTK1evVrh4eEaNWqUiouLa15jwsn27du1cOFCLViwwIae22677fy+Ex+yOSNP2w7lKzjQX9cOSHa6HAAAGl1gXT/gqquusrdv+8v/6aef1oMPPqixY8fax1577TUlJibalpbrr79eO3fu1EcffaS1a9dqwIAB9jXPPvusfvjDH+pPf/qTbZlp6v5xenDs6J4tFRse7HQ5AAB49xiUAwcOKCsry3brVIuOjtbgwYO1cuVKe98cTbdOdTgxzOv9/f1ti8vZlJSUKD8/v9bNV+UVldnxJ8ZPmVoMAGii3BpQTDgxTIvJmcz96ufMMSGh9n4ygYGBio2NrXnN102fPt0GnepbcrLvdnu8syFDJeWV6pIUqX4pzZ0uBwAAR3jFLJ4HHnhAeXl5Nbf09HT5ItNF9sbpwbGThrS1g5ABAGiK3BpQkpKS7DE7O7vW4+Z+9XPmmJOTU+v58vJyO7On+jVfFxISYmf8nHnzRSv3HdP+I4UKDw7QNX1bO10OAAC+EVBSU1NtyFi0aFHNY2a8iBlbMnToUHvfHHNzc7V+/fqa1yxevFiVlZV2rEpTVj21eFzf1ooIqfP4ZQAAfEad3wXNeiV79+6tNTB206ZNdgxJSkqK7rnnHj322GPq2LGjDSy///3v7cyccePG2dd37dpVV155pX7+85/bqchlZWW688477QyfpjyDJye/WJ9sr2p5YuVYAEBTV+eAsm7dOl1++eU196dNm2aPkydP1qxZs/Sb3/zGrpVi1jUxLSUXXXSRnVYcGhpa8zFvvPGGDSXDhw+3s3cmTJhg105pyt5am67ySpf6t22uri19swsLAIBz5ecyIzO9jOk2MrN5zIBZXxiPUlHp0sX/u1iH84r11HW9dU3fNk6XBACAo+/fXjGLx9ct3pVjw0nzsCBd1aOl0+UAAOA4AooHrRxrlrUPDQpwuhwAABxHQHFY2rEiLdtzpGZjQAAAQEBx3Ow1aTKjgC7u2ELtWoQ7XQ4AAB6BgOKgkvIKvb2ualVcphYDAPAfBBQHfbQtS8cLS5UUFarhXWrvTwQAQFNGQHHQayurBsdePyhZgQH8UwAAUI13RYesO3hc6786oeAAfwbHAgDwNQQUh8xcus8ex/drrYSo/6yyCwAACCiO+DK7QJ/uzJGfn3TbJe2dLgcAAI9DQHHAi0v32+OobklqHx/hdDkAAHgcAkojy8w7pfc2HbLnv7iU1hMAAM6GgNLIXvr8gN21eHBqrPqmNHe6HAAAPBIBpRHlFZXpzTVp9vz2yy5wuhwAADwWAaURvb7qoApLK9QlKVKXdYp3uhwAADwWAaWRFJdV6JXlB+357ZdeID8zhQcAAJwVAaWRzF2foWOFpWod00yje7V0uhwAADwaAaURVFS69LdlVVOLb704VUEsaw8AwHfinbIRfLgtU2nHi9Q8LEjXDUx2uhwAADweAaWBuVyummXtbxraTmHBgU6XBACAxyOgNLDle49p26F8hQb5a/KF7ZwuBwAAr0BAaWDVrSfXD0xRbHiw0+UAAOAVCCgNaNuhPH2x96gC/P005aJUp8sBAMBrEFAaofVkTK+WSo4Nc7ocAAC8BgGlgXx1rFD/3pppz2+7hGXtAQCoCwJKA/nb5/tV6ZIu7RSvbq2inC4HAACvQkBpACv2HdVba9NrlrUHAAB1Q0Bxs705Bbr99fUqq3BpTO9WGtI+1umSAADwOgQUNzp6skS3zFqr/OJy9W/bXH+c2ItNAQEAqAcCiht3K7711XVKP35KbePC9LebBig0KMDpsgAA8EoEFDeorHTp3rc2aVN6rqKbBemVmweyKBsAAOeBgOIG//vRLn24LUvBAf7664391T4+wumSAADwagSU8/TG6q/04rL99nzGxF4a3D7O6ZIAAPB6BJTz8NnuHD303nZ7Pu0HnTSub2unSwIAwCcQUOppZ2a+7py9URWVLk3o10Z3XdHB6ZIAAPAZBJR6yM4v1s9mrdXJknK7zsn08T2ZTgwAgBsRUOroVGmFpry6Vpl5xbogPlwv/nSAggO5jAAAuBPvrHX00HvbtO1QvuLCg/XKzYMUHRbkdEkAAPgcAkodzF2XrrnrM+TvJz37k75KiQtzuiQAAHwSAeUc7c4q0O/f22bP7x3RSRde0MLpkgAA8FkElHNQWFKuX76xXsVllbq4YwtNvZwZOwAANCQCyvdwuVz63byt2nekUElRoXr6uj7yN308AACgwRBQvsectemav+mwAvz97LiTuIgQp0sCAMDnEVC+w/bDeXr4X1Urxf56ZGcNbBfrdEkAADQJBJRvUVBcpqlvbFBpeaWu6JKgX1zS3umSAABoMggo3zLu5Lf/3KqDx4rUKjpU/3dtb8adAADQiAgoZ/H6qq/0wdZMBfr76S+T+ql5eLDTJQEA0KQQUL5mS0auHluw057/9qou6pfS3OmSAABocggoZ8g7VaapszeotKJSI7slaspFqU6XBABAk0RAOcP/fbJb6cdPqU3zZvrjxN7sUAwAgEMCnfrCnujXozrrRFGZbr0olU0AAQBwEAHlDFGhQXr2hr5OlwEAQJNHFw8AAPA4BBQAAOBxCCgAAMDjEFAAAIDHIaAAAACPQ0ABAAAeh4ACAAA8DgEFAAB4HAIKAADwOI4GlOeee07t2rVTaGioBg8erDVr1jhZDgAAaOoB5a233tK0adP08MMPa8OGDerdu7dGjRqlnJwcp0oCAABNPaA8+eST+vnPf65bbrlF3bp108yZMxUWFqaXX37ZqZIAAEBTDiilpaVav369RowY8Z9C/P3t/ZUrV37j9SUlJcrPz691AwAAvsuR3YyPHj2qiooKJSYm1nrc3N+1a9c3Xj99+nQ98sgj33icoAIAgPeoft92uVyeGVDq6oEHHrDjVaodOnTIdgslJyc7WhcAAKi7goICRUdHe15AadGihQICApSdnV3rcXM/KSnpG68PCQmxt2oRERFKT09XZGSk/Pz83J7uTPAxnz8qKsqtnxvfxPVuXFzvxsX1blxcb8+/3qblxISTVq1afe9rHQkowcHB6t+/vxYtWqRx48bZxyorK+39O++883s/3oxXadOmTYPWaC42P+CNh+vduLjejYvr3bi43p59vb+v5cTxLh7TZTN58mQNGDBAgwYN0tNPP63CwkI7qwcAADRtjgWU6667TkeOHNFDDz2krKws9enTRx999NE3Bs4CAICmx9FBsqY751y6dBqTGetiFo87c8wLGg7Xu3FxvRsX17txcb1963r7uc5lrg8AAEAjYrNAAADgcQgoAADA4xBQAACAxyGgAAAAj0NAOcNzzz2ndu3aKTQ0VIMHD9aaNWucLsknLFu2TGPGjLErB5qVf+fPn1/reTNO20w3b9mypZo1a2Y3jdyzZ49j9Xo7s3fVwIED7UrLCQkJdjHE3bt313pNcXGxpk6dqri4OLsy84QJE76xsjPOzQsvvKBevXrVLFY1dOhQffjhhzXPc60b1hNPPGF/r9xzzz01j3HN3ecPf/iDvb5n3rp06dIo15qActpbb71lF48zU6Y2bNig3r17a9SoUcrJyXG6NK9nFuAz19MEwLOZMWOGnnnmGc2cOVOrV69WeHi4vfbmBx91t3TpUvsLY9WqVVq4cKHKyso0cuRI++9Q7d5779X777+vuXPn2tcfPnxY48ePd7Rub2VWtTZvkmaH9nXr1umKK67Q2LFjtX37dvs817rhrF27Vi+++KINiGfimrtX9+7dlZmZWXP74osvGudam2nGcLkGDRrkmjp1as39iooKV6tWrVzTp093tC5fY37k5s2bV3O/srLSlZSU5PrjH/9Y81hubq4rJCTE9eabbzpUpW/Jycmx133p0qU11zcoKMg1d+7cmtfs3LnTvmblypUOVuo7mjdv7vr73//OtW5ABQUFro4dO7oWLlzouvTSS1133323fZxr7l4PP/ywq3fv3md9rqGvNS0okkpLS+1fP6Zr4cz9fsz9lStXOlqbrztw4IBdSfjMa2/2aTBdbFx798jLy7PH2NhYezQ/66ZV5cxrbppsU1JSuObnqaKiQnPmzLGtVaarh2vdcEwr4ejRo2tdW4Nr7n6my9100bdv316TJk1SWlpao1xrR1eS9RRHjx61v1i+vsy+ub9r1y7H6moKTDgxznbtq59D/ZlNOE3f/LBhw9SjRw/7mLmuZsPOmJiYWq/lmtff1q1bbSAx3ZKmH37evHnq1q2bNm3axLVuACYEmq5408Xzdfx8u5f5Y3HWrFnq3Lmz7d555JFHdPHFF2vbtm0Nfq0JKICP/5VpfpGc2WcM9zO/vE0YMa1V77zzjt0I1fTHw/3S09N199132/FVZkIDGtZVV11Vc27G+pjA0rZtW7399tt2UkNDootHUosWLRQQEPCNkcfmflJSkmN1NQXV15dr735mn6sFCxZoyZIldiBnNXNdTbdmbm5urddzzevP/BXZoUMH9e/f386iMoPC//znP3OtG4DpVjCTF/r166fAwEB7M2HQDLQ35+avd655wzGtJZ06ddLevXsb/OebgHL6l4v5xbJo0aJaTePmvmm2RcNJTU21P8hnXvv8/Hw7m4drXz9mLLIJJ6abYfHixfYan8n8rAcFBdW65mYasulX5pq7h/n9UVJSwrVuAMOHD7ddaqbFqvo2YMAAOzai+pxr3nBOnjypffv22WUhGvzn+7yH2fqIOXPm2Jkjs2bNcu3YscN12223uWJiYlxZWVlOl+YTo+03btxob+ZH7sknn7TnX331lX3+iSeesNf6vffec23ZssU1duxYV2pqquvUqVNOl+6V7rjjDld0dLTrs88+c2VmZtbcioqKal5z++23u1JSUlyLFy92rVu3zjV06FB7Q9399re/tTOkDhw4YH9+zX0/Pz/XJ598Yp/nWje8M2fxGFxz9/nVr35lf5eYn+/ly5e7RowY4WrRooWdHdjQ15qAcoZnn33WXujg4GA77XjVqlVOl+QTlixZYoPJ12+TJ0+umWr8+9//3pWYmGhD4vDhw127d+92umyvdbZrbW6vvPJKzWtM+PvlL39pp8OGhYW5rrnmGhtiUHc/+9nPXG3btrW/N+Lj4+3Pb3U4MbjWjR9QuObuc91117latmxpf75bt25t7+/du7dRrrWf+c/5t8MAAAC4D2NQAACAxyGgAAAAj0NAAQAAHoeAAgAAPA4BBQAAeBwCCgAA8DgEFAAA4HEIKAAAwOMQUAAAgMchoAAAAI9DQAEAAB6HgAIAAORp/j887t4ZolxLsQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "config = (\n",
    "    PPOConfig()\n",
    "    .api_stack(\n",
    "        enable_rl_module_and_learner=True,\n",
    "        enable_env_runner_and_connector_v2=True,\n",
    "    )\n",
    "    .api_stack(\n",
    "        enable_rl_module_and_learner=True,\n",
    "        enable_env_runner_and_connector_v2=True,\n",
    "    )\n",
    "    .environment(\"CartPole-v1\")\n",
    "    .env_runners(num_env_runners=0)\n",
    ")\n",
    "\n",
    "algo = config.build()\n",
    "t = time.time()\n",
    "mean_returns = []\n",
    "for i in range(50):\n",
    "    result = simplify_rllib_metrics(algo.train())\n",
    "    mean_returns.append(result[\"环境运行器\"][\"episode平均回报\"])\n",
    "\n",
    "print(f\"cost time: {((time.time() - t)/60):.2f}min\")\n",
    "pd.Series(mean_returns).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模拟参数服务器训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-18 19:15:14,463\tWARNING rl_module.py:427 -- Could not create a Catalog object for your RLModule! If you are not using the new API stack yet, make sure to switch it off in your config: `config.api_stack(enable_rl_module_and_learner=False, enable_env_runner_and_connector_v2=False)`. Some algos already use the new stack by default. Ignore this message, if your RLModule does not use a Catalog to build its sub-components.\n",
      "2025-01-18 19:15:14,534\tWARNING ppo.py:295 -- You are running PPO on the new API stack! This is the new default behavior for this algorithm. If you don't want to use the new API stack, set `config.api_stack(enable_rl_module_and_learner=False,enable_env_runner_and_connector_v2=False)`. For a detailed migration guide, see here: https://docs.ray.io/en/master/rllib/new-api-stack-migration-guide.html\n",
      "d:\\programs\\miniconda3\\Lib\\site-packages\\ray\\rllib\\algorithms\\algorithm.py:569: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "`UnifiedLogger` will be removed in Ray 2.7.\n",
      "  return UnifiedLogger(config, logdir, loggers=None)\n",
      "d:\\programs\\miniconda3\\Lib\\site-packages\\ray\\tune\\logger\\unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "The `JsonLogger interface is deprecated in favor of the `ray.tune.json.JsonLoggerCallback` interface and will be removed in Ray 2.7.\n",
      "  self._loggers.append(cls(self.config, self.logdir, self.trial))\n",
      "d:\\programs\\miniconda3\\Lib\\site-packages\\ray\\tune\\logger\\unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "The `CSVLogger interface is deprecated in favor of the `ray.tune.csv.CSVLoggerCallback` interface and will be removed in Ray 2.7.\n",
      "  self._loggers.append(cls(self.config, self.logdir, self.trial))\n",
      "d:\\programs\\miniconda3\\Lib\\site-packages\\ray\\tune\\logger\\unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "The `TBXLogger interface is deprecated in favor of the `ray.tune.tensorboardx.TBXLoggerCallback` interface and will be removed in Ray 2.7.\n",
      "  self._loggers.append(cls(self.config, self.logdir, self.trial))\n",
      "d:\\programs\\miniconda3\\Lib\\site-packages\\gymnasium\\envs\\registration.py:642: UserWarning: \u001b[33mWARN: Overriding environment rllib-single-agent-env-v0 already in registry.\u001b[0m\n",
      "  logger.warn(f\"Overriding environment {new_spec.id} already in registry.\")\n",
      "2025-01-18 19:15:14,747\tWARNING ppo.py:295 -- You are running PPO on the new API stack! This is the new default behavior for this algorithm. If you don't want to use the new API stack, set `config.api_stack(enable_rl_module_and_learner=False,enable_env_runner_and_connector_v2=False)`. For a detailed migration guide, see here: https://docs.ray.io/en/master/rllib/new-api-stack-migration-guide.html\n",
      "2025-01-18 19:15:14,918\tWARNING rl_module.py:427 -- Could not create a Catalog object for your RLModule! If you are not using the new API stack yet, make sure to switch it off in your config: `config.api_stack(enable_rl_module_and_learner=False, enable_env_runner_and_connector_v2=False)`. Some algos already use the new stack by default. Ignore this message, if your RLModule does not use a Catalog to build its sub-components.\n",
      "2025-01-18 19:15:14,960\tWARNING util.py:61 -- Install gputil for GPU system monitoring.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------- 训练迭代: 1 ---------\n",
      "环境运行器:\n",
      "  episode平均回报: 21.5400\n",
      "  episode最大回报: 70.0000\n",
      "  episode平均步数: 21.5400\n",
      "  episode最大步数: 70.0000\n",
      "  采样环境总步数: 4000.0000\n",
      "  episodes计数: 184.0000\n",
      "\n",
      "评估:\n",
      "  无评估数据\n",
      "\n",
      "学习者(默认策略):\n",
      "  熵: 0.6672\n",
      "  策略损失: 0.0442\n",
      "  值函数损失: 6.4843\n",
      "  总损失: 6.5337\n",
      "\n",
      "本轮时间: 22.6288\n",
      "每轮训练步数: 1\n",
      "------------------------------\n",
      "--------- 训练迭代: 2 ---------\n",
      "环境运行器:\n",
      "  episode平均回报: 37.4600\n",
      "  episode最大回报: 109.0000\n",
      "  episode平均步数: 37.4600\n",
      "  episode最大步数: 109.0000\n",
      "  采样环境总步数: 4000.0000\n",
      "  episodes计数: 111.0000\n",
      "\n",
      "评估:\n",
      "  无评估数据\n",
      "\n",
      "学习者(默认策略):\n",
      "  熵: 0.6221\n",
      "  策略损失: 0.0227\n",
      "  值函数损失: 7.8457\n",
      "  总损失: 7.8735\n",
      "\n",
      "本轮时间: 21.9798\n",
      "每轮训练步数: 1\n",
      "------------------------------\n",
      "--------- 训练迭代: 3 ---------\n",
      "环境运行器:\n",
      "  episode平均回报: 51.5300\n",
      "  episode最大回报: 185.0000\n",
      "  episode平均步数: 51.5300\n",
      "  episode最大步数: 185.0000\n",
      "  采样环境总步数: 4000.0000\n",
      "  episodes计数: 62.0000\n",
      "\n",
      "评估:\n",
      "  无评估数据\n",
      "\n",
      "学习者(默认策略):\n",
      "  熵: 0.5957\n",
      "  策略损失: -0.0901\n",
      "  值函数损失: 8.8519\n",
      "  总损失: 8.7659\n",
      "\n",
      "本轮时间: 21.6922\n",
      "每轮训练步数: 1\n",
      "------------------------------\n",
      "--------- 训练迭代: 4 ---------\n",
      "环境运行器:\n",
      "  episode平均回报: 81.9300\n",
      "  episode最大回报: 245.0000\n",
      "  episode平均步数: 81.9400\n",
      "  episode最大步数: 245.0000\n",
      "  采样环境总步数: 4000.0000\n",
      "  episodes计数: 31.0000\n",
      "\n",
      "评估:\n",
      "  无评估数据\n",
      "\n",
      "学习者(默认策略):\n",
      "  熵: 0.5990\n",
      "  策略损失: -0.0477\n",
      "  值函数损失: 9.4720\n",
      "  总损失: 9.4265\n",
      "\n",
      "本轮时间: 21.4702\n",
      "每轮训练步数: 1\n",
      "------------------------------\n",
      "--------- 训练迭代: 5 ---------\n",
      "环境运行器:\n",
      "  episode平均回报: 110.1200\n",
      "  episode最大回报: 320.0000\n",
      "  episode平均步数: 110.1400\n",
      "  episode最大步数: 320.0000\n",
      "  采样环境总步数: 4000.0000\n",
      "  episodes计数: 23.0000\n",
      "\n",
      "评估:\n",
      "  无评估数据\n",
      "\n",
      "学习者(默认策略):\n",
      "  熵: 0.5956\n",
      "  策略损失: 0.0224\n",
      "  值函数损失: 9.4497\n",
      "  总损失: 9.4751\n",
      "\n",
      "本轮时间: 21.5405\n",
      "每轮训练步数: 1\n",
      "------------------------------\n",
      "--------- 训练迭代: 6 ---------\n",
      "环境运行器:\n",
      "  episode平均回报: 139.3700\n",
      "  episode最大回报: 466.0000\n",
      "  episode平均步数: 139.4000\n",
      "  episode最大步数: 466.0000\n",
      "  采样环境总步数: 4000.0000\n",
      "  episodes计数: 19.0000\n",
      "\n",
      "评估:\n",
      "  无评估数据\n",
      "\n",
      "学习者(默认策略):\n",
      "  熵: 0.5847\n",
      "  策略损失: 0.0799\n",
      "  值函数损失: 9.6886\n",
      "  总损失: 9.7718\n",
      "\n",
      "本轮时间: 21.6253\n",
      "每轮训练步数: 1\n",
      "------------------------------\n",
      "--------- 训练迭代: 7 ---------\n",
      "环境运行器:\n",
      "  episode平均回报: 168.2200\n",
      "  episode最大回报: 500.0000\n",
      "  episode平均步数: 168.2600\n",
      "  episode最大步数: 500.0000\n",
      "  采样环境总步数: 4000.0000\n",
      "  episodes计数: 14.0000\n",
      "\n",
      "评估:\n",
      "  无评估数据\n",
      "\n",
      "学习者(默认策略):\n",
      "  熵: 0.5616\n",
      "  策略损失: -0.0715\n",
      "  值函数损失: 9.6803\n",
      "  总损失: 9.6119\n",
      "\n",
      "本轮时间: 21.5070\n",
      "每轮训练步数: 1\n",
      "------------------------------\n",
      "--------- 训练迭代: 8 ---------\n",
      "环境运行器:\n",
      "  episode平均回报: 199.9100\n",
      "  episode最大回报: 500.0000\n",
      "  episode平均步数: 199.9600\n",
      "  episode最大步数: 500.0000\n",
      "  采样环境总步数: 4000.0000\n",
      "  episodes计数: 9.0000\n",
      "\n",
      "评估:\n",
      "  无评估数据\n",
      "\n",
      "学习者(默认策略):\n",
      "  熵: 0.5328\n",
      "  策略损失: -0.0916\n",
      "  值函数损失: 9.7749\n",
      "  总损失: 9.6843\n",
      "\n",
      "本轮时间: 22.1168\n",
      "每轮训练步数: 1\n",
      "------------------------------\n",
      "--------- 训练迭代: 9 ---------\n",
      "环境运行器:\n",
      "  episode平均回报: 235.2100\n",
      "  episode最大回报: 500.0000\n",
      "  episode平均步数: 235.2600\n",
      "  episode最大步数: 501.0000\n",
      "  采样环境总步数: 4000.0000\n",
      "  episodes计数: 8.0000\n",
      "\n",
      "评估:\n",
      "  无评估数据\n",
      "\n",
      "学习者(默认策略):\n",
      "  熵: 0.5478\n",
      "  策略损失: 0.0883\n",
      "  值函数损失: 9.7152\n",
      "  总损失: 9.8044\n",
      "\n",
      "本轮时间: 21.5204\n",
      "每轮训练步数: 1\n",
      "------------------------------\n",
      "--------- 训练迭代: 10 ---------\n",
      "环境运行器:\n",
      "  episode平均回报: 263.0400\n",
      "  episode最大回报: 500.0000\n",
      "  episode平均步数: 263.1000\n",
      "  episode最大步数: 501.0000\n",
      "  采样环境总步数: 4000.0000\n",
      "  episodes计数: 11.0000\n",
      "\n",
      "评估:\n",
      "  无评估数据\n",
      "\n",
      "学习者(默认策略):\n",
      "  熵: 0.5562\n",
      "  策略损失: -0.1028\n",
      "  值函数损失: 9.9373\n",
      "  总损失: 9.8354\n",
      "\n",
      "本轮时间: 21.4829\n",
      "每轮训练步数: 1\n",
      "------------------------------\n",
      "--------- 训练迭代: 11 ---------\n",
      "环境运行器:\n",
      "  episode平均回报: 291.2200\n",
      "  episode最大回报: 500.0000\n",
      "  episode平均步数: 291.2900\n",
      "  episode最大步数: 501.0000\n",
      "  采样环境总步数: 4000.0000\n",
      "  episodes计数: 8.0000\n",
      "\n",
      "评估:\n",
      "  无评估数据\n",
      "\n",
      "学习者(默认策略):\n",
      "  熵: 0.5561\n",
      "  策略损失: 0.1884\n",
      "  值函数损失: 9.7929\n",
      "  总损失: 9.9817\n",
      "\n",
      "本轮时间: 21.5340\n",
      "每轮训练步数: 1\n",
      "------------------------------\n",
      "--------- 训练迭代: 12 ---------\n",
      "环境运行器:\n",
      "  episode平均回报: 314.2800\n",
      "  episode最大回报: 500.0000\n",
      "  episode平均步数: 314.3500\n",
      "  episode最大步数: 501.0000\n",
      "  采样环境总步数: 4000.0000\n",
      "  episodes计数: 10.0000\n",
      "\n",
      "评估:\n",
      "  无评估数据\n",
      "\n",
      "学习者(默认策略):\n",
      "  熵: 0.5224\n",
      "  策略损失: 0.0557\n",
      "  值函数损失: 9.8569\n",
      "  总损失: 9.9133\n",
      "\n",
      "本轮时间: 21.3638\n",
      "每轮训练步数: 1\n",
      "------------------------------\n",
      "--------- 训练迭代: 13 ---------\n",
      "环境运行器:\n",
      "  episode平均回报: 341.1400\n",
      "  episode最大回报: 500.0000\n",
      "  episode平均步数: 341.2200\n",
      "  episode最大步数: 501.0000\n",
      "  采样环境总步数: 4000.0000\n",
      "  episodes计数: 8.0000\n",
      "\n",
      "评估:\n",
      "  无评估数据\n",
      "\n",
      "学习者(默认策略):\n",
      "  熵: 0.5527\n",
      "  策略损失: -0.1523\n",
      "  值函数损失: 9.9222\n",
      "  总损失: 9.7701\n",
      "\n",
      "本轮时间: 21.2998\n",
      "每轮训练步数: 1\n",
      "------------------------------\n",
      "--------- 训练迭代: 14 ---------\n",
      "环境运行器:\n",
      "  episode平均回报: 363.5900\n",
      "  episode最大回报: 500.0000\n",
      "  episode平均步数: 363.6800\n",
      "  episode最大步数: 501.0000\n",
      "  采样环境总步数: 4000.0000\n",
      "  episodes计数: 10.0000\n",
      "\n",
      "评估:\n",
      "  无评估数据\n",
      "\n",
      "学习者(默认策略):\n",
      "  熵: 0.5653\n",
      "  策略损失: -0.0392\n",
      "  值函数损失: 9.6189\n",
      "  总损失: 9.5798\n",
      "\n",
      "本轮时间: 21.4150\n",
      "每轮训练步数: 1\n",
      "------------------------------\n",
      "--------- 训练迭代: 15 ---------\n",
      "环境运行器:\n",
      "  episode平均回报: 385.4000\n",
      "  episode最大回报: 500.0000\n",
      "  episode平均步数: 385.4900\n",
      "  episode最大步数: 501.0000\n",
      "  采样环境总步数: 4000.0000\n",
      "  episodes计数: 9.0000\n",
      "\n",
      "评估:\n",
      "  无评估数据\n",
      "\n",
      "学习者(默认策略):\n",
      "  熵: 0.5509\n",
      "  策略损失: -0.0866\n",
      "  值函数损失: 9.8941\n",
      "  总损失: 9.8077\n",
      "\n",
      "本轮时间: 21.3062\n",
      "每轮训练步数: 1\n",
      "------------------------------\n",
      "--------- 训练迭代: 16 ---------\n",
      "环境运行器:\n",
      "  episode平均回报: 406.9900\n",
      "  episode最大回报: 500.0000\n",
      "  episode平均步数: 407.0900\n",
      "  episode最大步数: 501.0000\n",
      "  采样环境总步数: 4000.0000\n",
      "  episodes计数: 8.0000\n",
      "\n",
      "评估:\n",
      "  无评估数据\n",
      "\n",
      "学习者(默认策略):\n",
      "  熵: 0.5270\n",
      "  策略损失: 0.1209\n",
      "  值函数损失: 9.7526\n",
      "  总损失: 9.8737\n",
      "\n",
      "本轮时间: 21.3002\n",
      "每轮训练步数: 1\n",
      "------------------------------\n",
      "--------- 训练迭代: 17 ---------\n",
      "环境运行器:\n",
      "  episode平均回报: 429.7600\n",
      "  episode最大回报: 500.0000\n",
      "  episode平均步数: 429.8600\n",
      "  episode最大步数: 501.0000\n",
      "  采样环境总步数: 4000.0000\n",
      "  episodes计数: 9.0000\n",
      "\n",
      "评估:\n",
      "  无评估数据\n",
      "\n",
      "学习者(默认策略):\n",
      "  熵: 0.5487\n",
      "  策略损失: -0.0089\n",
      "  值函数损失: 9.9839\n",
      "  总损失: 9.9752\n",
      "\n",
      "本轮时间: 21.5554\n",
      "每轮训练步数: 1\n",
      "------------------------------\n",
      "--------- 训练迭代: 18 ---------\n",
      "环境运行器:\n",
      "  episode平均回报: 441.0000\n",
      "  episode最大回报: 500.0000\n",
      "  episode平均步数: 441.1100\n",
      "  episode最大步数: 501.0000\n",
      "  采样环境总步数: 4000.0000\n",
      "  episodes计数: 10.0000\n",
      "\n",
      "评估:\n",
      "  无评估数据\n",
      "\n",
      "学习者(默认策略):\n",
      "  熵: 0.5427\n",
      "  策略损失: -0.0852\n",
      "  值函数损失: 10.0000\n",
      "  总损失: 9.9152\n",
      "\n",
      "本轮时间: 21.3827\n",
      "每轮训练步数: 1\n",
      "------------------------------\n",
      "--------- 训练迭代: 19 ---------\n",
      "环境运行器:\n",
      "  episode平均回报: 411.2000\n",
      "  episode最大回报: 500.0000\n",
      "  episode平均步数: 411.3000\n",
      "  episode最大步数: 501.0000\n",
      "  采样环境总步数: 4000.0000\n",
      "  episodes计数: 15.0000\n",
      "\n",
      "评估:\n",
      "  无评估数据\n",
      "\n",
      "学习者(默认策略):\n",
      "  熵: 0.5583\n",
      "  策略损失: -0.1564\n",
      "  值函数损失: 9.8688\n",
      "  总损失: 9.7126\n",
      "\n",
      "本轮时间: 21.3794\n",
      "每轮训练步数: 1\n",
      "------------------------------\n",
      "--------- 训练迭代: 20 ---------\n",
      "环境运行器:\n",
      "  episode平均回报: 410.1300\n",
      "  episode最大回报: 500.0000\n",
      "  episode平均步数: 410.2300\n",
      "  episode最大步数: 501.0000\n",
      "  采样环境总步数: 4000.0000\n",
      "  episodes计数: 9.0000\n",
      "\n",
      "评估:\n",
      "  无评估数据\n",
      "\n",
      "学习者(默认策略):\n",
      "  熵: 0.5418\n",
      "  策略损失: 0.0763\n",
      "  值函数损失: 9.9692\n",
      "  总损失: 10.0458\n",
      "\n",
      "本轮时间: 21.3682\n",
      "每轮训练步数: 1\n",
      "------------------------------\n",
      "--------- 训练迭代: 21 ---------\n",
      "环境运行器:\n",
      "  episode平均回报: 417.1900\n",
      "  episode最大回报: 500.0000\n",
      "  episode平均步数: 417.2900\n",
      "  episode最大步数: 501.0000\n",
      "  采样环境总步数: 4000.0000\n",
      "  episodes计数: 8.0000\n",
      "\n",
      "评估:\n",
      "  无评估数据\n",
      "\n",
      "学习者(默认策略):\n",
      "  熵: 0.5327\n",
      "  策略损失: 0.1037\n",
      "  值函数损失: 9.8304\n",
      "  总损失: 9.9342\n",
      "\n",
      "本轮时间: 21.4360\n",
      "每轮训练步数: 1\n",
      "------------------------------\n",
      "--------- 训练迭代: 22 ---------\n",
      "环境运行器:\n",
      "  episode平均回报: 418.4700\n",
      "  episode最大回报: 500.0000\n",
      "  episode平均步数: 418.5700\n",
      "  episode最大步数: 501.0000\n",
      "  采样环境总步数: 4000.0000\n",
      "  episodes计数: 10.0000\n",
      "\n",
      "评估:\n",
      "  无评估数据\n",
      "\n",
      "学习者(默认策略):\n",
      "  熵: 0.5088\n",
      "  策略损失: -0.0824\n",
      "  值函数损失: 9.8594\n",
      "  总损失: 9.7771\n",
      "\n",
      "本轮时间: 21.5781\n",
      "每轮训练步数: 1\n",
      "------------------------------\n",
      "--------- 训练迭代: 23 ---------\n",
      "环境运行器:\n",
      "  episode平均回报: 422.3600\n",
      "  episode最大回报: 500.0000\n",
      "  episode平均步数: 422.4600\n",
      "  episode最大步数: 501.0000\n",
      "  采样环境总步数: 4000.0000\n",
      "  episodes计数: 8.0000\n",
      "\n",
      "评估:\n",
      "  无评估数据\n",
      "\n",
      "学习者(默认策略):\n",
      "  熵: 0.5510\n",
      "  策略损失: -0.1171\n",
      "  值函数损失: 9.9273\n",
      "  总损失: 9.8103\n",
      "\n",
      "本轮时间: 21.4542\n",
      "每轮训练步数: 1\n",
      "------------------------------\n",
      "--------- 训练迭代: 24 ---------\n",
      "环境运行器:\n",
      "  episode平均回报: 424.5700\n",
      "  episode最大回报: 500.0000\n",
      "  episode平均步数: 424.6700\n",
      "  episode最大步数: 501.0000\n",
      "  采样环境总步数: 4000.0000\n",
      "  episodes计数: 8.0000\n",
      "\n",
      "评估:\n",
      "  无评估数据\n",
      "\n",
      "学习者(默认策略):\n",
      "  熵: 0.4980\n",
      "  策略损失: -0.1446\n",
      "  值函数损失: 9.9226\n",
      "  总损失: 9.7782\n",
      "\n",
      "本轮时间: 21.4841\n",
      "每轮训练步数: 1\n",
      "------------------------------\n",
      "--------- 训练迭代: 25 ---------\n",
      "环境运行器:\n",
      "  episode平均回报: 425.2400\n",
      "  episode最大回报: 500.0000\n",
      "  episode平均步数: 425.3400\n",
      "  episode最大步数: 501.0000\n",
      "  采样环境总步数: 4000.0000\n",
      "  episodes计数: 9.0000\n",
      "\n",
      "评估:\n",
      "  无评估数据\n",
      "\n",
      "学习者(默认策略):\n",
      "  熵: 0.5305\n",
      "  策略损失: 0.0315\n",
      "  值函数损失: 9.7347\n",
      "  总损失: 9.7665\n",
      "\n",
      "本轮时间: 21.3337\n",
      "每轮训练步数: 1\n",
      "------------------------------\n",
      "--------- 训练迭代: 26 ---------\n",
      "环境运行器:\n",
      "  episode平均回报: 426.1400\n",
      "  episode最大回报: 500.0000\n",
      "  episode平均步数: 426.2400\n",
      "  episode最大步数: 501.0000\n",
      "  采样环境总步数: 4000.0000\n",
      "  episodes计数: 9.0000\n",
      "\n",
      "评估:\n",
      "  无评估数据\n",
      "\n",
      "学习者(默认策略):\n",
      "  熵: 0.4841\n",
      "  策略损失: 0.0748\n",
      "  值函数损失: 9.9678\n",
      "  总损失: 10.0426\n",
      "\n",
      "本轮时间: 21.3845\n",
      "每轮训练步数: 1\n",
      "------------------------------\n",
      "--------- 训练迭代: 27 ---------\n",
      "环境运行器:\n",
      "  episode平均回报: 421.8900\n",
      "  episode最大回报: 500.0000\n",
      "  episode平均步数: 421.9900\n",
      "  episode最大步数: 501.0000\n",
      "  采样环境总步数: 4000.0000\n",
      "  episodes计数: 9.0000\n",
      "\n",
      "评估:\n",
      "  无评估数据\n",
      "\n",
      "学习者(默认策略):\n",
      "  熵: 0.4772\n",
      "  策略损失: 0.1176\n",
      "  值函数损失: 9.8467\n",
      "  总损失: 9.9644\n",
      "\n",
      "本轮时间: 21.4005\n",
      "每轮训练步数: 1\n",
      "------------------------------\n",
      "--------- 训练迭代: 28 ---------\n",
      "环境运行器:\n",
      "  episode平均回报: 422.9000\n",
      "  episode最大回报: 500.0000\n",
      "  episode平均步数: 423.0000\n",
      "  episode最大步数: 501.0000\n",
      "  采样环境总步数: 4000.0000\n",
      "  episodes计数: 8.0000\n",
      "\n",
      "评估:\n",
      "  无评估数据\n",
      "\n",
      "学习者(默认策略):\n",
      "  熵: 0.5131\n",
      "  策略损失: 0.0060\n",
      "  值函数损失: 9.9293\n",
      "  总损失: 9.9353\n",
      "\n",
      "本轮时间: 21.4069\n",
      "每轮训练步数: 1\n",
      "------------------------------\n",
      "--------- 训练迭代: 29 ---------\n",
      "环境运行器:\n",
      "  episode平均回报: 433.3000\n",
      "  episode最大回报: 500.0000\n",
      "  episode平均步数: 433.4000\n",
      "  episode最大步数: 501.0000\n",
      "  采样环境总步数: 4000.0000\n",
      "  episodes计数: 8.0000\n",
      "\n",
      "评估:\n",
      "  无评估数据\n",
      "\n",
      "学习者(默认策略):\n",
      "  熵: 0.4900\n",
      "  策略损失: 0.1151\n",
      "  值函数损失: 10.0000\n",
      "  总损失: 10.1151\n",
      "\n",
      "本轮时间: 21.4769\n",
      "每轮训练步数: 1\n",
      "------------------------------\n",
      "--------- 训练迭代: 30 ---------\n",
      "环境运行器:\n",
      "  episode平均回报: 454.2700\n",
      "  episode最大回报: 500.0000\n",
      "  episode平均步数: 454.3800\n",
      "  episode最大步数: 501.0000\n",
      "  采样环境总步数: 4000.0000\n",
      "  episodes计数: 8.0000\n",
      "\n",
      "评估:\n",
      "  无评估数据\n",
      "\n",
      "学习者(默认策略):\n",
      "  熵: 0.4850\n",
      "  策略损失: -0.1025\n",
      "  值函数损失: 9.6664\n",
      "  总损失: 9.5639\n",
      "\n",
      "本轮时间: 21.3128\n",
      "每轮训练步数: 1\n",
      "------------------------------\n",
      "--------- 训练迭代: 31 ---------\n",
      "环境运行器:\n",
      "  episode平均回报: 469.2900\n",
      "  episode最大回报: 500.0000\n",
      "  episode平均步数: 469.4000\n",
      "  episode最大步数: 501.0000\n",
      "  采样环境总步数: 4000.0000\n",
      "  episodes计数: 8.0000\n",
      "\n",
      "评估:\n",
      "  无评估数据\n",
      "\n",
      "学习者(默认策略):\n",
      "  熵: 0.4899\n",
      "  策略损失: -0.0434\n",
      "  值函数损失: 9.7247\n",
      "  总损失: 9.6813\n",
      "\n",
      "本轮时间: 21.2682\n",
      "每轮训练步数: 1\n",
      "------------------------------\n",
      "--------- 训练迭代: 32 ---------\n",
      "环境运行器:\n",
      "  episode平均回报: 470.9000\n",
      "  episode最大回报: 500.0000\n",
      "  episode平均步数: 471.0100\n",
      "  episode最大步数: 501.0000\n",
      "  采样环境总步数: 4000.0000\n",
      "  episodes计数: 9.0000\n",
      "\n",
      "评估:\n",
      "  无评估数据\n",
      "\n",
      "学习者(默认策略):\n",
      "  熵: 0.5036\n",
      "  策略损失: 0.0508\n",
      "  值函数损失: 9.7740\n",
      "  总损失: 9.8247\n",
      "\n",
      "本轮时间: 21.2529\n",
      "每轮训练步数: 1\n",
      "------------------------------\n",
      "--------- 训练迭代: 33 ---------\n",
      "环境运行器:\n",
      "  episode平均回报: 459.8900\n",
      "  episode最大回报: 500.0000\n",
      "  episode平均步数: 460.0000\n",
      "  episode最大步数: 501.0000\n",
      "  采样环境总步数: 4000.0000\n",
      "  episodes计数: 11.0000\n",
      "\n",
      "评估:\n",
      "  无评估数据\n",
      "\n",
      "学习者(默认策略):\n",
      "  熵: 0.4924\n",
      "  策略损失: -0.1058\n",
      "  值函数损失: 9.7808\n",
      "  总损失: 9.6751\n",
      "\n",
      "本轮时间: 21.2514\n",
      "每轮训练步数: 1\n",
      "------------------------------\n",
      "--------- 训练迭代: 34 ---------\n",
      "环境运行器:\n",
      "  episode平均回报: 462.5700\n",
      "  episode最大回报: 500.0000\n",
      "  episode平均步数: 462.6800\n",
      "  episode最大步数: 501.0000\n",
      "  采样环境总步数: 4000.0000\n",
      "  episodes计数: 8.0000\n",
      "\n",
      "评估:\n",
      "  无评估数据\n",
      "\n",
      "学习者(默认策略):\n",
      "  熵: 0.4947\n",
      "  策略损失: -0.0059\n",
      "  值函数损失: 9.7642\n",
      "  总损失: 9.7583\n",
      "\n",
      "本轮时间: 21.4775\n",
      "每轮训练步数: 1\n",
      "------------------------------\n",
      "--------- 训练迭代: 35 ---------\n",
      "环境运行器:\n",
      "  episode平均回报: 462.3900\n",
      "  episode最大回报: 500.0000\n",
      "  episode平均步数: 462.5000\n",
      "  episode最大步数: 501.0000\n",
      "  采样环境总步数: 4000.0000\n",
      "  episodes计数: 8.0000\n",
      "\n",
      "评估:\n",
      "  无评估数据\n",
      "\n",
      "学习者(默认策略):\n",
      "  熵: 0.4879\n",
      "  策略损失: 0.0155\n",
      "  值函数损失: 9.7815\n",
      "  总损失: 9.7970\n",
      "\n",
      "本轮时间: 21.4709\n",
      "每轮训练步数: 1\n",
      "------------------------------\n",
      "--------- 训练迭代: 36 ---------\n",
      "环境运行器:\n",
      "  episode平均回报: 470.4900\n",
      "  episode最大回报: 500.0000\n",
      "  episode平均步数: 470.6000\n",
      "  episode最大步数: 501.0000\n",
      "  采样环境总步数: 4000.0000\n",
      "  episodes计数: 8.0000\n",
      "\n",
      "评估:\n",
      "  无评估数据\n",
      "\n",
      "学习者(默认策略):\n",
      "  熵: 0.4464\n",
      "  策略损失: -0.0577\n",
      "  值函数损失: 9.7836\n",
      "  总损失: 9.7260\n",
      "\n",
      "本轮时间: 21.3070\n",
      "每轮训练步数: 1\n",
      "------------------------------\n",
      "--------- 训练迭代: 37 ---------\n",
      "环境运行器:\n",
      "  episode平均回报: 468.8500\n",
      "  episode最大回报: 500.0000\n",
      "  episode平均步数: 468.9600\n",
      "  episode最大步数: 501.0000\n",
      "  采样环境总步数: 4000.0000\n",
      "  episodes计数: 9.0000\n",
      "\n",
      "评估:\n",
      "  无评估数据\n",
      "\n",
      "学习者(默认策略):\n",
      "  熵: 0.4086\n",
      "  策略损失: -0.0071\n",
      "  值函数损失: 9.7241\n",
      "  总损失: 9.7169\n",
      "\n",
      "本轮时间: 21.2701\n",
      "每轮训练步数: 1\n",
      "------------------------------\n",
      "--------- 训练迭代: 38 ---------\n",
      "环境运行器:\n",
      "  episode平均回报: 471.2400\n",
      "  episode最大回报: 500.0000\n",
      "  episode平均步数: 471.3500\n",
      "  episode最大步数: 501.0000\n",
      "  采样环境总步数: 4000.0000\n",
      "  episodes计数: 8.0000\n",
      "\n",
      "评估:\n",
      "  无评估数据\n",
      "\n",
      "学习者(默认策略):\n",
      "  熵: 0.4075\n",
      "  策略损失: -0.0398\n",
      "  值函数损失: 10.0000\n",
      "  总损失: 9.9602\n",
      "\n",
      "本轮时间: 21.4229\n",
      "每轮训练步数: 1\n",
      "------------------------------\n",
      "--------- 训练迭代: 39 ---------\n",
      "环境运行器:\n",
      "  episode平均回报: 476.3000\n",
      "  episode最大回报: 500.0000\n",
      "  episode平均步数: 476.4100\n",
      "  episode最大步数: 501.0000\n",
      "  采样环境总步数: 4000.0000\n",
      "  episodes计数: 8.0000\n",
      "\n",
      "评估:\n",
      "  无评估数据\n",
      "\n",
      "学习者(默认策略):\n",
      "  熵: 0.3820\n",
      "  策略损失: 0.0815\n",
      "  值函数损失: 9.9337\n",
      "  总损失: 10.0153\n",
      "\n",
      "本轮时间: 21.3810\n",
      "每轮训练步数: 1\n",
      "------------------------------\n",
      "--------- 训练迭代: 40 ---------\n",
      "环境运行器:\n",
      "  episode平均回报: 476.3000\n",
      "  episode最大回报: 500.0000\n",
      "  episode平均步数: 476.4100\n",
      "  episode最大步数: 501.0000\n",
      "  采样环境总步数: 4000.0000\n",
      "  episodes计数: 8.0000\n",
      "\n",
      "评估:\n",
      "  无评估数据\n",
      "\n",
      "学习者(默认策略):\n",
      "  熵: 0.4168\n",
      "  策略损失: -0.0190\n",
      "  值函数损失: 9.8551\n",
      "  总损失: 9.8360\n",
      "\n",
      "本轮时间: 21.4279\n",
      "每轮训练步数: 1\n",
      "------------------------------\n",
      "--------- 训练迭代: 41 ---------\n",
      "环境运行器:\n",
      "  episode平均回报: 477.0600\n",
      "  episode最大回报: 500.0000\n",
      "  episode平均步数: 477.1700\n",
      "  episode最大步数: 501.0000\n",
      "  采样环境总步数: 4000.0000\n",
      "  episodes计数: 8.0000\n",
      "\n",
      "评估:\n",
      "  无评估数据\n",
      "\n",
      "学习者(默认策略):\n",
      "  熵: 0.3511\n",
      "  策略损失: 0.0043\n",
      "  值函数损失: 9.9703\n",
      "  总损失: 9.9746\n",
      "\n",
      "本轮时间: 21.4289\n",
      "每轮训练步数: 1\n",
      "------------------------------\n",
      "--------- 训练迭代: 42 ---------\n",
      "环境运行器:\n",
      "  episode平均回报: 477.0600\n",
      "  episode最大回报: 500.0000\n",
      "  episode平均步数: 477.1700\n",
      "  episode最大步数: 501.0000\n",
      "  采样环境总步数: 4000.0000\n",
      "  episodes计数: 8.0000\n",
      "\n",
      "评估:\n",
      "  无评估数据\n",
      "\n",
      "学习者(默认策略):\n",
      "  熵: 0.3330\n",
      "  策略损失: 0.0170\n",
      "  值函数损失: 9.8693\n",
      "  总损失: 9.8863\n",
      "\n",
      "本轮时间: 22.0936\n",
      "每轮训练步数: 1\n",
      "------------------------------\n",
      "--------- 训练迭代: 43 ---------\n",
      "环境运行器:\n",
      "  episode平均回报: 478.6100\n",
      "  episode最大回报: 500.0000\n",
      "  episode平均步数: 478.7200\n",
      "  episode最大步数: 501.0000\n",
      "  采样环境总步数: 4000.0000\n",
      "  episodes计数: 8.0000\n",
      "\n",
      "评估:\n",
      "  无评估数据\n",
      "\n",
      "学习者(默认策略):\n",
      "  熵: 0.4022\n",
      "  策略损失: 0.0386\n",
      "  值函数损失: 9.7998\n",
      "  总损失: 9.8384\n",
      "\n",
      "本轮时间: 21.2211\n",
      "每轮训练步数: 1\n",
      "------------------------------\n",
      "--------- 训练迭代: 44 ---------\n",
      "环境运行器:\n",
      "  episode平均回报: 481.9700\n",
      "  episode最大回报: 500.0000\n",
      "  episode平均步数: 482.0900\n",
      "  episode最大步数: 501.0000\n",
      "  采样环境总步数: 4000.0000\n",
      "  episodes计数: 8.0000\n",
      "\n",
      "评估:\n",
      "  无评估数据\n",
      "\n",
      "学习者(默认策略):\n",
      "  熵: 0.3698\n",
      "  策略损失: -0.0587\n",
      "  值函数损失: 9.8575\n",
      "  总损失: 9.7988\n",
      "\n",
      "本轮时间: 21.4132\n",
      "每轮训练步数: 1\n",
      "------------------------------\n",
      "--------- 训练迭代: 45 ---------\n",
      "环境运行器:\n",
      "  episode平均回报: 489.9200\n",
      "  episode最大回报: 500.0000\n",
      "  episode平均步数: 490.0400\n",
      "  episode最大步数: 501.0000\n",
      "  采样环境总步数: 4000.0000\n",
      "  episodes计数: 8.0000\n",
      "\n",
      "评估:\n",
      "  无评估数据\n",
      "\n",
      "学习者(默认策略):\n",
      "  熵: 0.3651\n",
      "  策略损失: -0.0575\n",
      "  值函数损失: 9.8090\n",
      "  总损失: 9.7515\n",
      "\n",
      "本轮时间: 21.2489\n",
      "每轮训练步数: 1\n",
      "------------------------------\n",
      "--------- 训练迭代: 46 ---------\n",
      "环境运行器:\n",
      "  episode平均回报: 494.1800\n",
      "  episode最大回报: 500.0000\n",
      "  episode平均步数: 494.3000\n",
      "  episode最大步数: 501.0000\n",
      "  采样环境总步数: 4000.0000\n",
      "  episodes计数: 8.0000\n",
      "\n",
      "评估:\n",
      "  无评估数据\n",
      "\n",
      "学习者(默认策略):\n",
      "  熵: 0.3924\n",
      "  策略损失: 0.0498\n",
      "  值函数损失: 9.9171\n",
      "  总损失: 9.9669\n",
      "\n",
      "本轮时间: 21.2498\n",
      "每轮训练步数: 1\n",
      "------------------------------\n",
      "--------- 训练迭代: 47 ---------\n",
      "环境运行器:\n",
      "  episode平均回报: 497.1000\n",
      "  episode最大回报: 500.0000\n",
      "  episode平均步数: 497.2200\n",
      "  episode最大步数: 501.0000\n",
      "  采样环境总步数: 4000.0000\n",
      "  episodes计数: 8.0000\n",
      "\n",
      "评估:\n",
      "  无评估数据\n",
      "\n",
      "学习者(默认策略):\n",
      "  熵: 0.3394\n",
      "  策略损失: 0.0184\n",
      "  值函数损失: 9.9245\n",
      "  总损失: 9.9429\n",
      "\n",
      "本轮时间: 21.2175\n",
      "每轮训练步数: 1\n",
      "------------------------------\n",
      "--------- 训练迭代: 48 ---------\n",
      "环境运行器:\n",
      "  episode平均回报: 497.1000\n",
      "  episode最大回报: 500.0000\n",
      "  episode平均步数: 497.2200\n",
      "  episode最大步数: 501.0000\n",
      "  采样环境总步数: 4000.0000\n",
      "  episodes计数: 8.0000\n",
      "\n",
      "评估:\n",
      "  无评估数据\n",
      "\n",
      "学习者(默认策略):\n",
      "  熵: 0.3210\n",
      "  策略损失: -0.0055\n",
      "  值函数损失: 9.9821\n",
      "  总损失: 9.9765\n",
      "\n",
      "本轮时间: 21.3304\n",
      "每轮训练步数: 1\n",
      "------------------------------\n",
      "--------- 训练迭代: 49 ---------\n",
      "环境运行器:\n",
      "  episode平均回报: 497.1000\n",
      "  episode最大回报: 500.0000\n",
      "  episode平均步数: 497.2200\n",
      "  episode最大步数: 501.0000\n",
      "  采样环境总步数: 4000.0000\n",
      "  episodes计数: 8.0000\n",
      "\n",
      "评估:\n",
      "  无评估数据\n",
      "\n",
      "学习者(默认策略):\n",
      "  熵: 0.3521\n",
      "  策略损失: -0.0563\n",
      "  值函数损失: 9.9236\n",
      "  总损失: 9.8673\n",
      "\n",
      "本轮时间: 21.2231\n",
      "每轮训练步数: 1\n",
      "------------------------------\n",
      "--------- 训练迭代: 50 ---------\n",
      "环境运行器:\n",
      "  episode平均回报: 500.0000\n",
      "  episode最大回报: 500.0000\n",
      "  episode平均步数: 500.1200\n",
      "  episode最大步数: 501.0000\n",
      "  采样环境总步数: 4000.0000\n",
      "  episodes计数: 8.0000\n",
      "\n",
      "评估:\n",
      "  无评估数据\n",
      "\n",
      "学习者(默认策略):\n",
      "  熵: 0.3412\n",
      "  策略损失: 0.0346\n",
      "  值函数损失: 9.9248\n",
      "  总损失: 9.9594\n",
      "\n",
      "本轮时间: 21.1719\n",
      "每轮训练步数: 1\n",
      "------------------------------\n",
      "cost time: 17.90min\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "server = None\n",
    "\n",
    "def get_weights(learner):\n",
    "    return learner.get_state(components=COMPONENT_RL_MODULE)['rl_module']['default_policy']\n",
    "\n",
    "def apply_gradients(gradients_dict, learner):\n",
    "    \"\"\"更新参数\"\"\"\n",
    "    params = learner._params\n",
    "    for k, v in zip(list(params.keys()), list(gradients_dict.values())):\n",
    "        params[k].grad = v.to(learner._device)\n",
    "    \n",
    "    learner.apply_gradients({})\n",
    "    return get_weights(learner)\n",
    "\n",
    "class DebugLearner(PPOTorchLearner):\n",
    "\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.server_weights = None\n",
    "\n",
    "    def apply_gradients(self, gradients_dict) -> None:\n",
    "        # 无用更新，最终参数也会被覆盖，可以优化\n",
    "        # 客户端只需要计算梯度，不需要更新参数\n",
    "        # super().apply_gradients(gradients_dict)\n",
    "\n",
    "        # 2. 使用服务器参数 覆盖 本地参数\n",
    "        self.set_state(self.server_weights)\n",
    "    \n",
    "    def compute_gradients(self, loss_per_module, **kwargs):\n",
    "        gradients = super().compute_gradients(loss_per_module, **kwargs)\n",
    "\n",
    "        # 1. 梯度传递给参数服务器, 获取服务器参数\n",
    "        server_params = apply_gradients(gradients, server)\n",
    "        self.server_weights = {'rl_module': {'default_policy': server_params}}\n",
    "\n",
    "        return gradients\n",
    "\n",
    "server_config = (\n",
    "    PPOConfig()\n",
    "    .api_stack(\n",
    "        enable_rl_module_and_learner=True,\n",
    "        enable_env_runner_and_connector_v2=True,\n",
    "    )\n",
    "    .api_stack(\n",
    "        enable_rl_module_and_learner=True,\n",
    "        enable_env_runner_and_connector_v2=True,\n",
    "    )\n",
    "    .env_runners(num_env_runners=0)\n",
    ")\n",
    "\n",
    "client_config = (\n",
    "    PPOConfig()\n",
    "    .api_stack(\n",
    "        enable_rl_module_and_learner=True,\n",
    "        enable_env_runner_and_connector_v2=True,\n",
    "    )\n",
    "    .api_stack(\n",
    "        enable_rl_module_and_learner=True,\n",
    "        enable_env_runner_and_connector_v2=True,\n",
    "    )\n",
    "    .environment(\"CartPole-v1\")\n",
    "    .env_runners(num_env_runners=0)\n",
    "    .training(\n",
    "        learner_class=DebugLearner,# 调试学习者\n",
    "    )\n",
    ")\n",
    "\n",
    "# 初始化 参数服务器\n",
    "server = server_config.build_learner(env=gym.make(\"CartPole-v1\"))\n",
    "server.build()\n",
    "\n",
    "# 初始化 客户端\n",
    "client = client_config.build()\n",
    "\n",
    "# 同步服务器参数 > 客户端\n",
    "server_init_params = get_weights(server)\n",
    "server_init_params = {'default_policy': server_init_params}\n",
    "client.learner_group.set_weights(server_init_params)\n",
    "\n",
    "t = time.time()\n",
    "mean_returns = []\n",
    "for i in range(50):\n",
    "    result = simplify_rllib_metrics(client.train())\n",
    "    mean_returns.append(result[\"环境运行器\"][\"episode平均回报\"])\n",
    "\n",
    "print(f\"cost time: {((time.time() - t)/60):.2f}min\")\n",
    "pd.Series(mean_returns).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
