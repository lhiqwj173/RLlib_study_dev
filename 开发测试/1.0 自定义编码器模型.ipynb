{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 准备环境 pip install ale_py gymnasium[accept-rom-license,atari]==1.0.0\n",
    "# !wget https://raw.githubusercontent.com/lhiqwj173/dl_helper/master/envs/rl.py > /dev/null 2>&1\n",
    "# !python rl.py not_install_dl_helper > /dev/null 2>&1\n",
    "# !pip install /kaggle/working/3rd/dl_helper > /dev/null 2>&1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ray 版本: 2.40.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import gymnasium as gym\n",
    "import ale_py\n",
    "gym.register_envs(ale_py)\n",
    "import ray\n",
    "print(\"ray 版本:\", ray.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RLlib 中的模型的生成逻辑\n",
    "1. 生成配置对象 config \n",
    "2. 根据配置生成模型 config.build()\n",
    "\n",
    "## 模型类型\n",
    "- PPO(通用IMPALA/APPO)\n",
    "- DQN(以及变种)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 相关类\n",
    "from ray.rllib.core.rl_module.rl_module import RLModule\n",
    "from ray.rllib.core.rl_module.torch import TorchRLModule\n",
    "from ray.rllib.algorithms.ppo.ppo_rl_module import PPORLModule\n",
    "from ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module import PPOTorchRLModule\n",
    "# API 类\n",
    "from ray.rllib.core.rl_module.apis import InferenceOnlyAPI, ValueFunctionAPI\n",
    "# 配置类，用于生成模型\n",
    "from ray.rllib.algorithms.ppo.ppo_catalog import PPOCatalog\n",
    "from ray.rllib.core.models.catalog import Catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31mInit signature:\u001b[0m\n",
      "\u001b[0mCatalog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mobservation_space\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mgymnasium\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mspaces\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mspace\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSpace\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0maction_space\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mgymnasium\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mspaces\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mspace\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSpace\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mmodel_config_dict\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mview_requirements\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mSource:\u001b[0m        \n",
      "\u001b[1;32mclass\u001b[0m \u001b[0mCatalog\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;34m\"\"\"Describes the sub-module-architectures to be used in RLModules.\n",
      "\n",
      "    RLlib's native RLModules get their Models from a Catalog object.\n",
      "    By default, that Catalog builds the configs it has as attributes.\n",
      "    This component was build to be hackable and extensible. You can inject custom\n",
      "    components into RL Modules by overriding the `build_xxx` methods of this class.\n",
      "    Note that it is recommended to write a custom RL Module for a single use-case.\n",
      "    Modifications to Catalogs mostly make sense if you want to reuse the same\n",
      "    Catalog for different RL Modules. For example if you have written a custom\n",
      "    encoder and want to inject it into different RL Modules (e.g. for PPO, DQN, etc.).\n",
      "    You can influence the decision tree that determines the sub-components by modifying\n",
      "    `Catalog._determine_components_hook`.\n",
      "\n",
      "    Usage example:\n",
      "\n",
      "    # Define a custom catalog\n",
      "\n",
      "    .. testcode::\n",
      "\n",
      "        import torch\n",
      "        import gymnasium as gym\n",
      "        from ray.rllib.core.models.configs import MLPHeadConfig\n",
      "        from ray.rllib.core.models.catalog import Catalog\n",
      "\n",
      "        class MyCatalog(Catalog):\n",
      "            def __init__(\n",
      "                self,\n",
      "                observation_space: gym.Space,\n",
      "                action_space: gym.Space,\n",
      "                model_config_dict: dict,\n",
      "            ):\n",
      "                super().__init__(observation_space, action_space, model_config_dict)\n",
      "                self.my_model_config = MLPHeadConfig(\n",
      "                    hidden_layer_dims=[64, 32],\n",
      "                    input_dims=[self.observation_space.shape[0]],\n",
      "                )\n",
      "\n",
      "            def build_my_head(self, framework: str):\n",
      "                return self.my_model_config.build(framework=framework)\n",
      "\n",
      "        # With that, RLlib can build and use models from this catalog like this:\n",
      "        catalog = MyCatalog(gym.spaces.Box(0, 1), gym.spaces.Box(0, 1), {})\n",
      "        my_head = catalog.build_my_head(framework=\"torch\")\n",
      "\n",
      "        # Make a call to the built model.\n",
      "        out = my_head(torch.Tensor([[1]]))\n",
      "    \"\"\"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;31m# TODO (Sven): Add `framework` arg to c'tor and remove this arg from `build`\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;31m#  methods. This way, we can already know in the c'tor of Catalog, what the exact\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;31m#  action distibution objects are and thus what the output dims for e.g. a pi-head\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;31m#  will be.\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mobservation_space\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mgym\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSpace\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0maction_space\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mgym\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSpace\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mmodel_config_dict\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;31m# deprecated args.\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mview_requirements\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mDEPRECATED_VALUE\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;34m\"\"\"Initializes a Catalog with a default encoder config.\n",
      "\n",
      "        Args:\n",
      "            observation_space: The observation space of the environment.\n",
      "            action_space: The action space of the environment.\n",
      "            model_config_dict: The model config that specifies things like hidden\n",
      "                dimensions and activations functions to use in this Catalog.\n",
      "        \"\"\"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;32mif\u001b[0m \u001b[0mview_requirements\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mDEPRECATED_VALUE\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0mdeprecation_warning\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mold\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"Catalog(view_requirements=..)\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merror\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;31m# TODO (sven): The following logic won't be needed anymore, once we get rid of\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;31m#  Catalogs entirely. We will assert directly inside the algo's DefaultRLModule\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;31m#  class that the `model_config` is a DefaultModelConfig. Thus users won't be\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;31m#  able to pass in partial config dicts into a default model (alternatively, we\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;31m#  could automatically augment the user provided dict by the default config\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;31m#  dataclass object only(!) for default modules).\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;32mif\u001b[0m \u001b[0mdataclasses\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_dataclass\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_config_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0mmodel_config_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdataclasses\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_config_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mdefault_config\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdataclasses\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDefaultModelConfig\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;31m# end: TODO\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobservation_space\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mobservation_space\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maction_space\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maction_space\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_model_config_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdefault_config\u001b[0m \u001b[1;33m|\u001b[0m \u001b[0mmodel_config_dict\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_latent_dims\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_determine_components_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;33m@\u001b[0m\u001b[0mOverrideToImplementCustomLogic_CallToSuperRecommended\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;32mdef\u001b[0m \u001b[0m_determine_components_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;34m\"\"\"Decision tree hook for subclasses to override.\n",
      "\n",
      "        By default, this method executes the decision tree that determines the\n",
      "        components that a Catalog builds. You can extend the components by overriding\n",
      "        this or by adding to the constructor of your subclass.\n",
      "\n",
      "        Override this method if you don't want to use the default components\n",
      "        determined here. If you want to use them but add additional components, you\n",
      "        should call `super()._determine_components()` at the beginning of your\n",
      "        implementation.\n",
      "\n",
      "        This makes it so that subclasses are not forced to create an encoder config\n",
      "        if the rest of their catalog is not dependent on it or if it breaks.\n",
      "        At the end of this method, an attribute `Catalog.latent_dims`\n",
      "        should be set so that heads can be built using that information.\n",
      "        \"\"\"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_encoder_config\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_encoder_config\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0mobservation_space\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobservation_space\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0maction_space\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maction_space\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0mmodel_config_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_model_config_dict\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;31m# Create a function that can be called when framework is known to retrieve the\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;31m# class type for action distributions\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_action_dist_class_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunctools\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpartial\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_dist_cls_from_action_space\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maction_space\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maction_space\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;31m# The dimensions of the latent vector that is output by the encoder and fed\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;31m# to the heads.\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlatent_dims\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_encoder_config\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutput_dims\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;32mdef\u001b[0m \u001b[0mlatent_dims\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;34m\"\"\"Returns the latent dimensions of the encoder.\n",
      "\n",
      "        This establishes an agreement between encoder and heads about the latent\n",
      "        dimensions. Encoders can be built to output a latent tensor with\n",
      "        `latent_dims` dimensions, and heads can be built with tensors of\n",
      "        `latent_dims` dimensions as inputs. This can be safely ignored if this\n",
      "        agreement is not needed in case of modifications to the Catalog.\n",
      "\n",
      "        Returns:\n",
      "            The latent dimensions of the encoder.\n",
      "        \"\"\"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_latent_dims\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;33m@\u001b[0m\u001b[0mlatent_dims\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msetter\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;32mdef\u001b[0m \u001b[0mlatent_dims\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_latent_dims\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;33m@\u001b[0m\u001b[0mOverrideToImplementCustomLogic\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;32mdef\u001b[0m \u001b[0mbuild_encoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mframework\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mEncoder\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;34m\"\"\"Builds the encoder.\n",
      "\n",
      "        By default, this method builds an encoder instance from Catalog._encoder_config.\n",
      "\n",
      "        You should override this if you want to use RLlib's default RL Modules but\n",
      "        only want to change the encoder. For example, if you want to use a custom\n",
      "        encoder, but want to use RLlib's default heads, action distribution and how\n",
      "        tensors are routed between them. If you want to have full control over the\n",
      "        RL Module, we recommend writing your own RL Module by inheriting from one of\n",
      "        RLlib's RL Modules instead.\n",
      "\n",
      "        Args:\n",
      "            framework: The framework to use. Either \"torch\" or \"tf2\".\n",
      "\n",
      "        Returns:\n",
      "            The encoder.\n",
      "        \"\"\"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;32massert\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"_encoder_config\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[1;34m\"You must define a `Catalog._encoder_config` attribute in your Catalog \"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[1;34m\"subclass or override the `Catalog.build_encoder` method. By default, \"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[1;34m\"an encoder_config is created in the __post_init__ method.\"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_encoder_config\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframework\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mframework\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;33m@\u001b[0m\u001b[0mOverrideToImplementCustomLogic\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;32mdef\u001b[0m \u001b[0mget_action_dist_cls\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mframework\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;34m\"\"\"Get the action distribution class.\n",
      "\n",
      "        The default behavior is to get the action distribution from the\n",
      "        `Catalog._action_dist_class_fn`.\n",
      "\n",
      "        You should override this to have RLlib build your custom action\n",
      "        distribution instead of the default one. For example, if you don't want to\n",
      "        use RLlib's default RLModules with their default models, but only want to\n",
      "        change the distribution that Catalog returns.\n",
      "\n",
      "        Args:\n",
      "            framework: The framework to use. Either \"torch\" or \"tf2\".\n",
      "\n",
      "        Returns:\n",
      "            The action distribution.\n",
      "        \"\"\"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;32massert\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"_action_dist_class_fn\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[1;34m\"You must define a `Catalog._action_dist_class_fn` attribute in your \"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[1;34m\"Catalog subclass or override the `Catalog.action_dist_class_fn` method. \"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[1;34m\"By default, an action_dist_class_fn is created in the __post_init__ \"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[1;34m\"method.\"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_action_dist_class_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframework\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mframework\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;33m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;32mdef\u001b[0m \u001b[0m_get_encoder_config\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mcls\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mobservation_space\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mgym\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSpace\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mmodel_config_dict\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0maction_space\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mgym\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSpace\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mModelConfig\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;34m\"\"\"Returns an EncoderConfig for the given input_space and model_config_dict.\n",
      "\n",
      "        Encoders are usually used in RLModules to transform the input space into a\n",
      "        latent space that is then fed to the heads. The returned EncoderConfig\n",
      "        objects correspond to the built-in Encoder classes in RLlib.\n",
      "        For example, for a simple 1D-Box input_space, RLlib offers an\n",
      "        MLPEncoder, hence this method returns the MLPEncoderConfig. You can overwrite\n",
      "        this method to produce specific EncoderConfigs for your custom Models.\n",
      "\n",
      "        The following input spaces lead to the following configs:\n",
      "        - 1D-Box: MLPEncoderConfig\n",
      "        - 3D-Box: CNNEncoderConfig\n",
      "        # TODO (Artur): Support more spaces here\n",
      "        # ...\n",
      "\n",
      "        Args:\n",
      "            observation_space: The observation space to use.\n",
      "            model_config_dict: The model config to use.\n",
      "            action_space: The action space to use if actions are to be encoded. This\n",
      "                is commonly the case for LSTM models.\n",
      "\n",
      "        Returns:\n",
      "            The encoder config.\n",
      "        \"\"\"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mactivation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_config_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"fcnet_activation\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0moutput_activation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_config_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"fcnet_activation\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0muse_lstm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_config_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"use_lstm\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;32mif\u001b[0m \u001b[0muse_lstm\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0mencoder_config\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRecurrentEncoderConfig\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[0minput_dims\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mobservation_space\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[0mrecurrent_layer_type\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"lstm\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[0mhidden_dim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel_config_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"lstm_cell_size\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[0mhidden_weights_initializer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel_config_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"lstm_kernel_initializer\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[0mhidden_weights_initializer_config\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel_config_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                    \u001b[1;34m\"lstm_kernel_initializer_kwargs\"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[0mhidden_bias_initializer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel_config_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"lstm_bias_initializer\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[0mhidden_bias_initializer_config\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel_config_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                    \u001b[1;34m\"lstm_bias_initializer_kwargs\"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[0mbatch_major\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[0mnum_layers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[0mtokenizer_config\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_tokenizer_config\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                    \u001b[0mobservation_space\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                    \u001b[0mmodel_config_dict\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[1;31m# TODO (Artur): Maybe check for original spaces here\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[1;31m# input_space is a 1D Box\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobservation_space\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mBox\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobservation_space\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[1;31m# In order to guarantee backward compatability with old configs,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[1;31m# we need to check if no latent dim was set and simply reuse the last\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[1;31m# fcnet hidden dim for that purpose.\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[0mhidden_layer_dims\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_config_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"fcnet_hiddens\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[0mencoder_latent_dim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_config_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"fcnet_hiddens\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[0mencoder_config\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMLPEncoderConfig\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                    \u001b[0minput_dims\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mobservation_space\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                    \u001b[0mhidden_layer_dims\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mhidden_layer_dims\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                    \u001b[0mhidden_layer_activation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mactivation\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                    \u001b[0mhidden_layer_weights_initializer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel_config_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                        \u001b[1;34m\"fcnet_kernel_initializer\"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                    \u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                    \u001b[0mhidden_layer_weights_initializer_config\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel_config_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                        \u001b[1;34m\"fcnet_kernel_initializer_kwargs\"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                    \u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                    \u001b[0mhidden_layer_bias_initializer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel_config_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                        \u001b[1;34m\"fcnet_bias_initializer\"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                    \u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                    \u001b[0mhidden_layer_bias_initializer_config\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel_config_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                        \u001b[1;34m\"fcnet_bias_initializer_kwargs\"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                    \u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                    \u001b[0moutput_layer_dim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencoder_latent_dim\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                    \u001b[0moutput_layer_activation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_activation\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                    \u001b[0moutput_layer_weights_initializer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel_config_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                        \u001b[1;34m\"fcnet_kernel_initializer\"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                    \u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                    \u001b[0moutput_layer_weights_initializer_config\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel_config_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                        \u001b[1;34m\"fcnet_kernel_initializer_kwargs\"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                    \u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                    \u001b[0moutput_layer_bias_initializer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel_config_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                        \u001b[1;34m\"fcnet_bias_initializer\"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                    \u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                    \u001b[0moutput_layer_bias_initializer_config\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel_config_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                        \u001b[1;34m\"fcnet_bias_initializer_kwargs\"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                    \u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[1;31m# input_space is a 3D Box\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[1;32melif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobservation_space\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mBox\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobservation_space\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mmodel_config_dict\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"conv_filters\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                    \u001b[0mmodel_config_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"conv_filters\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_filter_config\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                        \u001b[0mobservation_space\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                    \u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[0mencoder_config\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCNNEncoderConfig\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                    \u001b[0minput_dims\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mobservation_space\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                    \u001b[0mcnn_filter_specifiers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel_config_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"conv_filters\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                    \u001b[0mcnn_activation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel_config_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"conv_activation\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                    \u001b[0mcnn_kernel_initializer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel_config_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"conv_kernel_initializer\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                    \u001b[0mcnn_kernel_initializer_config\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel_config_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                        \u001b[1;34m\"conv_kernel_initializer_kwargs\"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                    \u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                    \u001b[0mcnn_bias_initializer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel_config_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"conv_bias_initializer\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                    \u001b[0mcnn_bias_initializer_config\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel_config_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                        \u001b[1;34m\"conv_bias_initializer_kwargs\"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                    \u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[1;31m# input_space is a 2D Box\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[1;32melif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobservation_space\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mBox\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobservation_space\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[1;31m# RLlib used to support 2D Box spaces by silently flattening them\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                    \u001b[1;33mf\"\u001b[0m\u001b[1;33mNo default encoder config for obs space=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mobservation_space\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                    \u001b[1;33mf\"\u001b[0m\u001b[1;33m lstm=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0muse_lstm\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m found. 2D Box \u001b[0m\u001b[1;33m\"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                    \u001b[1;33mf\"\u001b[0m\u001b[1;33mspaces are not supported. They should be either flattened to a \u001b[0m\u001b[1;33m\"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                    \u001b[1;33mf\"\u001b[0m\u001b[1;33m1D Box space or enhanced to be a 3D box space.\u001b[0m\u001b[1;33m\"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[1;31m# input_space is a possibly nested structure of spaces.\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[1;31m# NestedModelConfig\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                    \u001b[1;33mf\"\u001b[0m\u001b[1;33mNo default encoder config for obs space=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mobservation_space\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                    \u001b[1;33mf\"\u001b[0m\u001b[1;33m lstm=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0muse_lstm\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m found.\u001b[0m\u001b[1;33m\"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;32mreturn\u001b[0m \u001b[0mencoder_config\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;33m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;33m@\u001b[0m\u001b[0mOverrideToImplementCustomLogic\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;32mdef\u001b[0m \u001b[0mget_tokenizer_config\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mcls\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mobservation_space\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mgym\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSpace\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mmodel_config_dict\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;31m# deprecated args.\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mview_requirements\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mDEPRECATED_VALUE\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mModelConfig\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;34m\"\"\"Returns a tokenizer config for the given space.\n",
      "\n",
      "        This is useful for recurrent / transformer models that need to tokenize their\n",
      "        inputs. By default, RLlib uses the models supported by Catalog out of the box to\n",
      "        tokenize.\n",
      "\n",
      "        You should override this method if you want to change the custom tokenizer\n",
      "        inside current encoders that Catalog returns without providing the recurrent\n",
      "        network as a whole. For example, if you want to define some custom CNN layers\n",
      "        as a tokenizer for a recurrent encoder that already includes the recurrent\n",
      "        layers and handles the state.\n",
      "\n",
      "        Args:\n",
      "            observation_space: The observation space to use.\n",
      "            model_config_dict: The model config to use.\n",
      "        \"\"\"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;32mif\u001b[0m \u001b[0mview_requirements\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mDEPRECATED_VALUE\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0mdeprecation_warning\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mold\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"Catalog(view_requirements=..)\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merror\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_encoder_config\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0mobservation_space\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mobservation_space\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[1;31m# Use model_config_dict without flags that would end up in complex models\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0mmodel_config_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[1;33m**\u001b[0m\u001b[0mmodel_config_dict\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[1;33m**\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m\"use_lstm\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"use_attention\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;33m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;32mdef\u001b[0m \u001b[0m_get_dist_cls_from_action_space\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mcls\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0maction_space\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mgym\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSpace\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;33m*\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mframework\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mDistribution\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;34m\"\"\"Returns a distribution class for the given action space.\n",
      "\n",
      "        You can get the required input dimension for the distribution by calling\n",
      "        `action_dict_cls.required_input_dim(action_space)`\n",
      "        on the retrieved class. This is useful, because the Catalog needs to find out\n",
      "        about the required input dimension for the distribution before the model that\n",
      "        outputs these inputs is configured.\n",
      "\n",
      "        Args:\n",
      "            action_space: Action space of the target gym env.\n",
      "            framework: The framework to use.\n",
      "\n",
      "        Returns:\n",
      "            The distribution class for the given action space.\n",
      "        \"\"\"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;31m# If no framework provided, return no action distribution class (None).\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;32mif\u001b[0m \u001b[0mframework\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[1;32mreturn\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;31m# This method is structured in two steps:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;31m# Firstly, construct a dictionary containing the available distribution classes.\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;31m# Secondly, return the correct distribution class for the given action space.\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;31m# Step 1: Construct the dictionary.\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;32mclass\u001b[0m \u001b[0mDistEnum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0menum\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEnum\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0mCategorical\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"Categorical\"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0mDiagGaussian\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"Gaussian\"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0mDeterministic\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"Deterministic\"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0mMultiDistribution\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"MultiDistribution\"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0mMultiCategorical\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"MultiCategorical\"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;32mif\u001b[0m \u001b[0mframework\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"torch\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[1;32mfrom\u001b[0m \u001b[0mray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrllib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtorch_distributions\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[0mTorchCategorical\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[0mTorchDeterministic\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[0mTorchDiagGaussian\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0mdistribution_dicts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[0mDistEnum\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDeterministic\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTorchDeterministic\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[0mDistEnum\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDiagGaussian\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTorchDiagGaussian\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[0mDistEnum\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCategorical\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTorchCategorical\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[1;33m}\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;32melif\u001b[0m \u001b[0mframework\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"tf2\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[1;32mfrom\u001b[0m \u001b[0mray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrllib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtf_distributions\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[0mTfCategorical\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[0mTfDeterministic\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[0mTfDiagGaussian\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0mdistribution_dicts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[0mDistEnum\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDeterministic\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTfDeterministic\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[0mDistEnum\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDiagGaussian\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTfDiagGaussian\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[0mDistEnum\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCategorical\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTfCategorical\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[1;33m}\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[1;33mf\"\u001b[0m\u001b[1;33mUnknown framework: \u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mframework\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m. Only 'torch' and 'tf2' are \u001b[0m\u001b[1;33m\"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[1;34m\"supported for RLModule Catalogs.\"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;31m# Only add a MultiAction distribution class to the dict if we can compute its\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;31m# components (we need a Tuple/Dict space for this).\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction_space\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTuple\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0mpartial_multi_action_distribution_cls\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_multi_action_dist_partial_helper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[0mcatalog_cls\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcls\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[0maction_space\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maction_space\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[0mframework\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mframework\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0mdistribution_dicts\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[0mDistEnum\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMultiDistribution\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpartial_multi_action_distribution_cls\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;31m# Only add a MultiCategorical distribution class to the dict if we can compute\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;31m# its components (we need a MultiDiscrete space for this).\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction_space\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mMultiDiscrete\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0mpartial_multi_categorical_distribution_cls\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[0m_multi_categorical_dist_partial_helper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                    \u001b[0maction_space\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maction_space\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                    \u001b[0mframework\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mframework\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0mdistribution_dicts\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[0mDistEnum\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMultiCategorical\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpartial_multi_categorical_distribution_cls\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;31m# Step 2: Return the correct distribution class for the given action space.\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;31m# Box space -> DiagGaussian OR Deterministic.\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction_space\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mBox\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[1;32mif\u001b[0m \u001b[0maction_space\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchar\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtypecodes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"AllInteger\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                    \u001b[1;34m\"Box(..., `int`) action spaces are not supported. \"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                    \u001b[1;34m\"Use MultiDiscrete  or Box(..., `float`).\"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction_space\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                    \u001b[1;32mraise\u001b[0m \u001b[0mUnsupportedSpaceException\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                        \u001b[1;33mf\"\u001b[0m\u001b[1;33mAction space has multiple dimensions \u001b[0m\u001b[1;33m{\u001b[0m\u001b[0maction_space\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m. \u001b[0m\u001b[1;33m\"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                        \u001b[1;33mf\"\u001b[0m\u001b[1;33mConsider reshaping this into a single dimension, using a \u001b[0m\u001b[1;33m\"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                        \u001b[1;33mf\"\u001b[0m\u001b[1;33mcustom action distribution, using a Tuple action space, \u001b[0m\u001b[1;33m\"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                        \u001b[1;33mf\"\u001b[0m\u001b[1;33mor the multi-agent API.\u001b[0m\u001b[1;33m\"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                    \u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[1;32mreturn\u001b[0m \u001b[0mdistribution_dicts\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mDistEnum\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDiagGaussian\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;31m# Discrete Space -> Categorical.\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction_space\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDiscrete\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[1;32mreturn\u001b[0m \u001b[0mdistribution_dicts\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mDistEnum\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCategorical\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;31m# Tuple/Dict Spaces -> MultiAction.\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction_space\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTuple\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[1;32mreturn\u001b[0m \u001b[0mdistribution_dicts\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mDistEnum\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMultiDistribution\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;31m# Simplex -> Dirichlet.\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction_space\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSimplex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[1;31m# TODO(Artur): Supported Simplex (in torch).\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[1;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Simplex action space not yet supported.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;31m# MultiDiscrete -> MultiCategorical.\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction_space\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mMultiDiscrete\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[1;32mreturn\u001b[0m \u001b[0mdistribution_dicts\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mDistEnum\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMultiCategorical\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;31m# Unknown type -> Error.\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[1;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33mf\"\u001b[0m\u001b[1;33mUnsupported action space: `\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0maction_space\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m`\u001b[0m\u001b[1;33m\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;33m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;32mdef\u001b[0m \u001b[0mget_preprocessor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobservation_space\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mgym\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSpace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mPreprocessor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;34m\"\"\"Returns a suitable preprocessor for the given observation space.\n",
      "\n",
      "        Args:\n",
      "            observation_space: The input observation space.\n",
      "            **kwargs: Forward-compatible kwargs.\n",
      "\n",
      "        Returns:\n",
      "            preprocessor: Preprocessor for the observations.\n",
      "        \"\"\"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;31m# TODO(Artur): Since preprocessors have long been @PublicAPI with the options\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;31m#  kwarg as part of their constructor, we fade out support for this,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;31m#  beginning with this entrypoint.\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;31m# Next, we should deprecate the `options` kwarg from the Preprocessor itself,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;31m# after deprecating the old catalog and other components that still pass this.\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0moptions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"options\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;32mif\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0mdeprecation_warning\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[0mold\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"get_preprocessor_for_space(..., options={...})\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[0mhelp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"Override `Catalog.get_preprocessor()` \"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[1;34m\"in order to implement custom behaviour.\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[0merror\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;32mif\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"custom_preprocessor\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0mdeprecation_warning\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[0mold\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"model_config['custom_preprocessor']\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[0mhelp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"Custom preprocessors are deprecated, \"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[1;34m\"since they sometimes conflict with the built-in \"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[1;34m\"preprocessors for handling complex observation spaces. \"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[1;34m\"Please use wrapper classes around your environment \"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[1;34m\"instead.\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[0merror\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[1;31m# TODO(Artur): Inline the get_preprocessor() call here once we have\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[1;31m#  deprecated the old model catalog.\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0mcls\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_preprocessor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobservation_space\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0mprep\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobservation_space\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[1;32mreturn\u001b[0m \u001b[0mprep\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFile:\u001b[0m           d:\\programs\\miniconda3\\lib\\site-packages\\ray\\rllib\\core\\models\\catalog.py\n",
      "\u001b[1;31mType:\u001b[0m           type\n",
      "\u001b[1;31mSubclasses:\u001b[0m     PPOCatalog, BCCatalog, MARWILCatalog"
     ]
    }
   ],
   "source": [
    "from ray.rllib.algorithms.ppo.ppo_catalog import PPOCatalog\n",
    "from ray.rllib.core.models.catalog import Catalog\n",
    "Catalog??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Catalog\n",
    "配置的基类，通用所有的强化学习算法  \n",
    "主要负责通用的编码器生成\n",
    "- _get_encoder_config方法生成编码器配置\n",
    "- build_encoder方法生成编码器\n",
    "    会自动针对输入的维度选择编码器\n",
    "    - use_lstm > RecurrentEncoderConfig\n",
    "    - 1D-Box > MLPEncoderConfig\n",
    "    - 3D-Box > CNNEncoderConfig\n",
    "\n",
    "自动生成的编码器涵盖 MLP/CNN/LSTM  \n",
    "基本上都可以通过配置调整满足需求,如下示意  \n",
    "详细的配置参考 Catalog._get_encoder_config 方法中对配置字段的使用（或官方文档 https://docs.ray.io/en/latest/rllib/rllib-catalogs.html MODEL_DEFAULTS）\n",
    "\n",
    "```\n",
    "config.rl_module(\n",
    "    model_config={\n",
    "        # MLPEncoderConfig\n",
    "        \"fcnet_hiddens\": [5, 3, 3],\n",
    "        \"fcnet_kernel_initializer\": None,\n",
    "        \"fcnet_kernel_initializer_kwargs\": {},\n",
    "        \"fcnet_bias_initializer\": None,\n",
    "        \"fcnet_bias_initializer_kwargs\": {},\n",
    "\n",
    "        # CNNEncoderConfig\n",
    "        \"conv_filters\": [\n",
    "            [32, [8, 8], 4],  # [输出通道数, [kernel_size_h, kernel_size_w], stride]\n",
    "            [64, [4, 4], 2],  # [64个通道, 4x4卷积核, stride=2]\n",
    "            [64, [3, 3], 1],  # [64个通道, 3x3卷积核, stride=1] \n",
    "        ],\n",
    "\n",
    "        # RecurrentEncoderConfig\n",
    "        ...\n",
    "    },\n",
    ")\n",
    "\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 相关源码\n",
    "class Catalog:\n",
    "    \"\"\"描述用于 RL 模块的子模块架构。\n",
    "\n",
    "    RLlib 的原生 RL 模块从 Catalog 对象获取其模型。\n",
    "    默认情况下，该 Catalog 会构建其作为属性拥有的配置。\n",
    "    此组件被构建为可hack和可扩展的。您可以通过重写此类的 `build_xxx` 方法，\n",
    "    将自定义组件注入到 RL 模块中。\n",
    "    请注意，建议为单个用例编写自定义 RL 模块。\n",
    "    对 Catalog 的修改主要在您想要为不同的 RL 模块重用相同的 Catalog 时才有意义。\n",
    "    例如，如果您编写了一个自定义编码器并希望将其注入到不同的 RL 模块\n",
    "    （例如，PPO、DQN 等）。您可以通过修改\n",
    "    `Catalog._determine_components_hook` 来影响决定子组件的决策树。\n",
    "\n",
    "    使用示例：\n",
    "\n",
    "    # 定义一个自定义的 catalog\n",
    "\n",
    "    .. testcode::\n",
    "\n",
    "        import torch\n",
    "        import gymnasium as gym\n",
    "        from ray.rllib.core.models.configs import MLPHeadConfig\n",
    "        from ray.rllib.core.models.catalog import Catalog\n",
    "\n",
    "        class MyCatalog(Catalog):\n",
    "            def __init__(\n",
    "                self,\n",
    "                observation_space: gym.Space,\n",
    "                action_space: gym.Space,\n",
    "                model_config_dict: dict,\n",
    "            ):\n",
    "                super().__init__(observation_space, action_space, model_config_dict)\n",
    "                self.my_model_config = MLPHeadConfig(\n",
    "                    hidden_layer_dims=[64, 32],\n",
    "                    input_dims=[self.observation_space.shape[0]],\n",
    "                )\n",
    "\n",
    "            def build_my_head(self, framework: str):\n",
    "                return self.my_model_config.build(framework=framework)\n",
    "\n",
    "        # 有了这个，RLlib 可以像这样从这个 catalog 构建和使用模型：\n",
    "        catalog = MyCatalog(gym.spaces.Box(0, 1), gym.spaces.Box(0, 1), {})\n",
    "        my_head = catalog.build_my_head(framework=\"torch\")\n",
    "\n",
    "        # 对构建的模型进行调用。\n",
    "        out = my_head(torch.Tensor([[1]]))\n",
    "    \"\"\"\n",
    "    @OverrideToImplementCustomLogic_CallToSuperRecommended\n",
    "    def _determine_components_hook(self):\n",
    "        \"\"\"Decision tree hook for subclasses to override.\n",
    "\n",
    "        By default, this method executes the decision tree that determines the\n",
    "        components that a Catalog builds. You can extend the components by overriding\n",
    "        this or by adding to the constructor of your subclass.\n",
    "\n",
    "        Override this method if you don't want to use the default components\n",
    "        determined here. If you want to use them but add additional components, you\n",
    "        should call `super()._determine_components()` at the beginning of your\n",
    "        implementation.\n",
    "\n",
    "        This makes it so that subclasses are not forced to create an encoder config\n",
    "        if the rest of their catalog is not dependent on it or if it breaks.\n",
    "        At the end of this method, an attribute `Catalog.latent_dims`\n",
    "        should be set so that heads can be built using that information.\n",
    "        \"\"\"\n",
    "        self._encoder_config = self._get_encoder_config(\n",
    "            observation_space=self.observation_space,\n",
    "            action_space=self.action_space,\n",
    "            model_config_dict=self._model_config_dict,\n",
    "        )\n",
    "\n",
    "        # Create a function that can be called when framework is known to retrieve the\n",
    "        # class type for action distributions\n",
    "        self._action_dist_class_fn = functools.partial(\n",
    "            self._get_dist_cls_from_action_space, action_space=self.action_space\n",
    "        )\n",
    "\n",
    "        # The dimensions of the latent vector that is output by the encoder and fed\n",
    "        # to the heads.\n",
    "        self.latent_dims = self._encoder_config.output_dims\n",
    "\n",
    "    @OverrideToImplementCustomLogic\n",
    "    def build_encoder(self, framework: str) -> Encoder:\n",
    "        \"\"\"Builds the encoder.\n",
    "\n",
    "        By default, this method builds an encoder instance from Catalog._encoder_config.\n",
    "\n",
    "        You should override this if you want to use RLlib's default RL Modules but\n",
    "        only want to change the encoder. For example, if you want to use a custom\n",
    "        encoder, but want to use RLlib's default heads, action distribution and how\n",
    "        tensors are routed between them. If you want to have full control over the\n",
    "        RL Module, we recommend writing your own RL Module by inheriting from one of\n",
    "        RLlib's RL Modules instead.\n",
    "\n",
    "        Args:\n",
    "            framework: The framework to use. Either \"torch\" or \"tf2\".\n",
    "\n",
    "        Returns:\n",
    "            The encoder.\n",
    "        \"\"\"\n",
    "        \"\"\"构建编码器。\n",
    "\n",
    "        默认情况下，此方法从 Catalog._encoder_config 构建一个编码器实例。\n",
    "\n",
    "        如果您想使用 RLlib 的默认 RL 模块，但只想更改编码器，则应重写此方法。\n",
    "        例如，如果您想使用自定义编码器，但想使用 RLlib 的默认头、动作分布以及张量如何在它们之间路由。\n",
    "        如果您想完全控制 RL 模块，\n",
    "        我们建议您通过继承 RLlib 的 RL 模块之一来编写自己的 RL 模块。\n",
    "\n",
    "        Args:\n",
    "        framework: 要使用的框架。可以是 \"torch\" 或 \"tf2\"。\n",
    "\n",
    "        Returns:\n",
    "        编码器。\n",
    "        \"\"\"\n",
    "        assert hasattr(self, \"_encoder_config\"), (\n",
    "            \"You must define a `Catalog._encoder_config` attribute in your Catalog \"\n",
    "            \"subclass or override the `Catalog.build_encoder` method. By default, \"\n",
    "            \"an encoder_config is created in the __post_init__ method.\"\n",
    "        )\n",
    "        return self._encoder_config.build(framework=framework)\n",
    "\n",
    "    @classmethod\n",
    "    def _get_encoder_config(\n",
    "        cls,\n",
    "        observation_space: gym.Space,\n",
    "        model_config_dict: dict,\n",
    "        action_space: gym.Space = None,\n",
    "    ) -> ModelConfig:\n",
    "        \"\"\"Returns an EncoderConfig for the given input_space and model_config_dict.\n",
    "\n",
    "        Encoders are usually used in RLModules to transform the input space into a\n",
    "        latent space that is then fed to the heads. The returned EncoderConfig\n",
    "        objects correspond to the built-in Encoder classes in RLlib.\n",
    "        For example, for a simple 1D-Box input_space, RLlib offers an\n",
    "        MLPEncoder, hence this method returns the MLPEncoderConfig. You can overwrite\n",
    "        this method to produce specific EncoderConfigs for your custom Models.\n",
    "\n",
    "        The following input spaces lead to the following configs:\n",
    "        - 1D-Box: MLPEncoderConfig\n",
    "        - 3D-Box: CNNEncoderConfig\n",
    "        # TODO (Artur): Support more spaces here\n",
    "        # ...\n",
    "\n",
    "        Args:\n",
    "            observation_space: The observation space to use.\n",
    "            model_config_dict: The model config to use.\n",
    "            action_space: The action space to use if actions are to be encoded. This\n",
    "                is commonly the case for LSTM models.\n",
    "\n",
    "        Returns:\n",
    "            The encoder config.\n",
    "        \"\"\"\n",
    "        \"\"\"返回给定 input_space 和 model_config_dict 的 EncoderConfig。\n",
    "\n",
    "        编码器通常在 RLModules 中使用，用于将输入空间转换为一个潜在空间，然后将其传递给头部。\n",
    "        返回的 EncoderConfig 对象对应于 RLlib 中的内置编码器类。\n",
    "        例如，对于一个简单的 1D-Box 输入空间，RLlib 提供了 MLPEncoder\n",
    "        ，因此此方法返回 MLPEncoderConfig。\n",
    "        您可以重写此方法以生成特定的 EncoderConfig 以用于您的自定义模型。\n",
    "\n",
    "        以下输入空间会导致以下配置：\n",
    "\n",
    "        1D-Box: MLPEncoderConfig\n",
    "        3D-Box: CNNEncoderConfig\n",
    "        TODO (Artur): 在此处支持更多空间\n",
    "        ...\n",
    "        Args:\n",
    "        observation_space: 要使用的观测空间。\n",
    "        model_config_dict: 要使用的模型配置。\n",
    "        action_space: 如果动作需要编码，则要使用的动作空间。这在 LSTM 模型的情况下通常是这样。\n",
    "\n",
    "        Returns:\n",
    "        编码器配置。\n",
    "        \"\"\"\n",
    "\n",
    "        activation = model_config_dict[\"fcnet_activation\"]\n",
    "        output_activation = model_config_dict[\"fcnet_activation\"]\n",
    "        use_lstm = model_config_dict[\"use_lstm\"]\n",
    "\n",
    "        if use_lstm:\n",
    "            encoder_config = RecurrentEncoderConfig(\n",
    "                input_dims=observation_space.shape,\n",
    "                recurrent_layer_type=\"lstm\",\n",
    "                hidden_dim=model_config_dict[\"lstm_cell_size\"],\n",
    "                hidden_weights_initializer=model_config_dict[\"lstm_kernel_initializer\"],\n",
    "                hidden_weights_initializer_config=model_config_dict[\n",
    "                    \"lstm_kernel_initializer_kwargs\"\n",
    "                ],\n",
    "                hidden_bias_initializer=model_config_dict[\"lstm_bias_initializer\"],\n",
    "                hidden_bias_initializer_config=model_config_dict[\n",
    "                    \"lstm_bias_initializer_kwargs\"\n",
    "                ],\n",
    "                batch_major=True,\n",
    "                num_layers=1,\n",
    "                tokenizer_config=cls.get_tokenizer_config(\n",
    "                    observation_space,\n",
    "                    model_config_dict,\n",
    "                ),\n",
    "            )\n",
    "        else:\n",
    "            # TODO (Artur): Maybe check for original spaces here\n",
    "            # input_space is a 1D Box\n",
    "            if isinstance(observation_space, Box) and len(observation_space.shape) == 1:\n",
    "                # In order to guarantee backward compatability with old configs,\n",
    "                # we need to check if no latent dim was set and simply reuse the last\n",
    "                # fcnet hidden dim for that purpose.\n",
    "                hidden_layer_dims = model_config_dict[\"fcnet_hiddens\"][:-1]\n",
    "                encoder_latent_dim = model_config_dict[\"fcnet_hiddens\"][-1]\n",
    "                encoder_config = MLPEncoderConfig(\n",
    "                    input_dims=observation_space.shape,\n",
    "                    hidden_layer_dims=hidden_layer_dims,\n",
    "                    hidden_layer_activation=activation,\n",
    "                    hidden_layer_weights_initializer=model_config_dict[\n",
    "                        \"fcnet_kernel_initializer\"\n",
    "                    ],\n",
    "                    hidden_layer_weights_initializer_config=model_config_dict[\n",
    "                        \"fcnet_kernel_initializer_kwargs\"\n",
    "                    ],\n",
    "                    hidden_layer_bias_initializer=model_config_dict[\n",
    "                        \"fcnet_bias_initializer\"\n",
    "                    ],\n",
    "                    hidden_layer_bias_initializer_config=model_config_dict[\n",
    "                        \"fcnet_bias_initializer_kwargs\"\n",
    "                    ],\n",
    "                    output_layer_dim=encoder_latent_dim,\n",
    "                    output_layer_activation=output_activation,\n",
    "                    output_layer_weights_initializer=model_config_dict[\n",
    "                        \"fcnet_kernel_initializer\"\n",
    "                    ],\n",
    "                    output_layer_weights_initializer_config=model_config_dict[\n",
    "                        \"fcnet_kernel_initializer_kwargs\"\n",
    "                    ],\n",
    "                    output_layer_bias_initializer=model_config_dict[\n",
    "                        \"fcnet_bias_initializer\"\n",
    "                    ],\n",
    "                    output_layer_bias_initializer_config=model_config_dict[\n",
    "                        \"fcnet_bias_initializer_kwargs\"\n",
    "                    ],\n",
    "                )\n",
    "\n",
    "            # input_space is a 3D Box\n",
    "            elif (\n",
    "                isinstance(observation_space, Box) and len(observation_space.shape) == 3\n",
    "            ):\n",
    "                if not model_config_dict.get(\"conv_filters\"):\n",
    "                    model_config_dict[\"conv_filters\"] = get_filter_config(\n",
    "                        observation_space.shape\n",
    "                    )\n",
    "\n",
    "                encoder_config = CNNEncoderConfig(\n",
    "                    input_dims=observation_space.shape,\n",
    "                    cnn_filter_specifiers=model_config_dict[\"conv_filters\"],\n",
    "                    cnn_activation=model_config_dict[\"conv_activation\"],\n",
    "                    cnn_kernel_initializer=model_config_dict[\"conv_kernel_initializer\"],\n",
    "                    cnn_kernel_initializer_config=model_config_dict[\n",
    "                        \"conv_kernel_initializer_kwargs\"\n",
    "                    ],\n",
    "                    cnn_bias_initializer=model_config_dict[\"conv_bias_initializer\"],\n",
    "                    cnn_bias_initializer_config=model_config_dict[\n",
    "                        \"conv_bias_initializer_kwargs\"\n",
    "                    ],\n",
    "                )\n",
    "            # input_space is a 2D Box\n",
    "            elif (\n",
    "                isinstance(observation_space, Box) and len(observation_space.shape) == 2\n",
    "            ):\n",
    "                # RLlib used to support 2D Box spaces by silently flattening them\n",
    "                raise ValueError(\n",
    "                    f\"No default encoder config for obs space={observation_space},\"\n",
    "                    f\" lstm={use_lstm} found. 2D Box \"\n",
    "                    f\"spaces are not supported. They should be either flattened to a \"\n",
    "                    f\"1D Box space or enhanced to be a 3D box space.\"\n",
    "                )\n",
    "            # input_space is a possibly nested structure of spaces.\n",
    "            else:\n",
    "                # NestedModelConfig\n",
    "                raise ValueError(\n",
    "                    f\"No default encoder config for obs space={observation_space},\"\n",
    "                    f\" lstm={use_lstm} found.\"\n",
    "                )\n",
    "\n",
    "        return encoder_config\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 默认编码器使用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TorchMLPEncoder(\n",
      "  (net): TorchMLP(\n",
      "    (mlp): Sequential(\n",
      "      (0): Linear(in_features=2, out_features=8, bias=False)\n",
      "      (1): LayerNorm((8,), eps=0.001, elementwise_affine=True)\n",
      "      (2): SiLU()\n",
      "      (3): Linear(in_features=8, out_features=8, bias=False)\n",
      "      (4): LayerNorm((8,), eps=0.001, elementwise_affine=True)\n",
      "      (5): SiLU()\n",
      "      (6): Linear(in_features=8, out_features=4, bias=False)\n",
      "      (7): Tanh()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "TorchCNNEncoder(\n",
      "  (net): Sequential(\n",
      "    (0): TorchCNN(\n",
      "      (cnn): Sequential(\n",
      "        (0): ZeroPad2d((2, 2, 2, 2))\n",
      "        (1): Conv2d(3, 16, kernel_size=(8, 8), stride=(4, 4))\n",
      "        (2): ReLU()\n",
      "        (3): ZeroPad2d((1, 2, 1, 2))\n",
      "        (4): Conv2d(16, 32, kernel_size=(4, 4), stride=(2, 2))\n",
      "        (5): ReLU()\n",
      "      )\n",
      "    )\n",
      "    (1): Flatten(start_dim=1, end_dim=-1)\n",
      "  )\n",
      ")\n",
      "torch.Size([32, 84, 84, 3])\n",
      "{'encoder_out': tensor([[0.0000e+00, 3.1061e-01, 7.7291e-02,  ..., 2.3990e-02, 0.0000e+00,\n",
      "         0.0000e+00],\n",
      "        [5.4777e-02, 1.7335e-02, 0.0000e+00,  ..., 1.8215e-02, 1.9863e-04,\n",
      "         2.6533e-01],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 1.7246e-03, 1.2555e-01,\n",
      "         4.9848e-02],\n",
      "        ...,\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 4.4091e-02,\n",
      "         2.2372e-01],\n",
      "        [0.0000e+00, 3.2137e-02, 5.0495e-02,  ..., 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00],\n",
      "        [2.7655e-01, 2.3857e-03, 3.6505e-02,  ..., 0.0000e+00, 3.7922e-02,\n",
      "         1.3791e-01]], grad_fn=<ViewBackward0>)}\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from ray.rllib.core.models.configs import (\n",
    "    CNNEncoderConfig,\n",
    "    MLPEncoderConfig,\n",
    "    RecurrentEncoderConfig,\n",
    ")\n",
    "\n",
    "# MLP\n",
    "config = MLPEncoderConfig(\n",
    "    input_dims=[2],\n",
    "    hidden_layer_dims=[8, 8],\n",
    "    hidden_layer_activation=\"silu\",\n",
    "    hidden_layer_use_layernorm=True,\n",
    "    hidden_layer_use_bias=False,\n",
    "    output_layer_dim=4,\n",
    "    output_layer_activation=\"tanh\",\n",
    "    output_layer_use_bias=False,\n",
    ")\n",
    "model = config.build(framework=\"torch\")\n",
    "print(model)\n",
    "\n",
    "# CNN\n",
    "config = CNNEncoderConfig(\n",
    "    input_dims=[84, 84, 3],  # must be 3D tensor (image: w x h x C)\n",
    "    cnn_filter_specifiers=[\n",
    "        [16, [8, 8], 4],\n",
    "        [32, [4, 4], 2],\n",
    "    ],\n",
    "    cnn_activation=\"relu\",\n",
    "    cnn_use_layernorm=False,\n",
    "    cnn_use_bias=True,\n",
    ")\n",
    "model = config.build(framework=\"torch\")\n",
    "print(model)\n",
    "\n",
    "# 创建一个batch的输入数据\n",
    "batch_size = 32\n",
    "input_tensor = torch.randn(batch_size, 84, 84, 3)  # PyTorch格式\n",
    "print(input_tensor.shape)\n",
    "\n",
    "# 前向传播\n",
    "output = model({'obs': input_tensor})\n",
    "print(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-08 14:24:16,079\tWARNING ppo.py:295 -- You are running PPO on the new API stack! This is the new default behavior for this algorithm. If you don't want to use the new API stack, set `config.api_stack(enable_rl_module_and_learner=False,enable_env_runner_and_connector_v2=False)`. For a detailed migration guide, see here: https://docs.ray.io/en/master/rllib/new-api-stack-migration-guide.html\n",
      "d:\\programs\\miniconda3\\Lib\\site-packages\\ray\\rllib\\algorithms\\algorithm.py:569: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "`UnifiedLogger` will be removed in Ray 2.7.\n",
      "  return UnifiedLogger(config, logdir, loggers=None)\n",
      "d:\\programs\\miniconda3\\Lib\\site-packages\\ray\\tune\\logger\\unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "The `JsonLogger interface is deprecated in favor of the `ray.tune.json.JsonLoggerCallback` interface and will be removed in Ray 2.7.\n",
      "  self._loggers.append(cls(self.config, self.logdir, self.trial))\n",
      "d:\\programs\\miniconda3\\Lib\\site-packages\\ray\\tune\\logger\\unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "The `CSVLogger interface is deprecated in favor of the `ray.tune.csv.CSVLoggerCallback` interface and will be removed in Ray 2.7.\n",
      "  self._loggers.append(cls(self.config, self.logdir, self.trial))\n",
      "d:\\programs\\miniconda3\\Lib\\site-packages\\ray\\tune\\logger\\unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "The `TBXLogger interface is deprecated in favor of the `ray.tune.tensorboardx.TBXLoggerCallback` interface and will be removed in Ray 2.7.\n",
      "  self._loggers.append(cls(self.config, self.logdir, self.trial))\n",
      "2025-01-08 14:24:25,358\tINFO worker.py:1821 -- Started a local Ray instance.\n",
      "\u001b[36m(SingleAgentEnvRunner pid=204)\u001b[0m 2025-01-08 14:24:33,532\tWARNING deprecation.py:50 -- DeprecationWarning: `RLModule(config=[RLModuleConfig object])` has been deprecated. Use `RLModule(observation_space=.., action_space=.., inference_only=.., model_config=.., catalog_class=..)` instead. This will raise an error in the future!\n",
      "2025-01-08 14:24:34,081\tWARNING deprecation.py:50 -- DeprecationWarning: `RLModule(config=[RLModuleConfig object])` has been deprecated. Use `RLModule(observation_space=.., action_space=.., inference_only=.., model_config=.., catalog_class=..)` instead. This will raise an error in the future!\n",
      "2025-01-08 14:24:34,128\tWARNING ppo.py:295 -- You are running PPO on the new API stack! This is the new default behavior for this algorithm. If you don't want to use the new API stack, set `config.api_stack(enable_rl_module_and_learner=False,enable_env_runner_and_connector_v2=False)`. For a detailed migration guide, see here: https://docs.ray.io/en/master/rllib/new-api-stack-migration-guide.html\n",
      "2025-01-08 14:24:34,355\tWARNING rl_module.py:427 -- Could not create a Catalog object for your RLModule! If you are not using the new API stack yet, make sure to switch it off in your config: `config.api_stack(enable_rl_module_and_learner=False, enable_env_runner_and_connector_v2=False)`. Some algos already use the new stack by default. Ignore this message, if your RLModule does not use a Catalog to build its sub-components.\n",
      "2025-01-08 14:24:45,387\tINFO trainable.py:161 -- Trainable.setup took 28.843 seconds. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n",
      "2025-01-08 14:24:45,387\tWARNING util.py:61 -- Install gputil for GPU system monitoring.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PPOTorchRLModule(\n",
       "  (encoder): TorchActorCriticEncoder(\n",
       "    (actor_encoder): TorchMLPEncoder(\n",
       "      (net): TorchMLP(\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=4, out_features=5, bias=True)\n",
       "          (1): Tanh()\n",
       "          (2): Linear(in_features=5, out_features=3, bias=True)\n",
       "          (3): Tanh()\n",
       "          (4): Linear(in_features=3, out_features=3, bias=True)\n",
       "          (5): Tanh()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pi): TorchMLPHead(\n",
       "    (net): TorchMLP(\n",
       "      (mlp): Sequential(\n",
       "        (0): Linear(in_features=3, out_features=2, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (vf): TorchMLPHead(\n",
       "    (net): TorchMLP(\n",
       "      (mlp): Sequential(\n",
       "        (0): Linear(in_features=3, out_features=1, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ray.rllib.algorithms.ppo import PPOConfig\n",
    "\n",
    "config = (\n",
    "    PPOConfig()\n",
    "    .api_stack(# 使用新的api\n",
    "        enable_rl_module_and_learner=True,\n",
    "        enable_env_runner_and_connector_v2=True,\n",
    "    )\n",
    "    .environment(\"CartPole-v1\")# 输入的是1d，自动采用 MLP 编码器\n",
    "    .environment(\"pong\")# 输入的是3d(4, 42, 42)，自动采用 CNN 编码器\n",
    "    .rl_module(\n",
    "        model_config={\n",
    "            # MLP 参数\n",
    "            \"fcnet_hiddens\": [5, 3, 3],\n",
    "\n",
    "            # CNN 参数, 会自动计算输出维度\n",
    "            # \"conv_filters\": [\n",
    "            #     [32, [8, 8], 4],  # [输出通道数, [kernel_size_h, kernel_size_w], stride]\n",
    "            #     [64, [4, 4], 2],  # [64个通道, 4x4卷积核, stride=2]\n",
    "            #     [64, [3, 3], 1],  # [64个通道, 3x3卷积核, stride=1] \n",
    "            # ],\n",
    "        },\n",
    "    )\n",
    ")\n",
    "\n",
    "# 构建算法\n",
    "algo = config.build()\n",
    "\n",
    "# 查看模型\n",
    "algo.get_module()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 自定义编码器\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConvFCNetEncoder(\n",
      "  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (fc): Linear(in_features=65536, out_features=10, bias=True)\n",
      ")\n",
      "torch.Size([64, 3, 64, 64])\n",
      "{'encoder_out': tensor([[-0.1060, -0.0718,  0.2893,  0.0853, -0.0800, -0.1007, -0.6619,  0.1770,\n",
      "         -0.0339,  0.2272],\n",
      "        [ 0.3811,  0.1370,  0.3421,  0.1041, -0.1262, -0.2639, -0.0535, -0.0187,\n",
      "         -0.0592,  0.0211],\n",
      "        [ 0.5143, -0.3717,  0.2914,  0.1151, -0.2555, -0.1298, -0.1391,  0.1208,\n",
      "          0.2229,  0.5079],\n",
      "        [ 0.2116,  0.0579,  0.2209,  0.0372, -0.1045, -0.1047, -0.1429,  0.1153,\n",
      "         -0.1848,  0.0310],\n",
      "        [ 0.4995,  0.1069,  0.0805, -0.0269,  0.0331, -0.0717, -0.3668, -0.0560,\n",
      "         -0.0017,  0.1744],\n",
      "        [ 0.0340,  0.0345,  0.2767,  0.0576, -0.0720, -0.2415, -0.3790, -0.2408,\n",
      "          0.0134,  0.5356],\n",
      "        [ 0.1508,  0.0029,  0.3615, -0.0941,  0.0070, -0.4566, -0.2489, -0.0762,\n",
      "         -0.0789,  0.5071],\n",
      "        [-0.0379, -0.1246,  0.2279,  0.0109, -0.0331, -0.2974, -0.0875, -0.1484,\n",
      "          0.0161, -0.1113],\n",
      "        [-0.0917,  0.1891,  0.1918,  0.3689,  0.0831,  0.1155, -0.3410, -0.2057,\n",
      "         -0.0834,  0.4957],\n",
      "        [ 0.2121, -0.2113,  0.0420,  0.0719, -0.5379,  0.0180, -0.4109, -0.1040,\n",
      "         -0.1105, -0.3655],\n",
      "        [ 0.3581,  0.3822,  0.2364,  0.0605,  0.0579, -0.1904, -0.1299,  0.0917,\n",
      "          0.0773, -0.0268],\n",
      "        [ 0.2930, -0.0508, -0.1510,  0.1441, -0.2284,  0.1193, -0.4121,  0.1233,\n",
      "         -0.0654, -0.0014],\n",
      "        [ 0.2591,  0.4106, -0.2448,  0.1437, -0.3827, -0.3802, -0.3714,  0.1199,\n",
      "          0.2907,  0.1791],\n",
      "        [ 0.3750, -0.0334,  0.1462,  0.0525, -0.0255, -0.0558, -0.3109, -0.1608,\n",
      "         -0.0777,  0.2432],\n",
      "        [ 0.1169,  0.0059,  0.2303,  0.1395, -0.0972,  0.0234, -0.3440,  0.0295,\n",
      "          0.0782,  0.1716],\n",
      "        [ 0.1872, -0.4317, -0.1262, -0.2711, -0.0049, -0.0863, -0.0652,  0.3760,\n",
      "         -0.4137,  0.3006],\n",
      "        [-0.0227,  0.0111, -0.1867,  0.0903, -0.0043, -0.4573, -0.4497,  0.0358,\n",
      "          0.1147, -0.0787],\n",
      "        [ 0.4460, -0.1411,  0.1422,  0.2638,  0.0633, -0.0957, -0.4984,  0.1023,\n",
      "         -0.4500,  0.0973],\n",
      "        [ 0.2729, -0.1928,  0.2527,  0.0914, -0.2822, -0.2765, -0.5005,  0.1023,\n",
      "         -0.0398,  0.7407],\n",
      "        [ 0.0115, -0.0388,  0.3405,  0.0261, -0.0134, -0.2754, -0.0695,  0.0563,\n",
      "         -0.3226,  0.4390],\n",
      "        [ 0.0103, -0.1066,  0.2763,  0.2188, -0.0841, -0.0961, -0.0146, -0.0790,\n",
      "         -0.0555,  0.0066],\n",
      "        [ 0.0119, -0.1856,  0.1927, -0.0954, -0.0992,  0.0331,  0.0381,  0.0866,\n",
      "         -0.1330,  0.0231],\n",
      "        [ 0.2277,  0.0592,  0.3546,  0.1164, -0.2043, -0.1634, -0.1003,  0.0030,\n",
      "          0.0327,  0.1905],\n",
      "        [ 0.2092,  0.2661,  0.0392,  0.1134, -0.0129, -0.0020, -0.3029,  0.2690,\n",
      "          0.0650,  0.1968],\n",
      "        [ 0.3130, -0.1132,  0.4350, -0.0300, -0.0611, -0.1070, -0.6280, -0.1494,\n",
      "          0.0029,  0.2477],\n",
      "        [ 0.1172, -0.0522,  0.4402, -0.1529, -0.2127, -0.0042,  0.0433,  0.2497,\n",
      "         -0.2576, -0.0805],\n",
      "        [ 0.7293,  0.0907,  0.3871, -0.1415, -0.2409, -0.1458, -0.4789,  0.1788,\n",
      "         -0.0502,  0.0690],\n",
      "        [ 0.0870, -0.1360,  0.6418,  0.2924, -0.1933, -0.4920, -0.6358, -0.2292,\n",
      "         -0.2330,  0.1427],\n",
      "        [ 0.1031,  0.0877,  0.3121,  0.1470,  0.1474,  0.0399, -0.1651, -0.2949,\n",
      "         -0.1753,  0.6906],\n",
      "        [ 0.2938,  0.2811,  0.2679, -0.0464, -0.3330, -0.3504, -0.2632, -0.4855,\n",
      "          0.0473, -0.1458],\n",
      "        [ 0.0156, -0.0453, -0.1894, -0.1501, -0.0653, -0.2439, -0.3766,  0.2629,\n",
      "          0.0414,  0.2474],\n",
      "        [-0.0246, -0.0182,  0.5418, -0.1925, -0.0850,  0.0429, -0.0396,  0.0123,\n",
      "          0.1700, -0.0165],\n",
      "        [-0.0542, -0.3351,  0.4889,  0.1983, -0.0332,  0.0733, -0.3965,  0.0979,\n",
      "          0.1348,  0.0743],\n",
      "        [ 0.2833, -0.1285,  0.4534,  0.1286,  0.0678, -0.2493, -0.3485,  0.3310,\n",
      "         -0.2433,  0.3306],\n",
      "        [ 0.4024,  0.0724,  0.4037, -0.0721, -0.2160, -0.0551, -0.3218, -0.2158,\n",
      "          0.2375,  0.1437],\n",
      "        [ 0.2774,  0.4641,  0.1950, -0.1462, -0.2401,  0.0760, -0.1178,  0.0380,\n",
      "         -0.0794, -0.1996],\n",
      "        [ 0.3280,  0.1599,  0.1170, -0.0272, -0.3897, -0.2420, -0.4363,  0.1019,\n",
      "          0.2934,  0.1446],\n",
      "        [ 0.3649,  0.0693,  0.3498, -0.0430, -0.0256, -0.0704, -0.3906, -0.4579,\n",
      "         -0.0522,  0.2500],\n",
      "        [-0.1184,  0.0468,  0.4011,  0.1718, -0.2393, -0.0165, -0.5396, -0.0907,\n",
      "          0.1236,  0.4671],\n",
      "        [ 0.1955, -0.0466,  0.2347,  0.0438, -0.3367,  0.1049, -0.1853,  0.1573,\n",
      "         -0.2318,  0.1444],\n",
      "        [-0.2319,  0.2468,  0.5189, -0.0688, -0.2461, -0.2256, -0.5956,  0.0712,\n",
      "          0.1104,  0.0724],\n",
      "        [ 0.4324, -0.2587,  0.2182,  0.0798, -0.0856, -0.4120, -0.5433,  0.0999,\n",
      "         -0.2112, -0.0375],\n",
      "        [ 0.0583, -0.0756, -0.2798, -0.0312,  0.3975, -0.5392, -0.4331, -0.1368,\n",
      "          0.4506, -0.0624],\n",
      "        [ 0.0338, -0.0511,  0.3543, -0.0871,  0.1143,  0.2116, -0.6584,  0.2266,\n",
      "          0.2393, -0.0511],\n",
      "        [ 0.0533, -0.2250,  0.2895, -0.0502, -0.7401, -0.1167, -0.4254,  0.0580,\n",
      "         -0.1470,  0.2834],\n",
      "        [ 0.1930,  0.1619,  0.3639, -0.4222,  0.3061, -0.0521, -0.5112,  0.0194,\n",
      "          0.2865,  0.2827],\n",
      "        [ 0.1362, -0.1335,  0.2496,  0.2204, -0.1278,  0.0042,  0.0022, -0.0155,\n",
      "         -0.2896,  0.2016],\n",
      "        [ 0.1164, -0.0991,  0.6383,  0.5772, -0.2251, -0.2737, -0.4470, -0.1937,\n",
      "          0.2432,  0.0190],\n",
      "        [-0.0173,  0.2112,  0.5699,  0.2770, -0.3261, -0.1025, -0.1198,  0.1003,\n",
      "         -0.3960, -0.0202],\n",
      "        [ 0.0241, -0.2625,  0.3381, -0.0196,  0.0073, -0.0849, -0.0638, -0.3388,\n",
      "         -0.0104,  0.1231],\n",
      "        [ 0.3887, -0.0912,  0.2498,  0.5023,  0.1618, -0.1715, -0.5106,  0.0197,\n",
      "         -0.1483,  0.1456],\n",
      "        [ 0.3057, -0.2296,  0.1941,  0.2684,  0.2006, -0.3514, -0.1752, -0.0432,\n",
      "          0.3591,  0.6532],\n",
      "        [-0.1384,  0.0962,  0.4907,  0.1744, -0.1828, -0.2286, -0.4061, -0.1763,\n",
      "          0.0297,  0.3177],\n",
      "        [ 0.1076, -0.0252,  0.1472,  0.0623, -0.1645, -0.2042, -0.2536, -0.2133,\n",
      "          0.3866,  0.0881],\n",
      "        [ 0.2386,  0.0490, -0.0314,  0.3750,  0.0524,  0.1065, -0.5642,  0.1652,\n",
      "          0.0397,  0.1965],\n",
      "        [ 0.0219, -0.1060,  0.1185,  0.1573, -0.0802, -0.1253, -0.3449, -0.1027,\n",
      "          0.2665, -0.0501],\n",
      "        [ 0.0810, -0.0671,  0.8461,  0.3659, -0.0325, -0.0660, -0.2924,  0.0062,\n",
      "          0.0161,  0.1859],\n",
      "        [ 0.4059, -0.2319, -0.0395,  0.1863,  0.0840, -0.3887, -0.2945, -0.0030,\n",
      "         -0.0047,  0.2585],\n",
      "        [ 0.0710, -0.0423, -0.0037,  0.0901,  0.0025,  0.1176, -0.0991, -0.0152,\n",
      "          0.0508,  0.0639],\n",
      "        [ 0.2048, -0.2726,  0.3665,  0.1254,  0.0137,  0.0042, -0.2152,  0.0667,\n",
      "          0.0104,  0.0141],\n",
      "        [ 0.1171,  0.1446,  0.0860,  0.0570, -0.4180, -0.0419, -0.2316, -0.4344,\n",
      "          0.3701,  0.1126],\n",
      "        [ 0.3475, -0.1136,  0.5898,  0.1587, -0.3755, -0.1503, -0.2221, -0.0475,\n",
      "          0.1036,  0.1846],\n",
      "        [ 0.1964,  0.0404, -0.3705,  0.1125, -0.3182, -0.1173, -0.3621,  0.0148,\n",
      "          0.3457, -0.0016],\n",
      "        [ 0.1830,  0.1487,  0.0240, -0.1144, -0.4640, -0.1715, -0.5988, -0.3524,\n",
      "         -0.2699, -0.0365]], grad_fn=<AddmmBackward0>)}\n"
     ]
    }
   ],
   "source": [
    "# 自定义 ModelConfig\n",
    "from ray.rllib.core.models.configs import ModelConfig\n",
    "from ray.rllib.core.models.torch.encoder import TorchModel, Encoder\n",
    "from dataclasses import dataclass\n",
    "from ray.rllib.core.models.base import ENCODER_OUT\n",
    "from ray.rllib.core.columns import Columns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class ConvFCNetEncoder(TorchModel, Encoder):\n",
    "    \"\"\"\n",
    "    自定义的编码器\n",
    "    - 继承 TorchModel, Encoder\n",
    "    - 初始化函数接收参数 config（也就是 ModelConfig重写类 的示例本身）\n",
    "        TorchModel.__init__(self, config)\n",
    "        Encoder.__init__(self, config)\n",
    "    - 重写方法 def _forward(self, inputs: dict, **kwargs) -> dict:\n",
    "        注意输入 / 输出\n",
    "    \"\"\"\n",
    "    def __init__(self, config) -> None:\n",
    "        TorchModel.__init__(self, config)\n",
    "        Encoder.__init__(self, config)\n",
    "    \n",
    "        self.conv1 = nn.Conv2d(in_channels=config.input_dims[0], out_channels=16, kernel_size=3, stride=1, padding=1)\n",
    "        conv1_out = (config.input_dims[1] // 1) * (config.input_dims[2] // 1) * 16  # 64 * 64 * 16\n",
    "        self.fc = nn.Linear(conv1_out, config.out_dim)\n",
    "\n",
    "    def _forward(self, inputs: dict, **kwargs) -> dict:\n",
    "        x = F.relu(self.conv1(inputs[Columns.OBS]))\n",
    "        x = x.view(x.size(0), -1)  # Flatten the output of convolutional layer\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return {ENCODER_OUT: x}\n",
    "\n",
    "@dataclass# input_dims / out_dim 为实例参数\n",
    "class test_EncoderConfig(ModelConfig):\n",
    "    \"\"\"\n",
    "    output_dims函数 返回编码器输出的维度，用于其他构造 head模型 的输入\n",
    "    \"\"\"\n",
    "    input_dims = None\n",
    "    out_dim = 10\n",
    "    def build(self, framework: str = \"torch\"):\n",
    "        if framework == \"torch\":\n",
    "            # 一个卷积层 + 全连接层\n",
    "            return ConvFCNetEncoder(self)\n",
    "\n",
    "        else:\n",
    "            raise ValueError(f'only torch ModelConfig')\n",
    "\n",
    "    @property\n",
    "    def output_dims(self):\n",
    "        \"\"\"Read-only `output_dims` are inferred automatically from other settings.\"\"\"\n",
    "        return (int(self.out_dim),)# 注意返回的是维度，不是int\n",
    "    \n",
    "net = test_EncoderConfig([3, 64, 64], 10).build()\n",
    "print(net)\n",
    "\n",
    "batch_size = 64\n",
    "input_tensor = torch.randn(batch_size, 3, 64, 64)  # PyTorch格式\n",
    "print(input_tensor.shape)\n",
    "\n",
    "# 前向传播\n",
    "output = net({Columns.OBS: input_tensor})# 与默认编码器一致输入/输出\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-08 15:32:32,432\tWARNING ppo.py:295 -- You are running PPO on the new API stack! This is the new default behavior for this algorithm. If you don't want to use the new API stack, set `config.api_stack(enable_rl_module_and_learner=False,enable_env_runner_and_connector_v2=False)`. For a detailed migration guide, see here: https://docs.ray.io/en/master/rllib/new-api-stack-migration-guide.html\n",
      "2025-01-08 15:32:39,276\tWARNING ppo.py:295 -- You are running PPO on the new API stack! This is the new default behavior for this algorithm. If you don't want to use the new API stack, set `config.api_stack(enable_rl_module_and_learner=False,enable_env_runner_and_connector_v2=False)`. For a detailed migration guide, see here: https://docs.ray.io/en/master/rllib/new-api-stack-migration-guide.html\n",
      "2025-01-08 15:32:39,459\tWARNING rl_module.py:427 -- Could not create a Catalog object for your RLModule! If you are not using the new API stack yet, make sure to switch it off in your config: `config.api_stack(enable_rl_module_and_learner=False, enable_env_runner_and_connector_v2=False)`. Some algos already use the new stack by default. Ignore this message, if your RLModule does not use a Catalog to build its sub-components.\n",
      "2025-01-08 15:32:39,631\tWARNING util.py:61 -- Install gputil for GPU system monitoring.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PPOTorchRLModule(\n",
       "  (encoder): TorchActorCriticEncoder(\n",
       "    (actor_encoder): ConvFCNetEncoder(\n",
       "      (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (fc): Linear(in_features=537600, out_features=10, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (pi): TorchMLPHead(\n",
       "    (net): TorchMLP(\n",
       "      (mlp): Sequential(\n",
       "        (0): Linear(in_features=10, out_features=6, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (vf): TorchMLPHead(\n",
       "    (net): TorchMLP(\n",
       "      (mlp): Sequential(\n",
       "        (0): Linear(in_features=10, out_features=1, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import functools\n",
    "from ray.rllib.algorithms.ppo import PPOConfig\n",
    "from ray.rllib.algorithms.ppo.ppo_catalog import PPOCatalog\n",
    "from ray.rllib.core.rl_module.rl_module import RLModuleSpec\n",
    "from ray.tune.registry import get_trainable_cls, register_env\n",
    "from ray.rllib.env.wrappers.atari_wrappers import wrap_atari_for_new_api_stack\n",
    "\n",
    "class custom_PPOCatalog(PPOCatalog):\n",
    "    \"\"\"\n",
    "    - 重写 _determine_components_hook 生成配置\n",
    "    \"\"\"\n",
    "    def _determine_components_hook(self):\n",
    "        # 获取输入参数 可设置参数 input_dims / out_dim\n",
    "        input_dims = self._model_config_dict[\"input_dims\"]\n",
    "        out_dim = self._model_config_dict[\"out_dim\"]\n",
    "        # 生成配置\n",
    "        self._encoder_config = test_EncoderConfig(input_dims, out_dim)\n",
    "\n",
    "        # 不变\n",
    "        # Create a function that can be called when framework is known to retrieve the\n",
    "        # class type for action distributions\n",
    "        self._action_dist_class_fn = functools.partial(\n",
    "            self._get_dist_cls_from_action_space, action_space=self.action_space\n",
    "        )\n",
    "\n",
    "        # 不变\n",
    "        # The dimensions of the latent vector that is output by the encoder and fed\n",
    "        # to the heads.\n",
    "        self.latent_dims = self._encoder_config.output_dims\n",
    "\n",
    "\n",
    "register_env(\n",
    "    \"pong\",\n",
    "    lambda cfg: wrap_atari_for_new_api_stack(\n",
    "        gym.make(\"ale_py:ALE/Pong-v5\", **cfg),\n",
    "        dim=42,  # <- need images to be \"tiny\" for our custom model\n",
    "        framestack=4,\n",
    "    ),\n",
    ")\n",
    "\n",
    "config = (\n",
    "    PPOConfig()\n",
    "    .api_stack(# 使用新的api\n",
    "        enable_rl_module_and_learner=True,\n",
    "        enable_env_runner_and_connector_v2=True,\n",
    "    )\n",
    "    .environment(\"pong\")# 输入的是3d(4, 42, 42)\n",
    "    .rl_module(\n",
    "        rl_module_spec=RLModuleSpec(catalog_class=custom_PPOCatalog),# 使用自定义配置\n",
    "        model_config={\n",
    "            # # MLP 参数\n",
    "            # \"fcnet_hiddens\": [5, 3, 3],\n",
    "\n",
    "            # CNN 参数\n",
    "            # \"conv_filters\": [\n",
    "            #     [32, [8, 8], 4],  # [输出通道数, [kernel_size_h, kernel_size_w], stride]\n",
    "            #     [64, [4, 4], 2],  # [64个通道, 4x4卷积核, stride=2]\n",
    "            #     [64, [3, 3], 1],  # [64个通道, 3x3卷积核, stride=1] \n",
    "            # ],\n",
    "\n",
    "            # 自定义编码器参数\n",
    "            'input_dims' : [3, 210, 160],\n",
    "            'out_dim' : 10,\n",
    "        },\n",
    "    )\n",
    ")\n",
    "\n",
    "# 构建算法\n",
    "algo = config.build()\n",
    "\n",
    "# 查看模型\n",
    "algo.get_module()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
